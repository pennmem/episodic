{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b63a2c2f-69b7-47fd-b613-8843362dc85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/ptsa/data/TimeSeriesX.py:7: DeprecationWarning: importing from ptsa.data.TimeSeries is deprecated; import from ptsa.data.timeseries instead\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# General\n",
    "import sys\n",
    "import os\n",
    "import os.path as op\n",
    "from collections import OrderedDict as od\n",
    "from importlib import reload\n",
    "from glob import glob\n",
    "import warnings\n",
    "\n",
    "# Scientific\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "# Personal\n",
    "sys.path.append('/home1/dscho/code/general')\n",
    "sys.path.append('/home1/dscho/code/from_others')\n",
    "sys.path.append('/home1/dscho/code/projects')\n",
    "sys.path.append('/home1/dscho/code/projects/manning_replication')\n",
    "# sys.path.append('/home1/dscho/code/projects/unit_activity_and_hpc_theta')\n",
    "from cluster_helper.cluster import cluster_view\n",
    "# from CMLDask import CMLDask\n",
    "# from dask.distributed import wait, as_completed, progress\n",
    "from helper_funcs import *\n",
    "import data_io as dio\n",
    "import array_operations as aop\n",
    "# import phase_locking\n",
    "# import manning_analysis\n",
    "from unit_activity_and_hpc_theta import phase_locking as phlock\n",
    "from time_cells import eeg_preproc, spike_preproc\n",
    "from phase_locking import spectral_analysis, unit_lfp_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7010db-1e9c-46af-a210-0964951f667d",
   "metadata": {},
   "source": [
    "# Process Goldmine microwire EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "949c2046-68e1-4a96-954d-94cb51cc5a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_eeg_parallel(subj_sess_chan):\n",
    "    subj, sess, chan = subj_sess_chan.split('_')\n",
    "    subj_sess = '{}_{}'.format(subj, sess)\n",
    "    \n",
    "#     from time import sleep\n",
    "#     from random import randint\n",
    "        \n",
    "#     # Go to sleep.\n",
    "#     sleep_secs = randint(0, 1800)\n",
    "#     sleep_secs = (int(chan) * 30) + randint(-30, 30)\n",
    "#     sleep(sleep_secs)\n",
    "\n",
    "    import sys\n",
    "    import os\n",
    "    sys.path.append('/home1/dscho/code/projects')\n",
    "    from time_cells import eeg_preproc\n",
    "    \n",
    "    l_freq = 0.1\n",
    "    h_freq = 80\n",
    "    notch_freqs = [60]\n",
    "    downsample_to = 1000\n",
    "    save_output = True\n",
    "    overwrite = False\n",
    "    \n",
    "    try:\n",
    "        eeg, sr = eeg_preproc.process_eeg(subj_sess,\n",
    "                                          chan=chan,\n",
    "                                          downsample_to=downsample_to,\n",
    "                                          l_freq=l_freq,\n",
    "                                          h_freq=h_freq,\n",
    "                                          notch_freqs=notch_freqs,\n",
    "                                          save_output=save_output,\n",
    "                                          overwrite=overwrite,\n",
    "                                          verbose=False)\n",
    "        return None\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = '/home1/dscho/logs/TryExceptError-process_eeg_parallel-{}'.format(subj_sess_chan)\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62692b4e-6a5a-47d0-9177-2198b1c7eb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 subjects, 12 sessions\n"
     ]
    }
   ],
   "source": [
    "# Get sessions.\n",
    "sessions = np.unique([op.basename(f).split('-')[0] \n",
    "                      for f in glob(op.join('/data7', 'goldmine', 'analysis', 'events', '*.pkl'))])\n",
    "print('{} subjects, {} sessions'.format(len(np.unique([x.split('_')[0] for x in sessions])), len(sessions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "384ef8c8-118b-43e4-8527-95e880c95a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 EEG channels processed\n",
      "898 EEG channels still to process\n"
     ]
    }
   ],
   "source": [
    "processed_chans = []\n",
    "chans_to_process = []\n",
    "for subj_sess in sessions:\n",
    "    subj, sess = subj_sess.split('_')\n",
    "    eeg_chan_files = glob(op.join('/data7/goldmine', 'data', subj, sess, 'micro_lfps', 'CSC*.mat'))\n",
    "    processed_chans += glob(op.join('/data7/goldmine', 'data', subj, sess, 'micro_lfps', 'sr1000_bandpass0.1-80_notch60', 'CSC*.pkl'))\n",
    "    chans_to_process += ['{}_{}'.format(subj_sess, str_replace(op.basename(f), {'CSC': '', '.mat': ''}))\n",
    "                         for f in eeg_chan_files\n",
    "                         if not op.exists(op.join('/data7/goldmine', 'data', subj, sess, 'micro_lfps', 'sr1000_bandpass0.1-80_notch60',\n",
    "                                                  'CSC{}.pkl'.format(str_replace(op.basename(f), {'CSC': '', '.mat': ''}))))]\n",
    "print('{} EEG channels processed'.format(len(processed_chans)))\n",
    "print('{} EEG channels still to process'.format(len(chans_to_process)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b507a89-8431-4c97-92a1-bd06769119f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timer = Timer()\n",
    "# eeg, sr = process_eeg_parallel(chans_to_process[0])\n",
    "\n",
    "# print(sr, eeg.shape)\n",
    "# print(timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76d71f2d-bc60-4e6a-bee2-fbc62e6c4172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get channels to process.\n",
    "start_time = time()\n",
    "\n",
    "# Parallel processing\n",
    "n_ops = len(chans_to_process)\n",
    "print('Running code for {} operations.\\n'.format(n_ops))\n",
    "with cluster_view(scheduler=\"sge\", queue=\"RAM.q\", num_jobs=np.min((n_ops, 240)), cores_per_job=24, retries=2) as view:\n",
    "    output = view.map(process_eeg_parallel, chans_to_process)\n",
    "    \n",
    "print('Done in {:.1f}s'.format(time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb649be-4a09-41be-a552-64062e5a5598",
   "metadata": {},
   "source": [
    "# Process YCab EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70f3560c-9287-4a7d-98ea-2e000fa6d903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_eeg_ycab_parallel(subj_df):\n",
    "#     from time import sleep\n",
    "#     from random import randint\n",
    "        \n",
    "#     # Go to sleep.\n",
    "#     sleep_secs = randint(0, 1800)\n",
    "#     sleep_secs = (int(chan) * 30) + randint(-30, 30)\n",
    "#     sleep(sleep_secs)\n",
    "\n",
    "    import sys\n",
    "    import os\n",
    "    import numpy as np\n",
    "    sys.path.append('/home1/dscho/code/projects')\n",
    "    from time_cells import eeg_preproc\n",
    "    \n",
    "    convert_v_to_muv = True\n",
    "    downsample_to = 1000\n",
    "    l_freq = 0.1\n",
    "    h_freq = 80\n",
    "    notch_freqs = [60]\n",
    "    data_dir = '/scratch/dscho/ycab/eeg'\n",
    "    save_output = True\n",
    "    overwrite = True\n",
    "    \n",
    "    try:\n",
    "        for idx, subj_df_row in subj_df.iterrows():\n",
    "            subj_sess = subj_df_row['subj_sess']\n",
    "            chan = subj_df_row['chan']\n",
    "            subj_sess_chan = '{}_{}'.format(subj_sess, chan)\n",
    "            eeg_in = np.fromfile(subj_df_row['raw_lfp_file'], dtype='float32').astype(np.float64)\n",
    "            sr_in = 2000\n",
    "            eeg, sr = eeg_preproc.process_eeg(subj_sess,\n",
    "                                              chan,\n",
    "                                              eeg=eeg_in,\n",
    "                                              sr=sr_in,\n",
    "                                              convert_v_to_muv=convert_v_to_muv,\n",
    "                                              downsample_to=downsample_to,\n",
    "                                              l_freq=l_freq,\n",
    "                                              h_freq=h_freq,\n",
    "                                              notch_freqs=notch_freqs,\n",
    "                                              data_dir=data_dir,\n",
    "                                              save_output=save_output,\n",
    "                                              overwrite=overwrite,\n",
    "                                              verbose=False)\n",
    "        return None\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = '/home1/dscho/logs/TryExceptError-process_eeg_ycab_parallel-{}'.format(subj_sess_chan)\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12bae745-7297-43cd-b578-d4e4b885573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 subjects and 43 sessions\n",
      "subj_df: (2696, 14)\n"
     ]
    }
   ],
   "source": [
    "# Load the subject dataframe (each row = 1 channel)\n",
    "subj_df = phlock.get_subj_df()\n",
    "idx = np.where(subj_df.query(\"(subj!='U367')\")['location'].apply(lambda x: x[-1]=='H'))[0]\n",
    "subjs = subj_df.query(\"(subj!='U367')\").iloc[idx, :]['subj'].unique()\n",
    "subj_df = subj_df.query(\"(subj=={})\".format(subjs.tolist())).reset_index(drop=True)\n",
    "\n",
    "# Fix session naming.\n",
    "subj_df['subj_sess'] = subj_df['subj_sess'].apply(lambda x: str_replace(x, {'env': 'ses', '1a': '1'}))\n",
    "subj_df['sess'] = subj_df['sess'].apply(lambda x: str_replace(x, {'env': 'ses', '1a': '1'}))\n",
    "yc_subjs = np.sort(subj_df['subj'].unique())\n",
    "yc_sessions = np.sort(subj_df['subj_sess'].unique())\n",
    "\n",
    "# Add paths to the processed LFP channels.\n",
    "data_dir = '/scratch/dscho/ycab/eeg'\n",
    "subj_df['proc_lfp_file'] = subj_df.apply(lambda x: op.join(data_dir, x['subj'], x['sess'], 'micro_lfps',\n",
    "                                                           'V-to-muV_sr1000_bandpass0.1-80_notch60',\n",
    "                                                           'CSC{}.pkl'.format(x['chan'])), axis=1)\n",
    "\n",
    "print('{} subjects and {} sessions'.format(len(yc_subjs), len(yc_sessions)))\n",
    "print('subj_df: {}'.format(subj_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aca5e01c-e361-4d20-bb4d-01b4efbfb0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 sessions processed\n",
      "0 sessions still to process\n"
     ]
    }
   ],
   "source": [
    "# processed_chans = [row for idx, row in subj_df.iterrows() if op.exists(row['proc_lfp_file'])]\n",
    "# chans_to_process = [row for idx, row in subj_df.iterrows() if not op.exists(row['proc_lfp_file'])]\n",
    "processed_sessions = [df for idx, df in subj_df.groupby('subj_sess') if np.all(df['proc_lfp_file'].apply(op.exists))]\n",
    "sessions_to_process = [df for idx, df in subj_df.groupby('subj_sess') if not np.all(df['proc_lfp_file'].apply(op.exists))]\n",
    "\n",
    "print('{} sessions processed'.format(len(processed_sessions)))\n",
    "print('{} sessions still to process'.format(len(sessions_to_process)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "11dfc769-574b-49a1-b3d2-12d1460a13ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U369_ses2, chan1\n",
      "Notch filtering at [60] Hz\n",
      "eeg: (825808,), sr: 1000.0 Hz\n",
      "Ran in 1.0s\n"
     ]
    }
   ],
   "source": [
    "timer = Timer()\n",
    "\n",
    "_subj_df = sessions_to_process[0]\n",
    "print('{}'.format(_subj_df.iloc[0]['subj_sess']))\n",
    "_ = process_eeg_ycab_parallel(_subj_df)\n",
    "\n",
    "print(timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f7a775c-4a99-42e6-afbc-dcf043a14ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel processing\n",
    "n_ops = len(sessions_to_process)\n",
    "print('Running code for {} operations.\\n'.format(n_ops))\n",
    "with cluster_view(scheduler=\"sge\", queue=\"RAM.q\", num_jobs=np.min((n_ops, 10)), cores_per_job=8, retries=2) as view:\n",
    "    output = view.map(process_eeg_ycab_parallel, sessions_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9781a6c-c902-4ccc-be3d-5c01532d40ff",
   "metadata": {},
   "source": [
    "# Process Goldmine phase and power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa7384c0-aed0-462a-89b3-d90ef04d40c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_spectral_fooof_p_episode_parallel(info):\n",
    "#     # Go to sleep.\n",
    "#     from time import sleep\n",
    "#     from random import randint\n",
    "#     sleep_secs = randint(0, 1800)\n",
    "#     sleep_secs = (int(chan) * 30) + randint(-30, 30)\n",
    "#     sleep(sleep_secs)\n",
    "    import os\n",
    "    import sys\n",
    "    import os.path as op\n",
    "    import numpy as np\n",
    "    from fooof import FOOOF, FOOOFGroup\n",
    "    from fooof.objs.utils import combine_fooofs\n",
    "    sys.path.append('/home1/dscho/code/projects')\n",
    "    from time_cells import eeg_preproc, spectral_analysis\n",
    "    \n",
    "    try:\n",
    "        subj_sess = info['subj_sess']\n",
    "        roi = info['roi']\n",
    "        game_states = info['game_states']\n",
    "        gs_cat = 'delay' if 'Delay' in game_states[0] else 'nav'\n",
    "        \n",
    "        # -----------------------\n",
    "        # Load EEG for each channel and event.\n",
    "        buffer = 2500\n",
    "        l_freq = 0.1\n",
    "        h_freq = 80\n",
    "        notch_freqs = [60]\n",
    "        chan_exclusion_thresh = 2\n",
    "        verbose = True\n",
    "        \n",
    "        event_eeg = eeg_preproc.load_event_eeg(subj_sess,\n",
    "                                               regions=[roi],\n",
    "                                               game_states=game_states,\n",
    "                                               buffer=buffer,\n",
    "                                               l_freq=l_freq,\n",
    "                                               h_freq=h_freq,\n",
    "                                               notch_freqs=notch_freqs,\n",
    "                                               chan_exclusion_thresh=chan_exclusion_thresh,\n",
    "                                               verbose=verbose)\n",
    "        event_eeg = event_eeg[roi].stack(event=('gameState', 'trial')).transpose('event', 'chan', 'time')\n",
    "        \n",
    "        # -----------------------\n",
    "        # Save power and phase at each timepoint, for each channel and event.\n",
    "        freqs = np.arange(1, 31)\n",
    "        buffer = 2500\n",
    "        clip_buffer = False\n",
    "        n_cycles = 5\n",
    "        zero_mean = True\n",
    "        log_power = False\n",
    "        output_dir = op.join('/scratch/dscho/goldmine', gs_cat, 'spectral')\n",
    "        save_output = True\n",
    "        overwrite = True\n",
    "        verbose = True\n",
    "        \n",
    "        power, phase = spectral_analysis.timefreq_wavelet(event_eeg,\n",
    "                                                          freqs,\n",
    "                                                          clip_buffer=clip_buffer,\n",
    "                                                          n_cycles=n_cycles,\n",
    "                                                          zero_mean=zero_mean,\n",
    "                                                          log_power=log_power,\n",
    "                                                          output_dir=output_dir,\n",
    "                                                          save_output=save_output,\n",
    "                                                          overwrite=overwrite,\n",
    "                                                          verbose=verbose)\n",
    "        \n",
    "        # -----------------------\n",
    "        # Run FOOOF on spectral powers for each channel and event.\n",
    "        freqs = np.arange(1, 31)\n",
    "        peak_width_limits = (1, 8)\n",
    "        min_peak_height = 0.2\n",
    "        max_n_peaks = 4\n",
    "        peak_threshold = 2\n",
    "        aperiodic_mode = 'fixed'\n",
    "        output_dir = op.join('/home1/dscho/projects/unit_activity_and_hpc_theta/data2/goldmine',\n",
    "                             gs_cat, 'fooof')\n",
    "        save_output = True\n",
    "        overwrite = True\n",
    "        verbose = True\n",
    "        \n",
    "        fg = spectral_analysis.run_fooof(subj_sess,\n",
    "                                         roi,\n",
    "                                         power=power,\n",
    "                                         freqs=freqs,\n",
    "                                         peak_width_limits=peak_width_limits,\n",
    "                                         min_peak_height=min_peak_height,\n",
    "                                         max_n_peaks=max_n_peaks,\n",
    "                                         peak_threshold=peak_threshold,\n",
    "                                         aperiodic_mode=aperiodic_mode,\n",
    "                                         output_dir=output_dir,\n",
    "                                         save_output=save_output,\n",
    "                                         overwrite=overwrite,\n",
    "                                         verbose=verbose)\n",
    "        \n",
    "        # -----------------------\n",
    "        # Run P-episode.\n",
    "        freqs = np.arange(1, 31)\n",
    "        cycle_thresh = 3\n",
    "        thresh_req = 'mean'\n",
    "        chi2_pctl = 0.95\n",
    "        output_dir = op.join('/scratch/dscho/goldmine', gs_cat, 'p_episode')\n",
    "        save_output = True\n",
    "        overwrite = True\n",
    "        verbose = True\n",
    "        \n",
    "        osc_mask = spectral_analysis.run_p_episode(subj_sess,\n",
    "                                                   roi,\n",
    "                                                   freqs=freqs,\n",
    "                                                   cycle_thresh=cycle_thresh,\n",
    "                                                   thresh_req=thresh_req,\n",
    "                                                   chi2_pctl=chi2_pctl,\n",
    "                                                   output_dir=output_dir,\n",
    "                                                   save_output=save_output,\n",
    "                                                   overwrite=overwrite,\n",
    "                                                   verbose=verbose)\n",
    "        \n",
    "        # -----------------------\n",
    "        output = {'event_eeg': event_eeg,\n",
    "                  'power': power,\n",
    "                  'phase': phase,\n",
    "                  'fg': fg,\n",
    "                  'osc_mask': osc_mask}\n",
    "        return output\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = '/home1/dscho/logs/TryExceptError-save_spectral_fooof_p_episode_parallel-{}-{}-{}'.format(subj_sess, roi, '_'.join(game_states))\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6e65b31-6ba7-4ef3-b9c1-edde24433195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 subjects, 12 sessions\n"
     ]
    }
   ],
   "source": [
    "# Get sessions.\n",
    "sessions = np.unique([op.basename(f).split('-')[0] \n",
    "                      for f in glob(op.join('/data7', 'goldmine', 'analysis', 'events', '*.pkl'))])\n",
    "print('{} subjects, {} sessions'.format(len(np.unique([x.split('_')[0] for x in sessions])), len(sessions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6fa8f41-be7b-41a3-94a4-380b742751eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/113 regions to process\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all regions to process.\n",
    "overwrite = False\n",
    "# data_dir = '/home1/dscho/projects/unit_activity_and_hpc_theta/data2/goldmine/delay'\n",
    "data_dir = '/home1/dscho/projects/unit_activity_and_hpc_theta/data2/goldmine/nav'\n",
    "\n",
    "# -----------------------\n",
    "if op.basename(data_dir) == 'delay':\n",
    "    game_states = ['Delay1', 'Delay2']\n",
    "else:\n",
    "    game_states = ['Encoding', 'Retrieval']\n",
    "    \n",
    "processed = []\n",
    "to_process = []\n",
    "for subj_sess in sessions:\n",
    "    mont = spike_preproc.get_montage(subj_sess)\n",
    "    for roi in mont.keys():\n",
    "        info = {'subj_sess': subj_sess,\n",
    "                'roi': roi,\n",
    "                'game_states': game_states}\n",
    "        subj_sess_roi = '{}-{}'.format(subj_sess, roi)\n",
    "        basename = '{}.pkl'.format(subj_sess_roi)\n",
    "        output_files = (op.join(data_dir, 'spectral', 'power', basename),\n",
    "                        op.join(data_dir, 'spectral', 'phase', basename),\n",
    "                        op.join(data_dir, 'fooof', basename.replace('.pkl', '.json')),\n",
    "                        op.join(data_dir, 'p_episode', basename))\n",
    "        if np.all([op.exists(f) for f in output_files]) and not overwrite:\n",
    "            processed.append(info)\n",
    "        else:\n",
    "            to_process.append(info)\n",
    "\n",
    "print('{}/{} regions to process'.format(len(to_process), len(processed) + len(to_process)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3d84a6f-e0cc-41fa-b664-71ade8336b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subj_sess': 'U527_ses0', 'roi': 'LMH', 'game_states': ['Encoding', 'Retrieval']}\n",
      "U527_ses0\n",
      "---------\n",
      "Kept 8/8 (100%) channels across 1 regions\n",
      "Ran in 4.6s\n",
      "\n",
      "Ran in 4.8s\n"
     ]
    }
   ],
   "source": [
    "timer = Timer()\n",
    "\n",
    "ii = 0\n",
    "print(to_process[ii])\n",
    "_ = save_spectral_fooof_p_episode_parallel(to_process[ii])\n",
    "\n",
    "print(timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e192faf0-0609-40ba-87b1-fede4a3042b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get channels to process.\n",
    "start_time = time()\n",
    "\n",
    "# Parallel processing\n",
    "n_ops = len(to_process)\n",
    "print('Running code for {} operations.\\n'.format(n_ops))\n",
    "with cluster_view(scheduler=\"sge\", queue=\"RAM.q\", num_jobs=np.min((n_ops, 6)), cores_per_job=24, retries=2) as view:\n",
    "    output = view.map(save_spectral_fooof_p_episode_parallel, to_process)\n",
    "    \n",
    "print('Done in {:.1f}s'.format(time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3feea9d-f0bc-4d62-8938-4bdb16ef8fb5",
   "metadata": {},
   "source": [
    "# Process YCab phase and power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "58653b4f-62d7-45f2-b49d-e603175850f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_spectral_fooof_p_episode_ycab_parallel(data_in):\n",
    "#     # Go to sleep.\n",
    "#     from time import sleep\n",
    "#     from random import randint\n",
    "#     sleep_secs = randint(0, 1800)\n",
    "#     sleep_secs = (int(chan) * 30) + randint(-30, 30)\n",
    "#     sleep(sleep_secs)\n",
    "    import os\n",
    "    import sys\n",
    "    import os.path as op\n",
    "    import numpy as np\n",
    "    import xarray\n",
    "    from fooof import FOOOF, FOOOFGroup\n",
    "    from fooof.objs.utils import combine_fooofs\n",
    "    sys.path.append('/home1/dscho/code/general')\n",
    "    import array_operations as aop\n",
    "    sys.path.append('/home1/dscho/code/projects')\n",
    "    from time_cells import eeg_preproc, spectral_analysis\n",
    "    \n",
    "    try:\n",
    "        subj_sess = data_in['subj_sess']\n",
    "        subj, sess = subj_sess.split('_')\n",
    "        roi = data_in['roi']\n",
    "        mont = data_in['mont']\n",
    "        \n",
    "        # -----------------------\n",
    "        # Load EEG for each channel and event.\n",
    "        regions = [roi]\n",
    "        sr = 1000\n",
    "        session_cut = 60000 # cut this many samples from start and end of the session\n",
    "        event_len = 30000\n",
    "        buffer = 2500\n",
    "        l_freq = 0.1\n",
    "        h_freq = 80\n",
    "        notch_freqs = [60]\n",
    "        chan_exclusion_thresh = 2\n",
    "        output_dir = op.join('/scratch/dscho/ycab/eeg', subj, sess, 'micro_lfps',\n",
    "                             'V-to-muV_sr1000_bandpass0.1-80_notch60')\n",
    "        verbose = True\n",
    "\n",
    "        time_eeg = eeg_preproc.load_time_eeg(subj_sess,\n",
    "                                             mont=mont,\n",
    "                                             regions=regions,\n",
    "                                             l_freq=l_freq,\n",
    "                                             h_freq=h_freq,\n",
    "                                             notch_freqs=notch_freqs,\n",
    "                                             chan_exclusion_thresh=chan_exclusion_thresh,\n",
    "                                             verbose=verbose,\n",
    "                                             output_dir=output_dir)\n",
    "        time_eeg = time_eeg[roi]\n",
    "        chans = time_eeg.index.values\n",
    "        # start_cut samples are cut from session start, on top of session_cut, to make for even epoching.\n",
    "        split_every = int(event_len)\n",
    "        start_cut = time_eeg.iloc[:, session_cut:time_eeg.shape[1]-session_cut].values.shape[1] % split_every\n",
    "        n_splits = int(time_eeg.iloc[:, session_cut+start_cut:-session_cut].shape[1] / split_every)\n",
    "        start_stop = aop.rolling_window(np.arange(session_cut+start_cut,\n",
    "                                                  time_eeg.shape[1]-session_cut+1,\n",
    "                                                  split_every), 2)\n",
    "        event_idx = np.array([np.arange(start-buffer, stop+buffer)\n",
    "                              for (start, stop) in start_stop.tolist()])\n",
    "        event_eeg = np.swapaxes(time_eeg.values[:, event_idx], 0, 1)[None, :, :, :] # gameState x trial x chan x time\n",
    "        event_eeg = {roi: xarray.DataArray(event_eeg,\n",
    "                                           name=(subj_sess, roi),\n",
    "                                           coords=[('gameState', ['YCab']),\n",
    "                                                   ('trial', np.arange(1, event_eeg.shape[1]+1)),\n",
    "                                                   ('chan', chans),\n",
    "                                                   ('time', np.arange(event_eeg.shape[-1]))],\n",
    "                                           dims=['gameState', 'trial', 'chan', 'time'],\n",
    "                                           attrs={'sr': sr,\n",
    "                                                  'buffer': buffer,\n",
    "                                                  'chan_exclusion_thresh': chan_exclusion_thresh,\n",
    "                                                  'session_cut': session_cut,\n",
    "                                                  'start_cut': start_cut})}\n",
    "        event_eeg = event_eeg[roi].stack(event=('gameState', 'trial')).transpose('event', 'chan', 'time')\n",
    "        \n",
    "        # -----------------------\n",
    "        # Save power and phase at each timepoint, for each channel and event.\n",
    "        freqs = np.arange(1, 31)\n",
    "        buffer = 2500\n",
    "        clip_buffer = False\n",
    "        n_cycles = 5\n",
    "        zero_mean = True\n",
    "        log_power = False\n",
    "        output_dir = '/scratch/dscho/ycab/spectral'\n",
    "        save_output = True\n",
    "        overwrite = True\n",
    "        verbose = True\n",
    "        \n",
    "        power, phase = spectral_analysis.timefreq_wavelet(event_eeg,\n",
    "                                                          freqs,\n",
    "                                                          clip_buffer=clip_buffer,\n",
    "                                                          n_cycles=n_cycles,\n",
    "                                                          zero_mean=zero_mean,\n",
    "                                                          log_power=log_power,\n",
    "                                                          output_dir=output_dir,\n",
    "                                                          save_output=save_output,\n",
    "                                                          overwrite=overwrite,\n",
    "                                                          verbose=verbose)\n",
    "        \n",
    "        # -----------------------\n",
    "        # Run FOOOF on spectral powers for each channel and event.\n",
    "        freqs = np.arange(1, 31)\n",
    "        peak_width_limits = (1, 8)\n",
    "        min_peak_height = 0.2\n",
    "        max_n_peaks = 4\n",
    "        peak_threshold = 2\n",
    "        aperiodic_mode = 'fixed'\n",
    "        output_dir = '/scratch/dscho/ycab/fooof'\n",
    "        save_output = True\n",
    "        overwrite = True\n",
    "        verbose = False\n",
    "        \n",
    "        fg = spectral_analysis.run_fooof(subj_sess,\n",
    "                                         roi,\n",
    "                                         power=power,\n",
    "                                         freqs=freqs,\n",
    "                                         peak_width_limits=peak_width_limits,\n",
    "                                         min_peak_height=min_peak_height,\n",
    "                                         max_n_peaks=max_n_peaks,\n",
    "                                         peak_threshold=peak_threshold,\n",
    "                                         aperiodic_mode=aperiodic_mode,\n",
    "                                         output_dir=output_dir,\n",
    "                                         save_output=save_output,\n",
    "                                         overwrite=overwrite,\n",
    "                                         verbose=verbose)\n",
    "        \n",
    "        # -----------------------\n",
    "        # Run P-episode.\n",
    "        freqs = np.arange(1, 31)\n",
    "        cycle_thresh = 3\n",
    "        thresh_req = 'mean'\n",
    "        chi2_pctl = 0.95\n",
    "        output_dir = '/scratch/dscho/ycab/p_episode'\n",
    "        save_output = True\n",
    "        overwrite = True\n",
    "        verbose = True\n",
    "        \n",
    "        osc_mask = spectral_analysis.run_p_episode(subj_sess,\n",
    "                                                   roi,\n",
    "                                                   freqs=freqs,\n",
    "                                                   cycle_thresh=cycle_thresh,\n",
    "                                                   thresh_req=thresh_req,\n",
    "                                                   chi2_pctl=chi2_pctl,\n",
    "                                                   output_dir=output_dir,\n",
    "                                                   save_output=save_output,\n",
    "                                                   overwrite=overwrite,\n",
    "                                                   verbose=verbose)\n",
    "        data_out = {'power': power,\n",
    "                    'phase': phase,\n",
    "                    'fg': fg,\n",
    "                    'osc_mask': osc_mask}\n",
    "        return data_out\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = '/home1/dscho/logs/TryExceptError-save_spectral_fooof_p_episode_ycab_parallel-{}-{}'.format(subj_sess, roi)\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')\n",
    "        return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9fc499d4-ec81-4689-8c54-655567bc0e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 subjects and 43 sessions\n",
      "subj_df: (2696, 14)\n"
     ]
    }
   ],
   "source": [
    "# Load the subject dataframe (each row = 1 channel)\n",
    "subj_df = phlock.get_subj_df()\n",
    "idx = np.where(subj_df.query(\"(subj!='U367')\")['location'].apply(lambda x: x[-1]=='H'))[0]\n",
    "subjs = subj_df.query(\"(subj!='U367')\").iloc[idx, :]['subj'].unique()\n",
    "subj_df = subj_df.query(\"(subj=={})\".format(subjs.tolist())).reset_index(drop=True)\n",
    "\n",
    "# Fix session naming.\n",
    "subj_df['subj_sess'] = subj_df['subj_sess'].apply(lambda x: str_replace(x, {'env': 'ses', '1a': '1'}))\n",
    "subj_df['sess'] = subj_df['sess'].apply(lambda x: str_replace(x, {'env': 'ses', '1a': '1'}))\n",
    "yc_subjs = np.sort(subj_df['subj'].unique())\n",
    "yc_sessions = np.sort(subj_df['subj_sess'].unique())\n",
    "\n",
    "# Add paths to the processed LFP channels.\n",
    "data_dir = '/scratch/dscho/ycab/eeg'\n",
    "subj_df['proc_lfp_file'] = subj_df.apply(lambda x: op.join(data_dir, x['subj'], x['sess'], 'micro_lfps',\n",
    "                                                           'V-to-muV_sr1000_bandpass0.1-80_notch60',\n",
    "                                                           'CSC{}.pkl'.format(x['chan'])), axis=1)\n",
    "\n",
    "print('{} subjects and {} sessions'.format(len(yc_subjs), len(yc_sessions)))\n",
    "print('subj_df: {}'.format(subj_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0304dfcf-7d19-443e-b506-7d0eb8c9ee54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 regions to process\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all regions to process.\n",
    "overwrite = True\n",
    "data_dir = '/scratch/dscho/ycab'\n",
    "processed = []\n",
    "to_process = []\n",
    "for subj_sess in yc_sessions:\n",
    "    mont = (subj_df.query(\"(subj_sess=='{}')\".format(subj_sess))\n",
    "                   .groupby(['location'])['chan']\n",
    "                   .apply(lambda x: np.array([int(chan) for chan in x])))\n",
    "    for roi in mont.keys():\n",
    "        subj_sess_roi = '{}-{}'.format(subj_sess, roi)\n",
    "        basename = '{}.pkl'.format(subj_sess_roi)\n",
    "        output_files = (op.join(data_dir, 'spectral', 'power', basename),\n",
    "                        op.join(data_dir, 'spectral', 'phase', basename),\n",
    "                        op.join(data_dir, 'fooof', basename.replace('.pkl', '.json')),\n",
    "                        op.join(data_dir, 'p_episode', basename))\n",
    "        if np.all([op.exists(f) for f in output_files]) and not overwrite:\n",
    "            processed.append(subj_sess_roi)\n",
    "        else:\n",
    "            to_process.append({'subj_sess': subj_sess,\n",
    "                               'roi': roi,\n",
    "                               'mont': mont})\n",
    "\n",
    "print('{}/{} regions to process'.format(len(to_process), len(processed) + len(to_process)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f048440-1a55-4771-8bee-33871dc4b207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U369_ses1-LA\n",
      "\n",
      "U369_ses1\n",
      "---------\n",
      "Kept 8/8 (100%) channels across 1 regions\n",
      "Ran in 1.8s\n",
      "\n",
      "Saved /scratch/dscho/ycab/spectral/power/U369_ses1-LA.pkl\n",
      "Saved /scratch/dscho/ycab/spectral/phase/U369_ses1-LA.pkl\n",
      "Saved /scratch/dscho/ycab/p_episode/U369_ses1-LA.pkl\n",
      "Ran in 115.0s\n"
     ]
    }
   ],
   "source": [
    "timer = Timer()\n",
    "\n",
    "data_in = to_process[0]\n",
    "print('{}-{}'.format(data_in['subj_sess'], data_in['roi']), end='\\n'*2)\n",
    "data_out = save_spectral_fooof_p_episode_ycab_parallel(data_in)\n",
    "\n",
    "print(timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d7634f-c68a-4122-bef3-0f064033f723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running code for 336 operations.\n",
      "\n",
      "12 Engines running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Exception in callback BaseAsyncIOLoop._handle_events(56, 1)\n",
      "handle: <Handle BaseAsyncIOLoop._handle_events(56, 1)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/dscho/anaconda3/envs/memlab/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"<decorator-gen-150>\", line 2, in _dispatch_reply\n",
      "  File \"/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/ipyparallel/client/client.py\", line 71, in unpack_message\n",
      "    return f(self, msg)\n",
      "  File \"/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/ipyparallel/client/client.py\", line 930, in _dispatch_reply\n",
      "    handler(msg)\n",
      "  File \"/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/ipyparallel/client/client.py\", line 823, in _handle_apply_reply\n",
      "    self.results[msg_id] = serialize.deserialize_object(msg['buffers'])[0]\n",
      "  File \"/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/ipyparallel/serialize/serialize.py\", line 145, in deserialize_object\n",
      "    canned = pickle.loads(pobj)\n",
      "MemoryError\n"
     ]
    }
   ],
   "source": [
    "# Get channels to process.\n",
    "start_time = time()\n",
    "\n",
    "# Parallel processing\n",
    "n_ops = len(to_process)\n",
    "print('Running code for {} operations.\\n'.format(n_ops))\n",
    "with cluster_view(scheduler=\"sge\", queue=\"RAM.q\", num_jobs=np.min((n_ops, 12)), cores_per_job=12, retries=2) as view:\n",
    "    output = view.map(save_spectral_fooof_p_episode_ycab_parallel, to_process)\n",
    "    \n",
    "print('Done in {:.1f}s'.format(time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c90cdac-7022-41cc-b3fc-0eed55d81931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008 files\n",
      "Ran in 14391.3s\n"
     ]
    }
   ],
   "source": [
    "# Clip out the buffer and constrain frequencies to reduce file sizes.\n",
    "timer = Timer()\n",
    "freqs = np.arange(1, 31)\n",
    "# data_dir = '/home1/dscho/projects/unit_activity_and_hpc_theta/data2'\n",
    "data_dir = '/scratch/dscho/ycab'\n",
    "power_files = glob(op.join(data_dir, 'spectral', 'power', 'U*.pkl'))\n",
    "phase_files = glob(op.join(data_dir, 'spectral', 'phase', 'U*.pkl'))\n",
    "osc_mask_files = glob(op.join(data_dir, 'p_episode', 'U*.pkl'))\n",
    "all_files = phase_files + power_files + osc_mask_files\n",
    "print('{} files'.format(len(all_files)))\n",
    "\n",
    "for iFile, fpath in enumerate(all_files):\n",
    "    dat = dio.open_pickle(fpath)\n",
    "    dat = dat.loc[:, :, :, dat.buffer:dat.time.size-dat.buffer-1]\n",
    "    if 'clip_buffer' in dat.attrs:\n",
    "        dat.attrs['clip_buffer'] = True\n",
    "    dio.save_pickle(dat, fpath, verbose=False)\n",
    "\n",
    "print(timer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72acb7f8-1573-4843-81fd-30bc6cdf510b",
   "metadata": {},
   "source": [
    "# Clip out buffer and resave files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2227a86-6baf-4c00-aeb2-345b8f7962b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_the_buffer_parallel(fpath):\n",
    "    \"\"\"Remove the buffer and resave file.\"\"\"\n",
    "    from time import sleep\n",
    "    import random\n",
    "    sleep(random.randint(0, 120))\n",
    "    import sys\n",
    "    import os\n",
    "    sys.path.append('/home1/dscho/code/general')\n",
    "    import data_io as dio\n",
    "    \n",
    "    try:\n",
    "        dat = dio.open_pickle(fpath)\n",
    "        if (dat.buffer > 0) & (not dat.clip_buffer):\n",
    "            dat = dat.loc[:, :, :, dat.buffer:dat.time.size-dat.buffer-1]\n",
    "            dat.attrs['clip_buffer'] = True\n",
    "            dio.save_pickle(dat, fpath, verbose=False)\n",
    "        return None\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = ('/home1/dscho/logs/TryExceptError-clip_the_buffer_parallel-{}'\n",
    "                .format('-'.join(all_files[0].split('/')[-2:]).replace('.pkl', '')))\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a30baf-c446-4ccc-9574-2a0fc1dd28ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339 files\n",
      "Ran in 0.1s\n"
     ]
    }
   ],
   "source": [
    "# Clip out the buffer and constrain frequencies to reduce file sizes.\n",
    "# data_dir = '/scratch/dscho/ycab'\n",
    "# data_dir = '/scratch/dscho/goldmine/delay'\n",
    "data_dir = '/scratch/dscho/goldmine/nav'\n",
    "power_files = glob(op.join(data_dir, 'spectral', 'power', 'U*.pkl'))\n",
    "phase_files = glob(op.join(data_dir, 'spectral', 'phase', 'U*.pkl'))\n",
    "osc_mask_files = glob(op.join(data_dir, 'p_episode', 'U*.pkl'))\n",
    "all_files = phase_files + power_files + osc_mask_files\n",
    "print('{} files'.format(len(all_files)))\n",
    "\n",
    "# for iFile, fpath in enumerate(all_files):\n",
    "#     dat = dio.open_pickle(fpath)\n",
    "#     if (dat.buffer > 0) & (not dat.clip_buffer):\n",
    "#         dat = dat.loc[:, :, :, dat.buffer:dat.time.size-dat.buffer-1]\n",
    "#         dat.attrs['clip_buffer'] = True\n",
    "#         dio.save_pickle(dat, fpath, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37fc0a52-9a02-4a29-94f6-c7fc3b309c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel processing\n",
    "n_ops = len(all_files)\n",
    "print('Running code for {} operations.\\n'.format(n_ops))\n",
    "with cluster_view(scheduler=\"sge\", queue=\"RAM.q\", num_jobs=np.min((n_ops, 12)), cores_per_job=8, retries=2) as view:\n",
    "    output = view.map(clip_the_buffer_parallel, all_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998b4105-c6f9-4f17-8dae-e431676d31ce",
   "metadata": {},
   "source": [
    "# Run Goldmine phase-locking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a55118a-1b73-4a44-9b50-7efa1614fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_to_lfp_phase_locking_parallel(unit):\n",
    "    import sys\n",
    "    import os\n",
    "    sys.path.append('/home1/dscho/code/projects')\n",
    "    from phase_locking import unit_lfp_comparison\n",
    "    \n",
    "    try:\n",
    "        expmt = 'goldmine'\n",
    "        game_states = ['Encoding', 'Retrieval']\n",
    "        n_rois = 8\n",
    "        keep_same_hem = [True]\n",
    "        keep_edges=['hpc-local', 'hpc-hpc', 'hpc-ctx', 'ctx-local', 'ctx-hpc', 'ctx-ctx']\n",
    "        exclude_gen_rois = ['Other']\n",
    "        mask_phase = True\n",
    "        n_perm = 1000\n",
    "        data_dir = '/home1/dscho/projects/unit_activity_and_hpc_theta/data2/goldmine/nav'\n",
    "        save_output = True\n",
    "        overwrite = True\n",
    "\n",
    "        _ = unit_lfp_comparison.unit_to_lfp_phase_locking(unit,\n",
    "                                                          expmt=expmt,\n",
    "                                                          game_states=game_states,\n",
    "                                                          n_rois=n_rois,\n",
    "                                                          keep_same_hem=keep_same_hem,\n",
    "                                                          keep_edges=keep_edges,\n",
    "                                                          exclude_gen_rois=exclude_gen_rois,\n",
    "                                                          mask_phase=mask_phase,\n",
    "                                                          n_perm=n_perm,\n",
    "                                                          data_dir=data_dir,\n",
    "                                                          save_output=save_output,\n",
    "                                                          overwrite=overwrite)\n",
    "        return None\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = ('/home1/dscho/logs/TryExceptError-unit_to_lfp_phase_locking_parallel-{}'\n",
    "                .format('{}-{}-{}'.format(unit['subj_sess'], unit['chan'], unit['unit'])))\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59955cf9-3f61-49a5-9d65-b9bf281ac045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 subjects, 12 sessions\n",
      "spikes: (448, 10)\n",
      "Ran in 30.6s\n",
      "spikes: (402, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load spikes.\n",
    "fr_thresh = 0.2\n",
    "nspike_thresh = 0 # 400\n",
    "n_rois = 8\n",
    "expmt = 'goldmine'\n",
    "game_states = ['Encoding', 'Retrieval']\n",
    "exclude_gen_rois = ['Other']\n",
    "\n",
    "spikes = unit_lfp_comparison.load_all_unit_spikes(fr_thresh=fr_thresh,\n",
    "                                                  nspike_thresh=nspike_thresh,\n",
    "                                                  n_rois=n_rois,\n",
    "                                                  expmt=expmt,\n",
    "                                                  game_states=game_states)\n",
    "spikes = spikes.query(\"(roi_gen!={})\".format(exclude_gen_rois)).reset_index(drop=True)\n",
    "\n",
    "print('spikes: {}'.format(spikes.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1aadb056-1b22-48e7-95bd-3160b30b7600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 units to process\n"
     ]
    }
   ],
   "source": [
    "# Find units to process.\n",
    "data_dir = '/home1/dscho/projects/unit_activity_and_hpc_theta/data2/goldmine/nav'\n",
    "output_dir = op.join(data_dir, 'phase_locking')\n",
    "overwrite = 0\n",
    "process_idx = []\n",
    "for idx, unit in spikes.iterrows():\n",
    "    basename = '{}-{}-{}.pkl'.format(unit['subj_sess'], unit['chan'], unit['unit'])\n",
    "    if overwrite or not op.exists(op.join(output_dir, basename)):\n",
    "        process_idx.append(idx)\n",
    "        \n",
    "_spikes = spikes.loc[process_idx, :]\n",
    "print('{}/{} units to process'.format(len(_spikes), len(spikes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf76b023-4591-454a-a4be-1b1592d7a358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /home1/dscho/projects/unit_activity_and_hpc_theta/data2/goldmine/nav/phase_locking/U540_ses0-56-1.pkl\n",
      "pl_mrls: (1, 29)\n",
      "Ran in 11.4s\n",
      "Ran in 11.6s\n"
     ]
    }
   ],
   "source": [
    "# # Serial processing.\n",
    "# timer = Timer()\n",
    "\n",
    "# game_states = ['Encoding', 'Retrieval']\n",
    "# n_rois = 8\n",
    "# keep_same_hem = [True]\n",
    "# keep_edges=['hpc-local', 'hpc-hpc', 'hpc-ctx', 'ctx-local', 'ctx-hpc', 'ctx-ctx']\n",
    "# exclude_gen_rois = ['Other']\n",
    "# mask_phase = True\n",
    "# n_perm = 10\n",
    "# data_dir = '/home1/dscho/projects/unit_activity_and_hpc_theta/data2/goldmine/nav'\n",
    "# save_output = True\n",
    "# overwrite = True\n",
    "\n",
    "# unit = spikes.iloc[-1]\n",
    "# # unit = spikes.loc[spikes.query(\"(subj_sess=='U518_ses0') & (chan==11) & (unit==1)\").index[0]]\n",
    "# pl_mrls = unit_lfp_comparison.unit_to_lfp_phase_locking(unit,\n",
    "#                                                         game_states=game_states,\n",
    "#                                                         n_rois=n_rois,\n",
    "#                                                         keep_same_hem=keep_same_hem,\n",
    "#                                                         keep_edges=keep_edges,\n",
    "#                                                         exclude_gen_rois=exclude_gen_rois,\n",
    "#                                                         mask_phase=mask_phase,\n",
    "#                                                         n_perm=n_perm,\n",
    "#                                                         data_dir=data_dir,\n",
    "#                                                         save_output=save_output,\n",
    "#                                                         overwrite=overwrite)\n",
    "\n",
    "# print(timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f545c629-e2c5-4698-a7a5-5d34c9de8225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running code for 402 operations.\n",
      "\n",
      "25 Engines running\n"
     ]
    }
   ],
   "source": [
    "# Parallel processing\n",
    "n_ops = len(_spikes)\n",
    "print('Running code for {} operations.\\n'.format(n_ops))\n",
    "with cluster_view(scheduler=\"sge\", queue=\"RAM.q\", num_jobs=np.min((n_ops, 25)), cores_per_job=4, retries=2) as view:\n",
    "    output = view.map(unit_to_lfp_phase_locking_parallel, [vals for (idx, vals) in _spikes.iterrows()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7524b6e1-fc2f-47cc-bb58-6b5740857ab5",
   "metadata": {},
   "source": [
    "## osc2mask, unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b461f195-8910-44ee-9264-3ee4af631cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_to_lfp_phase_locking_osc2mask_parallel(unit):\n",
    "    import sys\n",
    "    import os\n",
    "    sys.path.append('/home1/dscho/code/projects')\n",
    "    from phase_locking import unit_lfp_comparison\n",
    "    \n",
    "    try:\n",
    "        expmt = 'goldmine'\n",
    "        game_states = ['Encoding', 'Retrieval']\n",
    "        n_rois = 8\n",
    "        keep_same_hem = [True]\n",
    "        keep_edges=['hpc-hpc', 'hpc-ctx', 'ctx-hpc', 'ctx-ctx']\n",
    "        exclude_gen_rois = ['Other']\n",
    "        n_perm = 1000\n",
    "        data_dir = '/home1/dscho/projects/unit_activity_and_hpc_theta/data2/goldmine/nav'\n",
    "        save_output = True\n",
    "        overwrite = True\n",
    "\n",
    "        _ = unit_lfp_comparison.unit_to_lfp_phase_locking_osc2mask(unit,\n",
    "                                                                   expmt=expmt,\n",
    "                                                                   game_states=game_states,\n",
    "                                                                   n_rois=n_rois,\n",
    "                                                                   keep_same_hem=keep_same_hem,\n",
    "                                                                   keep_edges=keep_edges,\n",
    "                                                                   exclude_gen_rois=exclude_gen_rois,\n",
    "                                                                   n_perm=n_perm,\n",
    "                                                                   data_dir=data_dir,\n",
    "                                                                   save_output=save_output,\n",
    "                                                                   overwrite=overwrite)\n",
    "        return None\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = ('/home1/dscho/logs/TryExceptError-unit_to_lfp_phase_locking_osc2mask_parallel-{}'\n",
    "                .format('{}-{}-{}'.format(unit['subj_sess'], unit['chan'], unit['unit'])))\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac211148-a53a-443e-8f04-99bde884b480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 units to process\n"
     ]
    }
   ],
   "source": [
    "# Find units to process.\n",
    "data_dir = '/home1/dscho/projects/unit_activity_and_hpc_theta/data2/goldmine/nav'\n",
    "output_dir = op.join(data_dir, 'phase_locking', 'osc2mask')\n",
    "overwrite = 0\n",
    "process_idx = []\n",
    "for idx, unit in spikes.iterrows():\n",
    "    basename = '{}-{}-{}.pkl'.format(unit['subj_sess'], unit['chan'], unit['unit'])\n",
    "    if overwrite or not op.exists(op.join(output_dir, basename)):\n",
    "        process_idx.append(idx)\n",
    "        \n",
    "_spikes = spikes.loc[process_idx, :]\n",
    "print('{}/{} units to process'.format(len(_spikes), len(spikes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8227b840-b544-401c-9680-0d6f1377df8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serial processing.\n",
    "unit = spikes.query(\"(subj_sess=='U540_ses0') & (chan==18) & (unit==1)\").iloc[0]\n",
    "expmt = 'goldmine'\n",
    "game_states = ['Encoding', 'Retrieval']\n",
    "n_rois = 8\n",
    "keep_same_hem = [True]\n",
    "keep_edges=['hpc-hpc', 'hpc-ctx', 'ctx-hpc', 'ctx-ctx']\n",
    "exclude_gen_rois = ['Other']\n",
    "n_perm = 10\n",
    "data_dir = '/home1/dscho/projects/unit_activity_and_hpc_theta/data2/goldmine/nav'\n",
    "save_output = True\n",
    "overwrite = True\n",
    "\n",
    "pl_mrls = unit_lfp_comparison.unit_to_lfp_phase_locking_osc2mask(unit,\n",
    "                                                                 expmt=expmt,\n",
    "                                                                 game_states=game_states,\n",
    "                                                                 n_rois=n_rois,\n",
    "                                                                 keep_same_hem=keep_same_hem,\n",
    "                                                                 keep_edges=keep_edges,\n",
    "                                                                 exclude_gen_rois=exclude_gen_rois,\n",
    "                                                                 n_perm=n_perm,\n",
    "                                                                 data_dir=data_dir,\n",
    "                                                                 save_output=save_output,\n",
    "                                                                 overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c2698249-69e5-46d2-91ad-c1a223ef19e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel processing\n",
    "n_ops = len(_spikes)\n",
    "print('Running code for {} operations.\\n'.format(n_ops))\n",
    "with cluster_view(scheduler=\"sge\", queue=\"RAM.q\", num_jobs=np.min((n_ops, 50)), cores_per_job=4, retries=2) as view:\n",
    "    output = view.map(unit_to_lfp_phase_locking_osc2mask_parallel, [vals for (idx, vals) in _spikes.iterrows()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af014cf6-3a8c-4d02-86e2-4a65b390e07a",
   "metadata": {},
   "source": [
    "## osc2mask, matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "810f23b4-b5e8-42b2-9c44-7bd7d3e631da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_to_lfp_phase_locking_osc2mask_matched_parallel(unit):\n",
    "    import sys\n",
    "    import os\n",
    "    sys.path.append('/home1/dscho/code/projects')\n",
    "    from phase_locking import unit_lfp_comparison\n",
    "    \n",
    "    try:\n",
    "        expmt = 'goldmine'\n",
    "        game_states = ['Encoding', 'Retrieval']\n",
    "        n_rois = 8\n",
    "        keep_same_hem = [True]\n",
    "        keep_edges=['hpc-hpc', 'hpc-ctx', 'ctx-hpc', 'ctx-ctx']\n",
    "        exclude_gen_rois = ['Other']\n",
    "        match_spikes = True\n",
    "        n_perm = 1000\n",
    "        data_dir = '/home1/dscho/projects/unit_activity_and_hpc_theta/data2/goldmine/nav'\n",
    "        output_dir = os.path.join(data_dir, 'phase_locking', 'osc2mask_matched')\n",
    "        save_output = True\n",
    "        overwrite = True\n",
    "\n",
    "        _ = unit_lfp_comparison.unit_to_lfp_phase_locking_osc2mask(unit,\n",
    "                                                                   expmt=expmt,\n",
    "                                                                   game_states=game_states,\n",
    "                                                                   n_rois=n_rois,\n",
    "                                                                   keep_same_hem=keep_same_hem,\n",
    "                                                                   keep_edges=keep_edges,\n",
    "                                                                   exclude_gen_rois=exclude_gen_rois,\n",
    "                                                                   match_spikes=match_spikes,\n",
    "                                                                   n_perm=n_perm,\n",
    "                                                                   data_dir=data_dir,\n",
    "                                                                   output_dir=output_dir,\n",
    "                                                                   save_output=save_output,\n",
    "                                                                   overwrite=overwrite)\n",
    "        return None\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = ('/home1/dscho/logs/TryExceptError-unit_to_lfp_phase_locking_osc2mask_matched_parallel-{}'\n",
    "                .format('{}-{}-{}'.format(unit['subj_sess'], unit['chan'], unit['unit'])))\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "30aebd9f-c5c1-4161-adb7-4324a0d8bdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 units to process\n"
     ]
    }
   ],
   "source": [
    "# Find units to process.\n",
    "data_dir = '/home1/dscho/projects/unit_activity_and_hpc_theta/data2/goldmine/nav'\n",
    "output_dir = op.join(data_dir, 'phase_locking', 'osc2mask_matched')\n",
    "overwrite = 0\n",
    "process_idx = []\n",
    "for idx, unit in spikes.iterrows():\n",
    "    basename = '{}-{}-{}.pkl'.format(unit['subj_sess'], unit['chan'], unit['unit'])\n",
    "    if overwrite or not op.exists(op.join(output_dir, basename)):\n",
    "        process_idx.append(idx)\n",
    "        \n",
    "_spikes = spikes.loc[process_idx, :]\n",
    "print('{}/{} units to process'.format(len(_spikes), len(spikes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6a34b834-54aa-44c3-8f63-f95f0edd83a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serial processing.\n",
    "unit = spikes.query(\"(subj_sess=='U540_ses0') & (chan==18) & (unit==1)\").iloc[0]\n",
    "expmt = 'goldmine'\n",
    "game_states = ['Encoding', 'Retrieval']\n",
    "n_rois = 8\n",
    "keep_same_hem = [True]\n",
    "keep_edges=['hpc-hpc', 'hpc-ctx', 'ctx-hpc', 'ctx-ctx']\n",
    "exclude_gen_rois = ['Other']\n",
    "match_spikes = True\n",
    "n_perm = 10\n",
    "data_dir = '/home1/dscho/projects/unit_activity_and_hpc_theta/data2/goldmine/nav'\n",
    "output_dir = op.join(data_dir, 'phase_locking', 'osc2mask_matched')\n",
    "save_output = True\n",
    "overwrite = False\n",
    "\n",
    "pl_mrls = unit_lfp_comparison.unit_to_lfp_phase_locking_osc2mask(unit,\n",
    "                                                                 expmt=expmt,\n",
    "                                                                 game_states=game_states,\n",
    "                                                                 n_rois=n_rois,\n",
    "                                                                 keep_same_hem=keep_same_hem,\n",
    "                                                                 keep_edges=keep_edges,\n",
    "                                                                 exclude_gen_rois=exclude_gen_rois,\n",
    "                                                                 match_spikes=match_spikes,\n",
    "                                                                 n_perm=n_perm,\n",
    "                                                                 data_dir=data_dir,\n",
    "                                                                 output_dir=output_dir,\n",
    "                                                                 save_output=save_output,\n",
    "                                                                 overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93c5667-5634-40be-871f-17bc51e84d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running code for 402 operations.\n",
      "\n",
      "50 Engines running\n"
     ]
    }
   ],
   "source": [
    "# Parallel processing\n",
    "n_ops = len(_spikes)\n",
    "print('Running code for {} operations.\\n'.format(n_ops))\n",
    "with cluster_view(scheduler=\"sge\", queue=\"RAM.q\", num_jobs=np.min((n_ops, 50)), cores_per_job=4, retries=2) as view:\n",
    "    output = view.map(unit_to_lfp_phase_locking_osc2mask_matched_parallel, [vals for (idx, vals) in _spikes.iterrows()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ce8ba8-01a6-41e2-b7f0-72ccaa4fe14f",
   "metadata": {},
   "source": [
    "# Run YCab phase-locking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a540039-4487-4c0a-946a-b7d305172160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_to_lfp_phase_locking_ycab_parallel(unit):\n",
    "    import sys\n",
    "    import os\n",
    "    sys.path.append('/home1/dscho/code/projects')\n",
    "    from phase_locking import unit_lfp_comparison\n",
    "    \n",
    "    try:\n",
    "        expmt = 'ycab'\n",
    "        game_states = ['YCab']\n",
    "        n_rois = 8\n",
    "        keep_same_hem = [True]\n",
    "        keep_edges = ['hpc-local', 'ctx-local', 'ctx-hpc'] #['hpc-local', 'hpc-hpc', 'hpc-ctx', 'ctx-local', 'ctx-hpc', 'ctx-ctx']\n",
    "        exclude_gen_rois = ['Other']\n",
    "        mask_phase = True\n",
    "        n_perm = 10000\n",
    "        data_dir = '/home1/dscho/projects/unit_activity_and_hpc_theta/data2/ycab'\n",
    "        output_dir = os.path.join(data_dir, 'phase_locking', '10000perm')\n",
    "        save_output = True\n",
    "        overwrite = True\n",
    "\n",
    "        _ = unit_lfp_comparison.unit_to_lfp_phase_locking(unit,\n",
    "                                                          expmt=expmt,\n",
    "                                                          game_states=game_states,\n",
    "                                                          n_rois=n_rois,\n",
    "                                                          keep_same_hem=keep_same_hem,\n",
    "                                                          keep_edges=keep_edges,\n",
    "                                                          exclude_gen_rois=exclude_gen_rois,\n",
    "                                                          mask_phase=mask_phase,\n",
    "                                                          n_perm=n_perm,\n",
    "                                                          data_dir=data_dir,\n",
    "                                                          output_dir=output_dir,\n",
    "                                                          save_output=save_output,\n",
    "                                                          overwrite=overwrite)\n",
    "        return None\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = ('/home1/dscho/logs/TryExceptError-unit_to_lfp_phase_locking_ycab_parallel-{}'\n",
    "                .format('{}-{}-{}'.format(unit['subj_sess'], unit['chan'], unit['unit'])))\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd3f00d0-b568-4b34-b2a9-0c1740ac9bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 subjects and 43 sessions\n",
      "subj_df: (2696, 14)\n"
     ]
    }
   ],
   "source": [
    "# Load the subject dataframe (each row = 1 channel)\n",
    "subj_df = phlock.get_subj_df()\n",
    "idx = np.where(subj_df.query(\"(subj!='U367')\")['location'].apply(lambda x: x[-1]=='H'))[0]\n",
    "subjs = subj_df.query(\"(subj!='U367')\").iloc[idx, :]['subj'].unique()\n",
    "subj_df = subj_df.query(\"(subj=={})\".format(subjs.tolist())).reset_index(drop=True)\n",
    "\n",
    "# Fix session naming.\n",
    "subj_df['subj_sess'] = subj_df['subj_sess'].apply(lambda x: str_replace(x, {'env': 'ses', '1a': '1'}))\n",
    "subj_df['sess'] = subj_df['sess'].apply(lambda x: str_replace(x, {'env': 'ses', '1a': '1'}))\n",
    "yc_subjs = np.sort(subj_df['subj'].unique())\n",
    "yc_sessions = np.sort(subj_df['subj_sess'].unique())\n",
    "\n",
    "# Add paths to the processed LFP channels.\n",
    "data_dir = '/scratch/dscho/ycab/eeg'\n",
    "subj_df['proc_lfp_file'] = subj_df.apply(lambda x: op.join(data_dir, x['subj'], x['sess'], 'micro_lfps',\n",
    "                                                           'V-to-muV_sr1000_bandpass0.1-80_notch60',\n",
    "                                                           'CSC{}.pkl'.format(x['chan'])), axis=1)\n",
    "\n",
    "print('{} subjects and {} sessions'.format(len(yc_subjs), len(yc_sessions)))\n",
    "print('subj_df: {}'.format(subj_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c750ed54-1728-49ab-8988-e02931a9d819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spikes: (1633, 10)\n",
      "Ran in 11.9s\n",
      "spikes: (1538, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load spikes.\n",
    "fr_thresh = 0.2\n",
    "nspike_thresh = 0 # 400\n",
    "n_rois = 8\n",
    "expmt = 'ycab'\n",
    "exclude_gen_rois = ['Other']\n",
    "\n",
    "spikes = unit_lfp_comparison.load_all_unit_spikes(fr_thresh=fr_thresh,\n",
    "                                                  nspike_thresh=nspike_thresh,\n",
    "                                                  n_rois=n_rois,\n",
    "                                                  expmt=expmt)\n",
    "spikes = spikes.query(\"(roi_gen!={})\".format(exclude_gen_rois)).reset_index(drop=True)\n",
    "\n",
    "print('spikes: {}'.format(spikes.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c10d27f-2f51-4a3c-ac52-f0295e7c158a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1538/1538 units to process\n"
     ]
    }
   ],
   "source": [
    "# Find units to process.\n",
    "data_dir = '/home1/dscho/projects/unit_activity_and_hpc_theta/data2/ycab'\n",
    "output_dir = op.join(data_dir, 'phase_locking', '10000perm')\n",
    "overwrite = False\n",
    "process_idx = []\n",
    "for idx, unit in spikes.iterrows():\n",
    "    basename = '{}-{}-{}.pkl'.format(unit['subj_sess'], unit['chan'], unit['unit'])\n",
    "    if overwrite or not op.exists(op.join(output_dir, basename)):\n",
    "        process_idx.append(idx)\n",
    "        \n",
    "_spikes = spikes.loc[process_idx, :]\n",
    "print('{}/{} units to process'.format(len(_spikes), len(spikes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "68a4eac5-3078-4191-9e48-3f70bde9abd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Serial processing.\n",
    "# timer = Timer()\n",
    "\n",
    "# expmt = 'ycab'\n",
    "# game_states = ['YCab']\n",
    "# n_rois = 8\n",
    "# keep_same_hem = [True]\n",
    "# keep_edges=['hpc-local', 'hpc-hpc', 'hpc-ctx', 'ctx-local', 'ctx-hpc', 'ctx-ctx']\n",
    "# exclude_gen_rois = ['Other']\n",
    "# mask_phase = True\n",
    "# n_perm = 1000\n",
    "# data_dir = '/home1/dscho/projects/unit_activity_and_hpc_theta/data2/ycab'\n",
    "# save_output = True\n",
    "# overwrite = True\n",
    "\n",
    "# unit = spikes.iloc[0]\n",
    "# pl_mrls = unit_lfp_comparison.unit_to_lfp_phase_locking(unit,\n",
    "#                                                         expmt=expmt,\n",
    "#                                                         game_states=game_states,\n",
    "#                                                         n_rois=n_rois,\n",
    "#                                                         keep_same_hem=keep_same_hem,\n",
    "#                                                         keep_edges=keep_edges,\n",
    "#                                                         exclude_gen_rois=exclude_gen_rois,\n",
    "#                                                         mask_phase=mask_phase,\n",
    "#                                                         n_perm=n_perm,\n",
    "#                                                         data_dir=data_dir,\n",
    "#                                                         save_output=save_output,\n",
    "#                                                         overwrite=overwrite)\n",
    "\n",
    "# print(timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef79ce3-3524-42dd-aee9-2943a8f54fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running code for 1538 operations.\n",
      "\n",
      "50 Engines running\n"
     ]
    }
   ],
   "source": [
    "# Parallel processing\n",
    "n_ops = len(_spikes)\n",
    "print('Running code for {} operations.\\n'.format(n_ops))\n",
    "with cluster_view(scheduler=\"sge\", queue=\"RAM.q\", num_jobs=np.min((n_ops, 50)), cores_per_job=4, retries=2) as view:\n",
    "    output = view.map(unit_to_lfp_phase_locking_ycab_parallel, [vals for (idx, vals) in _spikes.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "4f5ababc-026a-4b58-b3f5-d1fa5090584f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pl_df: (4672, 22)\n"
     ]
    }
   ],
   "source": [
    "# Load the older phase-locking dataframe (original manuscript).\n",
    "pl_df = phlock.load_pl_df(drop_repeat_connections=False)\n",
    "pl_df['subj_sess'] = pl_df['subj_sess'].apply(lambda x: str_replace(x, {'env': 'ses', '1a': '1'}))\n",
    "pl_df.insert(pl_df.columns.tolist().index('unit_chan_ind')+1, 'unit_chan', pl_df['unit_chan_ind'] + 1)\n",
    "pl_df['subj_sess_unit'] = pl_df.apply(lambda x: '{}-{}-{}'.format(x['subj_sess'], x['unit_chan'], x['unit']), axis=1)\n",
    "drop_cols = ['sess', 'subj_unit_chan', 'unit_chan_ind', 'unit_hem',\n",
    "             'unit_roi', 'unit_is_hpc', 'lfp_hem', 'lfp_roi', 'lfp_is_hpc',\n",
    "             'same_chan', 'same_roi', 'both_hpc', 'unit_hemroi2', 'lfp_hemroi2',\n",
    "             'unit_roi2', 'lfp_roi2', 'same_roi2', 'unit_nsamp_spikes', 'spike_inds',\n",
    "             'bs_mrls', 'tl_mrls', 'bs_mrls_z', 'tl_mrls_z', 'bs_ind_z', 'tl_locked_freq_z',\n",
    "             'tl_locked_time_z', 'tl_locked_mrl_z', 'pref_phase', 'phase_offsets',\n",
    "             'pref_phase_tl_locked_time_freq_z', 'phase_offsets_tl_locked_time_freq_z',\n",
    "             'unit_roi3', 'roi', 'roi_unit_to_lfp', 'pl_freq', 'pl_strength',\n",
    "             'pl_time_shift', 'pl_latency']\n",
    "pl_df.drop(columns=[col for col in drop_cols if col in pl_df], inplace=True)\n",
    "n_rois = 6\n",
    "roi_map = spike_preproc.roi_mapping(n_rois)\n",
    "pl_df.insert(pl_df.columns.tolist().index('unit_hemroi')+1, 'unit_roi_gen', pl_df['unit_hemroi'].apply(lambda x: roi_map[x[1:]]))\n",
    "pl_df.insert(pl_df.columns.tolist().index('lfp_hemroi')+1, 'lfp_roi_gen', pl_df['lfp_hemroi'].apply(lambda x: roi_map[x[1:]]))\n",
    "freqs = np.array([2**((i/2) - 1) for i in range(16)])\n",
    "pl_df.insert(pl_df.columns.tolist().index('locked_freq_ind_z')+1, 'locked_freq_z',\n",
    "             pl_df['locked_freq_ind_z'].apply(lambda x: np.round(freqs[x], 1)))\n",
    "pl_df = (pl_df.query(\"(edge==['ctx-local', 'hpc-local', 'ctx-hpc', 'hpc-hpc'])\")\n",
    "              .sort_values(['subj_sess_unit', 'edge'])\n",
    "              .reset_index(drop=True))\n",
    "print('pl_df: {}'.format(pl_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbffb51-a26c-4fad-af1e-d2a0722286e8",
   "metadata": {},
   "source": [
    "## osc2mach, unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "8a23f621-7a95-41e2-ad54-cefdfabfea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_to_lfp_phase_locking_osc2mask_ycab_parallel(unit):\n",
    "    import sys\n",
    "    import os\n",
    "    sys.path.append('/home1/dscho/code/projects')\n",
    "    from phase_locking import unit_lfp_comparison\n",
    "    \n",
    "    try:\n",
    "        expmt = 'ycab'\n",
    "        game_states = ['YCab']\n",
    "        n_rois = 8\n",
    "        keep_same_hem = [True]\n",
    "        keep_edges = ['hpc-hpc', 'hpc-ctx', 'ctx-hpc', 'ctx-ctx']\n",
    "        exclude_gen_rois = ['Other']\n",
    "        n_perm = 1000\n",
    "        data_dir = '/home1/dscho/projects/unit_activity_and_hpc_theta/data2/ycab'\n",
    "        save_output = True\n",
    "        overwrite = True\n",
    "\n",
    "        _ = unit_lfp_comparison.unit_to_lfp_phase_locking_osc2mask(unit,\n",
    "                                                                   expmt=expmt,\n",
    "                                                                   game_states=game_states,\n",
    "                                                                   n_rois=n_rois,\n",
    "                                                                   keep_same_hem=keep_same_hem,\n",
    "                                                                   keep_edges=keep_edges,\n",
    "                                                                   exclude_gen_rois=exclude_gen_rois,\n",
    "                                                                   n_perm=n_perm,\n",
    "                                                                   data_dir=data_dir,\n",
    "                                                                   save_output=save_output,\n",
    "                                                                   overwrite=overwrite)\n",
    "        return None\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = ('/home1/dscho/logs/TryExceptError-unit_to_lfp_phase_locking_osc2mask_ycab_parallel-{}'\n",
    "                .format('{}-{}-{}'.format(unit['subj_sess'], unit['chan'], unit['unit'])))\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "3188d9f4-9b3d-4b40-a15d-bcb29f70b041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1315 units to process\n"
     ]
    }
   ],
   "source": [
    "# Find units to process.\n",
    "data_dir = '/home1/dscho/projects/unit_activity_and_hpc_theta/data2/ycab'\n",
    "output_dir = op.join(data_dir, 'phase_locking', 'osc2mask')\n",
    "overwrite = 0\n",
    "process_idx = []\n",
    "for idx, unit in spikes.iterrows():\n",
    "    basename = '{}-{}-{}.pkl'.format(unit['subj_sess'], unit['chan'], unit['unit'])\n",
    "    if overwrite or not op.exists(op.join(output_dir, basename)):\n",
    "        process_idx.append(idx)\n",
    "        \n",
    "_spikes = spikes.loc[process_idx, :]\n",
    "print('{}/{} units to process'.format(len(_spikes), len(spikes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead0e63-dd21-4eeb-bf65-f7d97cc4ff20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running code for 1315 operations.\n",
      "\n",
      "6 Engines running\n"
     ]
    }
   ],
   "source": [
    "# Parallel processing\n",
    "n_ops = len(_spikes)\n",
    "print('Running code for {} operations.\\n'.format(n_ops))\n",
    "with cluster_view(scheduler=\"sge\", queue=\"RAM.q\", num_jobs=np.min((n_ops, 75)), cores_per_job=4, retries=2) as view:\n",
    "    output = view.map(unit_to_lfp_phase_locking_osc2mask_ycab_parallel, [vals for (idx, vals) in _spikes.iterrows()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6eea22-8259-42e4-a22e-5eb8b3b70c32",
   "metadata": {},
   "source": [
    "## osc2mask, matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "236f1289-21bf-406c-8fbd-37dcdd60a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_to_lfp_phase_locking_osc2mask_ycab_matched_parallel(unit):\n",
    "    import sys\n",
    "    import os\n",
    "    sys.path.append('/home1/dscho/code/projects')\n",
    "    from phase_locking import unit_lfp_comparison\n",
    "    \n",
    "    try:\n",
    "        expmt = 'ycab'\n",
    "        game_states = ['YCab']\n",
    "        n_rois = 8\n",
    "        keep_same_hem = [True]\n",
    "        keep_edges = ['hpc-hpc', 'hpc-ctx', 'ctx-hpc', 'ctx-ctx']\n",
    "        exclude_gen_rois = ['Other']\n",
    "        match_spikes = True\n",
    "        n_perm = 1000\n",
    "        data_dir = '/home1/dscho/projects/unit_activity_and_hpc_theta/data2/ycab'\n",
    "        output_dir = os.path.join(data_dir, 'phase_locking', 'osc2mask_matched')\n",
    "        save_output = True\n",
    "        overwrite = True\n",
    "\n",
    "        _ = unit_lfp_comparison.unit_to_lfp_phase_locking_osc2mask(unit,\n",
    "                                                                   expmt=expmt,\n",
    "                                                                   game_states=game_states,\n",
    "                                                                   n_rois=n_rois,\n",
    "                                                                   keep_same_hem=keep_same_hem,\n",
    "                                                                   keep_edges=keep_edges,\n",
    "                                                                   exclude_gen_rois=exclude_gen_rois,\n",
    "                                                                   match_spikes=match_spikes,\n",
    "                                                                   n_perm=n_perm,\n",
    "                                                                   data_dir=data_dir,\n",
    "                                                                   output_dir=output_dir,\n",
    "                                                                   save_output=save_output,\n",
    "                                                                   overwrite=overwrite)\n",
    "        return None\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = ('/home1/dscho/logs/TryExceptError-unit_to_lfp_phase_locking_osc2mask_ycab_matched_parallel-{}'\n",
    "                .format('{}-{}-{}'.format(unit['subj_sess'], unit['chan'], unit['unit'])))\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be0ad842-f545-4885-84d2-d8aa7bed4941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1538 units to process\n"
     ]
    }
   ],
   "source": [
    "# Find units to process.\n",
    "data_dir = '/home1/dscho/projects/unit_activity_and_hpc_theta/data2/ycab'\n",
    "output_dir = op.join(data_dir, 'phase_locking', 'osc2mask_matched')\n",
    "overwrite = 0\n",
    "process_idx = []\n",
    "for idx, unit in spikes.iterrows():\n",
    "    basename = '{}-{}-{}.pkl'.format(unit['subj_sess'], unit['chan'], unit['unit'])\n",
    "    if overwrite or not op.exists(op.join(output_dir, basename)):\n",
    "        process_idx.append(idx)\n",
    "        \n",
    "_spikes = spikes.loc[process_idx, :]\n",
    "print('{}/{} units to process'.format(len(_spikes), len(spikes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8688dc24-0986-40ad-8f24-b99664c16818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running code for 1538 operations.\n",
      "\n",
      "7 Engines running\n"
     ]
    }
   ],
   "source": [
    "# Parallel processing\n",
    "n_ops = len(_spikes)\n",
    "print('Running code for {} operations.\\n'.format(n_ops))\n",
    "with cluster_view(scheduler=\"sge\", queue=\"RAM.q\", num_jobs=np.min((n_ops, 75)), cores_per_job=4, retries=2) as view:\n",
    "    output = view.map(unit_to_lfp_phase_locking_osc2mask_ycab_matched_parallel, [vals for (idx, vals) in _spikes.iterrows()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bb6bc0-0134-4d14-8696-ce2735242e71",
   "metadata": {},
   "source": [
    "# Save YCab event_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "02d0b6ff-cc5a-4c0a-9eca-bb765362a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save event_times for each yellow cab session.\n",
    "save_output = True\n",
    "overwrite = False\n",
    "\n",
    "timer = Timer()\n",
    "\n",
    "for subj_sess in yc_sessions:\n",
    "    # Load the event_times dataframe if it exists.\n",
    "    output_f = op.join('/home1/dscho/projects/unit_activity_and_hpc_theta/data2/ycab/events',\n",
    "                       '{}-event_times.pkl'.format(subj_sess))\n",
    "    if op.exists(output_f) and not overwrite:\n",
    "        event_times = dio.open_pickle(output_f)\n",
    "        continue\n",
    "\n",
    "    # Load EEG for each channel and event.\n",
    "    subj, sess = subj_sess.split('_')\n",
    "    mont = (subj_df.query(\"(subj_sess=='{}')\".format(subj_sess))\n",
    "                   .groupby(['location'])['chan']\n",
    "                   .apply(lambda x: np.array([int(chan) for chan in x])))\n",
    "    roi = mont.keys()[0]\n",
    "    regions = [roi]\n",
    "    sr = 1000\n",
    "    session_cut = 60000 # cut this many samples from start and end of the session\n",
    "    event_len = 30000\n",
    "    buffer = 2500\n",
    "    l_freq = 0.1\n",
    "    h_freq = 80\n",
    "    notch_freqs = [60]\n",
    "    chan_exclusion_thresh = 2\n",
    "    output_dir = op.join('/scratch/dscho/ycab/eeg', subj, sess, 'micro_lfps',\n",
    "                         'V-to-muV_sr1000_bandpass0.1-80_notch60')\n",
    "    verbose = False\n",
    "    \n",
    "    time_eeg = eeg_preproc.load_time_eeg(subj_sess,\n",
    "                                         mont=mont,\n",
    "                                         regions=regions,\n",
    "                                         l_freq=l_freq,\n",
    "                                         h_freq=h_freq,\n",
    "                                         notch_freqs=notch_freqs,\n",
    "                                         chan_exclusion_thresh=chan_exclusion_thresh,\n",
    "                                         verbose=verbose,\n",
    "                                         output_dir=output_dir)\n",
    "    time_eeg = time_eeg[roi]\n",
    "    \n",
    "    # Break the session into non-overlapping events.\n",
    "    chans = time_eeg.index.values\n",
    "    split_every = int(event_len)\n",
    "    start_cut = time_eeg.iloc[:, session_cut:time_eeg.shape[1]-session_cut].values.shape[1] % split_every\n",
    "    n_splits = int(time_eeg.iloc[:, session_cut+start_cut:-session_cut].shape[1] / split_every)\n",
    "    start_stop = aop.rolling_window(np.arange(session_cut+start_cut,\n",
    "                                              time_eeg.shape[1]-session_cut+1,\n",
    "                                              split_every), 2)\n",
    "    \n",
    "    # Create the event_times dataframe.\n",
    "    event_times = []\n",
    "    for iTrial, (start, stop) in enumerate(start_stop):\n",
    "        event_times.append([iTrial+1, 'YCab', start, stop])\n",
    "    cols = ['trial', 'gameState', 'start_time', 'stop_time']\n",
    "    event_times = pd.DataFrame(event_times, columns=cols)\n",
    "    \n",
    "    # Save the dataframe.\n",
    "    if save_output:\n",
    "        dio.save_pickle(event_times, output_f)\n",
    "        \n",
    "print(timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cdd2dd-baa0-43d1-b337-2020c553eb0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memlab",
   "language": "python",
   "name": "memlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
