{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ols_results_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import sys\n",
    "import os.path as op\n",
    "import copy\n",
    "from time import time\n",
    "from collections import OrderedDict as od\n",
    "from glob import glob\n",
    "import itertools\n",
    "import warnings\n",
    "from importlib import reload\n",
    "# from cluster_helper.cluster import cluster_view\n",
    "\n",
    "# Scientific\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "# Stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.utils.fixes import loguniform\n",
    "import scipy.stats as stats\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import minmax_scale, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import patsy\n",
    "\n",
    "# Plots\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.patches as patches\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "mpl.rcParams['grid.linewidth'] = 0.1\n",
    "mpl.rcParams['grid.alpha'] = 0.75\n",
    "mpl.rcParams['lines.linewidth'] = 1\n",
    "mpl.rcParams['lines.markersize'] = 3\n",
    "mpl.rcParams['xtick.labelsize'] = 12\n",
    "mpl.rcParams['ytick.labelsize'] = 12\n",
    "mpl.rcParams['xtick.major.width'] = 0.8\n",
    "mpl.rcParams['ytick.major.width'] = 0.8\n",
    "colors = ['1f77b4', 'd62728', '2ca02c', 'ff7f0e', '9467bd', \n",
    "          '8c564b', 'e377c2', '7f7f7f', 'bcbd22', '17becf']\n",
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler('color', colors)\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.formatter.offset_threshold'] = 2\n",
    "mpl.rcParams['axes.labelsize'] = 14\n",
    "mpl.rcParams['axes.labelpad'] = 8\n",
    "mpl.rcParams['axes.titlesize'] = 16\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['axes.axisbelow'] = True\n",
    "mpl.rcParams['legend.loc'] = 'upper right'\n",
    "mpl.rcParams['legend.fontsize'] = 14\n",
    "mpl.rcParams['legend.frameon'] = False\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "mpl.rcParams['figure.titlesize'] = 16\n",
    "mpl.rcParams['figure.figsize'] = (10, 4) \n",
    "mpl.rcParams['figure.subplot.wspace'] = 0.25 \n",
    "mpl.rcParams['figure.subplot.hspace'] = 0.25 \n",
    "mpl.rcParams['font.sans-serif'] = ['Helvetica']\n",
    "mpl.rcParams['savefig.format'] = 'pdf'\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "# Personal\n",
    "sys.path.append('/home1/cjmac/code/general')\n",
    "sys.path.append('/home1/cjmac/code/projects/manning_replication')\n",
    "sys.path.append('/home1/cjmac/code/projects')\n",
    "import data_io as dio\n",
    "import array_operations as aop\n",
    "from helper_funcs import *\n",
    "from eeg_plotting import plot_trace, plot_trace2\n",
    "from time_cells import spike_sorting, spike_preproc, events_preproc, events_proc, time_bin_analysis, remapping, pop_decoding, time_cell_plots\n",
    "from goldmine_replay import place_cells\n",
    "\n",
    "font = {'tick': 12,\n",
    "        'label': 14,\n",
    "        'annot': 12,\n",
    "        'fig': 16}\n",
    "\n",
    "# Colors\n",
    "n = 4\n",
    "c = 2\n",
    "colors = [sns.color_palette('Blues', n)[c], \n",
    "          sns.color_palette('Reds', n)[c], \n",
    "          sns.color_palette('Greens', n)[c],\n",
    "          sns.color_palette('Purples', n)[c],\n",
    "          sns.color_palette('Oranges', n)[c],\n",
    "          sns.color_palette('Greys', n)[c],\n",
    "          sns.color_palette('YlOrBr', n+3)[c],\n",
    "          'k']\n",
    "cmap = sns.palettes.blend_palette((colors[0], \n",
    "                                   'w',\n",
    "                                   colors[1]), 501)\n",
    "\n",
    "colws = od([('1', 6.55),\n",
    "            ('2-1/2', 3.15),\n",
    "            ('2-1/3', 2.1),\n",
    "            ('2-2/3', 4.2),\n",
    "            ('3', 2.083),\n",
    "            ('4', 1.525),\n",
    "            ('5', 1.19),\n",
    "            ('6', 0.967),\n",
    "            (1, 2.05),\n",
    "            (2, 3.125),\n",
    "            (3, 6.45),\n",
    "            ('nat1w', 3.50394),\n",
    "            ('nat2w', 7.20472),\n",
    "            ('natl', 9.72441)])\n",
    "\n",
    "data_dir = '/home1/cjmac/projects/time_cells'\n",
    "proj_dir = '/home1/cjmac/projects/time_cells'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 subjects, 1 sessions\n"
     ]
    }
   ],
   "source": [
    "# Get sessions.\n",
    "sessions = np.unique([op.basename(f).split('-')[0] \n",
    "                      for f in glob(op.join(data_dir, 'analysis', 'events', '*-Events.pkl'))])\n",
    "print('{} subjects, {} sessions'.format(len(np.unique([x.split('_')[0] for x in sessions])), len(sessions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ols_delay_parallel(subj_sess_unit):\n",
    "    import sys\n",
    "    import os\n",
    "    sys.path.append('/home1/cjmac/code/projects')\n",
    "    from time_cells import time_bin_analysis\n",
    "    \n",
    "    proj_dir = '/home1/cjmac/projects/time_cells'\n",
    "    n_perm = 10000\n",
    "    \n",
    "    try:\n",
    "        mod_pairs, ols_weights = time_bin_analysis.run_ols_delay(subj_sess_unit,\n",
    "                                                                 n_perm=1000,\n",
    "                                                                 alpha=0.05,\n",
    "                                                                 save_output=True,\n",
    "                                                                 overwrite=False)\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = '/home1/cjmac/logs/TryExceptError-run_ols_delay_parallel-{}'.format(subj_sess_unit)\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get neurons to process.\n",
    "fpath = op.join(proj_dir, 'analysis', 'unit_to_behav_10k', '{}-Delay1_Delay2-ols_model_pairs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8.4.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_spikes = pop_decoding.load_pop_spikes()\n",
    "neurons = [neuron for neuron in pop_spikes.neurons if not op.exists(fpath.format(neuron))]\n",
    "print('{} neurons to process'.format(len(neurons)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel processing\n",
    "n_ops = len(neurons)\n",
    "print('Running code for {} operations.\\n'.format(n_ops))\n",
    "with cluster_view(scheduler=\"sge\", queue=\"RAM.q\", num_jobs=np.min((n_ops, 100)), cores_per_job=1) as view:\n",
    "    output = view.map(run_ols_delay_parallel, neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_sess_unit = 'U532_ses0-21-1' # 'U527_ses0-58-2' # 'U518_ses0-73-1'\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "mod_pairs, ols_weights = time_bin_analysis.run_ols_delay(subj_sess_unit)\n",
    "\n",
    "print('Done in {:.1f}s'.format(time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load mod_pairs, ols_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed OLS files.\n",
    "mod_pairs_globstr = op.join(proj_dir, 'analysis', 'unit_to_behav_1000perm', '*Delay1_Delay2-ols_model_pairs.pkl')\n",
    "ols_weights_globstr = op.join(proj_dir, 'analysis', 'unit_to_behav_1000perm', '*Delay1_Delay2-ols_weights.pkl')\n",
    "mod_pairs = pd.concat([dio.open_pickle(f) for f in glob(mod_pairs_globstr)]).reset_index(drop=True)\n",
    "ols_weights = pd.concat([dio.open_pickle(f) for f in glob(ols_weights_globstr)]).reset_index(drop=True)\n",
    "\n",
    "# Drop rows.\n",
    "drop_red = ['full-time,gameState:time']\n",
    "mod_pairs = mod_pairs.query(\"(red!={})\".format(drop_red)).reset_index(drop=True)\n",
    "\n",
    "# Add columns.\n",
    "_map = {'full-gameState': 'gameState',\n",
    "        'full-time': 'time',\n",
    "        'full-gameState:time': 'gameState:time'}\n",
    "testvar_cat = pd.CategoricalDtype(['gameState', 'time', 'gameState:time'],\n",
    "                                  ordered=True)\n",
    "mod_pairs.insert(4, 'testvar', mod_pairs['red'].apply(lambda x: _map[x]))\n",
    "mod_pairs['testvar'] = mod_pairs['testvar'].astype(testvar_cat)\n",
    "\n",
    "print('mod_pairs: {}'.format(mod_pairs.shape))\n",
    "print('ols_weights: {}'.format(ols_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FDR correct across all neurons.\n",
    "alpha = 0.05\n",
    "sig_col = 'sig'\n",
    "\n",
    "mod_pairs['sig01'] = ''\n",
    "mod_pairs['sig_fdr'] = ''\n",
    "for testvar in mod_pairs['testvar'].unique():\n",
    "    pvals = mod_pairs.loc[mod_pairs['testvar']==testvar, 'emp_pval']\n",
    "    sig_fdr = sm.stats.multipletests(pvals, alpha, method='fdr_tsbky')[0]\n",
    "    pvals_fdr = sm.stats.multipletests(pvals, alpha, method='fdr_tsbky')[1]\n",
    "    \n",
    "    mod_pairs.loc[mod_pairs['testvar']==testvar, 'sig01'] = pvals < 0.01\n",
    "    mod_pairs.loc[mod_pairs['testvar']==testvar, 'pvals_fdr'] = pvals_fdr\n",
    "    mod_pairs.loc[mod_pairs['testvar']==testvar, 'sig_fdr'] = sig_fdr\n",
    "\n",
    "sig_cells = od([])\n",
    "for testvar in mod_pairs['testvar'].unique():\n",
    "    sig_cells[testvar] = mod_pairs.query(\"(testvar=='{}') & ({}==True)\".format(testvar, sig_col))['subj_sess_unit'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testvars = ['gameState', 'time', 'gameState:time']\n",
    "\n",
    "count_sig = od([])\n",
    "count_all = od([])\n",
    "n_cells = mod_pairs['subj_sess_unit'].unique().size\n",
    "pvals_unc = od([])\n",
    "for testvar in testvars:\n",
    "    n_sig = len(sig_cells[testvar])\n",
    "    binom_p = stats.binom_test(n_sig,\n",
    "                               n_cells,\n",
    "                               p=0.05,\n",
    "                               alternative='greater')\n",
    "    count_sig[testvar] = n_sig\n",
    "    count_all[testvar] = n_cells\n",
    "    pvals_unc[testvar] = binom_p\n",
    "\n",
    "# Bonferroni-Holm correct\n",
    "pvals_corr = sm.stats.multipletests(list(pvals_unc.values()), method='holm')[1]\n",
    "\n",
    "for iTest, testvar in enumerate(pvals_unc):\n",
    "    print('{:>19}'.format(testvar),\n",
    "          '{:>3}/{:>3} {:>6.1%} '.format(count_sig[testvar], count_all[testvar], (1. * count_sig[testvar]) / count_all[testvar]),\n",
    "          '{:.10f}{:>1}'.format(pvals_unc[testvar], '*' if (pvals_unc[testvar] < alpha) else ''),\n",
    "          '{:.10f}{:>1}'.format(pvals_corr[iTest], '*' if (pvals_corr[iTest] < alpha) else ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many time cells per subject?\n",
    "aop.unique([x.split('_')[0] for x in sig_cells['time']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many delay category cells per subject?\n",
    "aop.unique([x.split('_')[0] for x in sig_cells['gameState']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_pairs.groupby('testvar', observed=True).agg({'sig': count_pct,\n",
    "                                                 'sig01': count_pct,\n",
    "                                                 'sig_fdr': count_pct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mod_pairs.query(\"(sig==True)\")\n",
    "          .groupby('testvar', observed=True)\n",
    "          .agg({'subj_sess_unit': len,\n",
    "                'z_lr': [mean_sem, median_q]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = (ols_weights.query(\"(subj_sess_unit=={}) & (factor=='gameState')\".format(sig_cells['gameState']))\n",
    "                  .groupby(\"subj_sess_unit\")['z_weight']\n",
    "                  .apply(lambda x: 1 * x))\n",
    "print(count_pct(_df>0) + ' neurons with a main effect of delay category fire more in Delay1 than Delay2', \n",
    "      '(p = {:.6f}, binomial test)'.format(stats.binom_test(np.count_nonzero(_df>0), len(_df), 0.5)))\n",
    "plt.plot(_df.sort_values().values, marker='.', linewidth=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_name = 'full'\n",
    "factor = 'time'\n",
    "weight_col = 'z_weight'\n",
    "\n",
    "qry = \"(subj_sess_unit=={}) & (model=='{}') & (factor=='{}')\"\n",
    "levels = ols_weights.query(qry.format(sig_cells[factor], mod_name, factor))['level'].drop_duplicates().values\n",
    "\n",
    "_df = (ols_weights.query(qry.format(sig_cells[factor], mod_name, factor))\n",
    "                  .groupby(['subj_sess_unit', 'model', 'factor'], sort=False)\n",
    "                  .agg({weight_col: [lambda x: levels[np.argmax(np.abs(x))], lambda x: np.array(x)[np.argmax(np.abs(x))]]})\n",
    "                  .reset_index())\n",
    "_df.columns = ['subj_sess_unit', 'model', 'factor', 'level', weight_col]\n",
    "_df['level'] = _df['level'].astype(pd.CategoricalDtype(levels, ordered=True)) \n",
    "\n",
    "print('{} – {}; P = {:.6f}, binomial test'.format(factor,\n",
    "                                                  count_pct(_df[weight_col]>0),\n",
    "                                                  stats.binom_test(np.count_nonzero(_df[weight_col]>0), len(_df), 0.5)),\n",
    "      end='\\n'*2)\n",
    "(_df.groupby('level', observed=False)\n",
    "    .agg({'subj_sess_unit' : lambda x: '{:>2}/{:>2} ({:.1%})'.format(len(x), len(_df), len(x)/len(_df)),\n",
    "          weight_col       : [lambda x: mean_sem(np.abs(x)), lambda x: count_pct(x>0)]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are time cells over-represented in each third of the delay?\n",
    "x = [67, 17, 15]\n",
    "bins = [3, 4, 3]\n",
    "n = 457\n",
    "alpha = 0.05\n",
    "\n",
    "pvals = [stats.binom_test(x[i], n, 0.05 * (bins[i]/10)) for i in range(len(x))]\n",
    "pvals_corr = sm.stats.multipletests(pvals, alpha, method='holm')[1]\n",
    "\n",
    "print(pvals, pvals_corr, pvals_corr<alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = ['icpt', 'gameState', 'time', 'gameState:time']\n",
    "ols_weights['factor'] = ols_weights['factor'].astype(pd.CategoricalDtype(factors, ordered=True))\n",
    "\n",
    "levels = ['icpt', 'gameState_Delay1'] + ['time_{}'.format(iTime) for iTime in range(1, 11)] + ['gameState_Delay1:time_{}'.format(iTime) for iTime in range(1, 11)]\n",
    "ols_weights['level'] = ols_weights['level'].astype(pd.CategoricalDtype(levels, ordered=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _merge_dfs():\n",
    "    level = 'level-{}'.format(factor)\n",
    "    level_weight = level + '-z_weight'\n",
    "    if level in mod_pairs:\n",
    "        mod_pairs.drop(columns=level, inplace=True)\n",
    "    if level_weight in mod_pairs:\n",
    "        mod_pairs.drop(columns=level_weight, inplace=True)\n",
    "        \n",
    "    return (pd.merge(mod_pairs, _df.rename(columns={'model': 'full', 'factor': 'testvar'}),\n",
    "                     on=['subj_sess_unit', 'full', 'testvar'], how='left')\n",
    "            .rename(columns={'level': level, 'z_weight': level_weight}))\n",
    "\n",
    "# How many cells preferentially encode each level\n",
    "# of a given variable of interest?\n",
    "mod_name = 'full'\n",
    "factor = 'time'\n",
    "merge_mod_pairs = True\n",
    "\n",
    "qry = \"(subj_sess_unit=={}) & (model=='{}') & (factor=='{}')\"\n",
    "levels = ols_weights.query(qry.format(sig_cells[factor], mod_name, factor))['level'].drop_duplicates().values\n",
    "\n",
    "_df = (ols_weights.query(qry.format(sig_cells[factor], mod_name, factor))\n",
    "                  .groupby(['subj_sess_unit', 'model', 'factor'], sort=False, observed=True)\n",
    "                  .agg({'z_weight': [lambda x: levels[np.argmax(np.abs(x))], lambda x: np.array(x)[np.argmax(np.abs(x))]]})\n",
    "                  .reset_index())\n",
    "_df.columns = ['subj_sess_unit', 'model', 'factor', 'level', 'z_weight']\n",
    "_df['level'] = _df['level'].astype(pd.CategoricalDtype(levels, ordered=True))\n",
    "if merge_mod_pairs:\n",
    "    mod_pairs = _merge_dfs()\n",
    "    \n",
    "print('{} – {}; P = {:.6f}, binomial test'.format(factor,\n",
    "                                                  count_pct(_df['z_weight']>0),\n",
    "                                                  stats.binom_test(np.count_nonzero(_df['z_weight']>0), len(_df), 0.5)),\n",
    "      end='\\n'*2)\n",
    "(_df.groupby('level', observed=True)\n",
    "    .agg({'subj_sess_unit' : lambda x: '{:>2}/{:>2} ({:.1%})'.format(len(x), len(_df), len(x)/len(_df)),\n",
    "          'z_weight'       : [lambda x: mean_sem(np.abs(x)), lambda x: count_pct(x>0)]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_pairs.query(\"(full=='full') & (testvar=='time') & (sig==True)\").sort_values('z_lr', ascending=0).iloc[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_sess_unit = 'U532_ses0-10-1'\n",
    "\n",
    "display(mod_pairs.query(\"(subj_sess_unit=='{}')\".format(subj_sess_unit)))\n",
    "display(ols_weights.query(\"(model=='full') & (subj_sess_unit=='{}')\".format(subj_sess_unit))\n",
    "                   .sort_values(['factor', 'level'], ascending=[True, True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(time_bin_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find time fields for all significant gameState:time cells.\n",
    "save_output = 1\n",
    "overwrite = 0\n",
    "verbose = False\n",
    "smooth = 1\n",
    "n_perm = 1000\n",
    "thresh = 1.96\n",
    "max_skips = 1\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "for subj_sess_unit in sig_cells['time']:\n",
    "    output = time_bin_analysis.bootstrap_time_fields(subj_sess_unit,\n",
    "                                                     game_states=['Delay1', 'Delay2'],\n",
    "                                                     smooth=smooth,\n",
    "                                                     n_perm=n_perm,\n",
    "                                                     thresh=thresh,\n",
    "                                                     max_skips=max_skips,\n",
    "                                                     save_output=save_output,\n",
    "                                                     overwrite=overwrite,\n",
    "                                                     verbose=verbose)\n",
    "    \n",
    "print('Done in {:.1f}s'.format(time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load time field results.\n",
    "files = glob(op.join(proj_dir, 'analysis', 'time_fields', '*Delay1_Delay2-smooth1*.pkl'))\n",
    "# files = glob(op.join(proj_dir, 'analysis', 'time_fields', '*Delay1_Delay2-smooth0*.pkl'))\n",
    "\n",
    "time_fields = pd.concat([dio.open_pickle(f)['time_fields'] for f in files]).reset_index(drop=True)\n",
    "\n",
    "print('time_fields:', time_fields.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_fields.query(\"(gameState=='Delay1Delay2')\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} time cells with a time_field'.format(count_pct(np.isin(sig_cells['time'],\n",
    "          time_fields.query(\"(gameState=='Delay1Delay2')\")['subj_sess_unit'].unique()))),\n",
    "      '{} time cells with a positive time_field'.format(count_pct(np.isin(sig_cells['time'],\n",
    "          time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos')\")['subj_sess_unit'].unique()))),\n",
    "      '{} time cells with a negative time_field'.format(count_pct(np.isin(sig_cells['time'],\n",
    "          time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='neg')\")['subj_sess_unit'].unique()))),\n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_sess_unit = 'U518_ses0-16-1'\n",
    "\n",
    "mod_pairs.query(\"(subj_sess_unit=='{}')\".format(subj_sess_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_sess_unit = 'U518_ses0-16-1'\n",
    "\n",
    "time_fields.query(\"(subj_sess_unit=='{}')\".format(subj_sess_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos')\")\n",
    "            .groupby('subj_sess_unit')\n",
    "            .agg({'peak_z': np.max,\n",
    "                  'field_peak': list,\n",
    "                  'field_size': list})\n",
    "            .sort_values('peak_z'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many positive time fields does each time cell have?\n",
    "_df = aop.unique(time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos')\").groupby('subj_sess_unit').size(),\n",
    "                 sort=False).reset_index()\n",
    "_df.columns = ['fields', 'count']\n",
    "print('{} time fields/neuron'.format(mean_sem(time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos')\").groupby('subj_sess_unit').size())))\n",
    "print('{} time fields/neuron'.format(median_q(time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos')\").groupby('subj_sess_unit').size())))\n",
    "print('{} neurons have only 1 time field'\n",
    "      .format(np.sum(time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos')\").groupby('subj_sess_unit').size()==1)))\n",
    "      \n",
    "plt.close()\n",
    "sns.barplot(x='fields', y='count', data=_df, color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos')\").groupby('subj_sess_unit').size()==1)[0]\n",
    "_neurons = time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos')\").groupby('subj_sess_unit').size().index[idx].tolist()\n",
    "_df = (time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos') & (subj_sess_unit=={})\".format(_neurons))\n",
    "                  .groupby('field_size').size()\n",
    "                  .reset_index()\n",
    "                  .rename(columns={0: 'count'}))\n",
    "plt.close()\n",
    "sns.barplot(x='field_size', y='count', data=_df, color='k')\n",
    "\n",
    "print(mean_sd(time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos') & (subj_sess_unit=={})\".format(_neurons))['field_size'] / 2))\n",
    "print(median_q(time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos') & (subj_sess_unit=={})\".format(_neurons))['field_size'] / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over what duration is each time field firing above the mean?\n",
    "_df = time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos')\").groupby('field_size').size().reset_index()\n",
    "_df.columns = ['field_size', 'count']\n",
    "print('{}s field size'.format(mean_sem(time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos')\")['field_size'] / 2)))\n",
    "print('{}s field size'.format(median_q(time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos')\")['field_size'] / 2)))\n",
    "\n",
    "plt.close()\n",
    "sns.barplot(x='field_size', y='count', data=_df, color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_df = time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos')\").groupby('field_peak').size().reset_index()\n",
    "_df.columns = ['field_peak', 'count']\n",
    "print('{} peak firing index'.format(mean_sem(time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos')\")['field_peak'])))\n",
    "print('{} peak firing index'.format(median_q(time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos')\")['field_peak'])))\n",
    "\n",
    "plt.close()\n",
    "sns.barplot(x='field_peak', y='count', data=_df, color='#7ccaa5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='neg')\").groupby('field_peak').size().reset_index()\n",
    "_df.columns = ['field_peak', 'count']\n",
    "print('{} peak firing index'.format(mean_sem(time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='neg')\")['field_peak'])))\n",
    "print('{} peak firing index'.format(median_q(time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='neg')\")['field_peak'])))\n",
    "\n",
    "plt.close()\n",
    "sns.barplot(x='field_peak', y='count', data=_df, color='#e55749')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_fields.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('field_peak ~ field_size:', \n",
    "      stats.pearsonr(time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos')\")['field_peak'],\n",
    "                     time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos')\")['field_size']))\n",
    "print('field_peak ~ peak_z:', \n",
    "      stats.pearsonr(time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos')\")['field_peak'],\n",
    "                     time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos')\")['peak_z']))\n",
    "print('field_peak ~ mean_z:', \n",
    "      stats.pearsonr(time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos')\")['field_peak'],\n",
    "                     time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos')\")['mean_z']))\n",
    "\n",
    "formula = 'field_peak ~ field_size * mean_z'\n",
    "mod = ols(formula, data=time_fields.query(\"(gameState=='Delay1Delay2') & (field_type=='pos')\"))\n",
    "fit = mod.fit()\n",
    "print(fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timebin = 9\n",
    "_params = ols_weights.set_index('level')['weight']\n",
    "\n",
    "delay1_spikes = event_spikes.get_spike_mat(neuron, 'Delay1', column='time_step').values.astype(float)\n",
    "delay2_spikes = event_spikes.get_spike_mat(neuron, 'Delay2', column='time_step').values.astype(float)\n",
    "print(((delay1_spikes + delay2_spikes) / 2).mean(),\n",
    "        delay1_spikes.mean(),\n",
    "        delay2_spikes.mean())\n",
    "print(_params['icpt'],\n",
    "      _params['icpt'] + _params[Xycols['gameState'][0]],\n",
    "      _params['icpt'] - _params[Xycols['gameState'][0]])\n",
    "print('Delay1, timebin {}:'.format(timebin+1), delay1_spikes[:, timebin].mean())\n",
    "print('Delay2, timebin {}:'.format(timebin+1), delay2_spikes[:, timebin].mean())\n",
    "print('Delay1, timebin {}:'.format(timebin+1),\n",
    "      _params['icpt'] + _params['gameState_Delay1'] + _params['time_{}'.format(timebin+1)] + _params['gameState_Delay1:time_{}'.format(timebin+1)])\n",
    "print('Delay1, timebin {}:'.format(timebin+1), \n",
    "      _params['icpt'] - _params['gameState_Delay1'] + _params['time_{}'.format(timebin+1)] - _params['gameState_Delay1:time_{}'.format(timebin+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ols_mods['full'].fit().params\n",
    "n_params = 0\n",
    "for k, v in Xycols.items():\n",
    "    print(k, len(v))\n",
    "    if k != 'neuron':\n",
    "        n_params += len(v)\n",
    "print('{} parameters total'.format(n_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mod_name, mod in ols_mods.items():\n",
    "    print(mod_name, mod.fit().llf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay1_spikes = event_spikes.get_spike_mat(neuron, 'Delay1', column='time_step').values.astype(float)\n",
    "delay2_spikes = event_spikes.get_spike_mat(neuron, 'Delay2', column='time_step').values.astype(float)\n",
    "print(((delay1_spikes + delay2_spikes) / 2).mean(),\n",
    "        delay1_spikes.mean(),\n",
    "        delay2_spikes.mean())\n",
    "print(params['Intercept'],\n",
    "      params['Intercept'] + params[Xycols['gameState'][0]],\n",
    "      params['Intercept'] - params[Xycols['gameState'][0]])\n",
    "print(delay1_spikes[:, 3].mean(),\n",
    "      params['Intercept'] + params[Xycols['gameState'][0]] + params[Xycols['time'][3]] + params[Xycols['gameState:time'][3]])\n",
    "print(delay2_spikes[:, 3].mean(),\n",
    "      params['Intercept'] - params[Xycols['gameState'][0]] + params[Xycols['time'][3]] - params[Xycols['gameState:time'][3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k:v for k, v in Xycols.items() if k!='neuron'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mod_name, mod in ols_mods.items():\n",
    "    print(mod_name, mod.fit().llf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy['gameState_Delay1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_mods['full'].fit().params[Xycols['gameState_x_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ols_mods['full'].fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5.7303+0.8273+0.3606"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mod, fit in mod_fits.items():\n",
    "    print(mod, fit.fit().llf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ols_time_formulas(neuron, full_mod):\n",
    "    \"\"\"Define model formulas for single-unit to behavior comparisons.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    neuron : str\n",
    "        e.g. '5-2' would be channel 5, unit 2\n",
    "    \"\"\"\n",
    "    # Get the expanded predictor matrix of deviation-coded parameters,\n",
    "    # and add on the dependent column.\n",
    "    Xy = pd.concat((pd.Series(full_mod.endog, name=neuron),\n",
    "                    pd.DataFrame(full_mod.exog, columns=full_mod.exog_names)),\n",
    "                   axis=1)\n",
    "    Xy.drop(columns=['Intercept'], inplace=True)\n",
    "    Xycols_old = od([('neuron', [neuron]),\n",
    "                     ('gameState', [col for col in Xy.columns if np.all([('gameState' in col),\n",
    "                                                                         (':' not in col)])]),\n",
    "                     ('time', [col for col in Xy.columns if np.all([('time_step' in col),\n",
    "                                                                    (':' not in col)])]),\n",
    "                     ('gameState_x_time', [col for col in Xy.columns if np.all([('time' in col),\n",
    "                                                                                ('gameState' in col),\n",
    "                                                                                (':' in col)])])])\n",
    "    Xycols_new = od([('neuron', [neuron]),\n",
    "                     ('gameState', str_replace(Xcols['gameState'], {'C(gameState, Sum)[S.': 'gameState_',\n",
    "                                                                    ']': ''})),\n",
    "                     ('time', str_replace(Xcols['time'], {'C(time_step, Sum)[S.': 'time_',\n",
    "                                                          ']': ''})),\n",
    "                     ('gameState_x_time', str_replace(Xcols['gameState_x_time'], {'C(gameState, Sum)[S.': 'gameState_',\n",
    "                                                                                  'C(time_step, Sum)[S.': 'time_',\n",
    "                                                                                  ']': ''}))])\n",
    "    for col_type in Xycols_old:\n",
    "        Xy.rename(columns=pd.Series(index=Xycols_old[col_type], data=Xycols_new[col_type]).to_dict(), inplace=True)\n",
    "    Xycols = Xycols_new\n",
    "    \n",
    "    # Define formulas.\n",
    "    formulas = od([])\n",
    "    formulas['full']             = \"Q('{}') ~ 1 + {} + {} + {}\".format(neuron, ' + '.join(Xycols['gameState']), ' + '.join(Xycols['time']), ' + '.join(Xycols['gameState_x_time']))\n",
    "    formulas['subgs']       = \"Q('{}') ~ 1      + {} + {}\".format(neuron,                                  ' + '.join(Xycols['time']), ' + '.join(Xycols['gameState_x_time']))\n",
    "    formulas['subtime']     = \"Q('{}') ~ 1 + {}      + {}\".format(neuron, ' + '.join(Xycols['gameState']),                             ' + '.join(Xycols['gameState_x_time']))\n",
    "    formulas['subgsxtime']  = \"Q('{}') ~ 1 + {} + {}     \".format(neuron, ' + '.join(Xycols['gameState']), ' + '.join(Xycols['time'])                                        )\n",
    "    \n",
    "    return Xy, Xycols, formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy, Xycols, formulas = get_ols_time_formulas(neuron, mod_fits['full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model.\n",
    "mod_fits = od([])\n",
    "for mod, formula in formulas.items():\n",
    "    mod_fits[mod] = ols(formula, data=Xy)#.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mod, fit in mod_fits.items():\n",
    "    print(mod, fit.fit().llf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_fits['full'].fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_fits['full'].fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5.7303 + 0.8273, 5.7303 - 0.8273"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay1_spikes = event_spikes.get_spike_mat(neuron, 'Delay1', column='time_step').values.astype(float)\n",
    "delay2_spikes = event_spikes.get_spike_mat(neuron, 'Delay2', column='time_step').values.astype(float)\n",
    "delay1_spikes.mean(), delay2_spikes.mean(), ((delay1_spikes + delay2_spikes) / 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5.7303 + 0.8273 + 0.3606 + -0.4636, delay1_spikes[:, 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((delay1_spikes + delay2_spikes) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay1_spikes[1].mean() / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#event_spikes.get_spike_mat(neuron, 'Delay1', column='time_step').values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_fits['full'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_fits['red'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron = '8-2'\n",
    "dpi = 300\n",
    "font = {'tick': 6, 'label': 7, 'fig': 9}\n",
    "base_color = 'w'\n",
    "game_states = ['Encoding']\n",
    "spikes_when_moving = False\n",
    "\n",
    "for game_state in game_states:    \n",
    "    fig, ax = time_cell_plots.plot_firing_maze(subj_sess, \n",
    "                                               neuron, \n",
    "                                               game_state, \n",
    "                                               font=font, \n",
    "                                               base_color=base_color,\n",
    "                                               only_show_spikes_when_moving=spikes_when_moving,\n",
    "                                               nav_lw=0.12,\n",
    "                                               nav_color='#296eb4',\n",
    "                                               nav_alpha=0.5,\n",
    "                                               spike_marker='.',\n",
    "                                               spike_fill_color='#e10600',\n",
    "                                               spike_edge_color='#e10600',\n",
    "                                               spike_alpha=0.75,\n",
    "                                               spike_markersize=1.5,\n",
    "                                               spike_mew=0,\n",
    "                                               dpi=dpi)\n",
    "    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_place_cells_parallel(subj_sess_neuron):\n",
    "    import sys\n",
    "    import os\n",
    "    import os.path as op\n",
    "    import pandas as pd\n",
    "    sys.path.append('/home1/cjmac/code/general')\n",
    "    import data_io as dio\n",
    "    sys.path.append('/home1/cjmac/code/projects')\n",
    "    from time_cells import time_bin_analysis\n",
    "    sys.path.append('/home1/cjmac/code/goldmine_replay')\n",
    "    import place_cells\n",
    "    \n",
    "    save_output = True\n",
    "    overwrite = False\n",
    "    game_state = 'Encoding'\n",
    "    nperm = 1000\n",
    "    alpha = 0.05\n",
    "    zthresh = 2\n",
    "    data_dir = '/data7/goldmine'\n",
    "    proj_dir = '/home1/cjmac/projects/goldmine_replay'\n",
    "    \n",
    "    try:\n",
    "        subj_sess, *neuron = subj_sess_neuron.split('-')\n",
    "        neuron = '-'.join(neuron)\n",
    "\n",
    "        # Load event_spikes.\n",
    "        event_spikes = time_bin_analysis.load_event_spikes(subj_sess, proj_dir=data_dir)\n",
    "\n",
    "        obs_weights = place_cells.get_ols_params_place(neuron, event_spikes, game_state=game_state)\n",
    "        null_weights = pd.concat([place_cells.get_ols_params_place(neuron, event_spikes, game_state=game_state, circshift_frs=True)\n",
    "                                  for iPerm in range(nperm)])\n",
    "        place_fits = place_cells.get_ols_sig_place(obs_weights, null_weights, alpha=alpha, zthresh=zthresh)\n",
    "\n",
    "        if save_output:\n",
    "            filename = op.join(proj_dir, 'ols_place_cells', '{}-{}.pkl'.format(place_fits.iloc[0]['subj_sess_unit'], place_fits.iloc[0]['gameState']))\n",
    "            if overwrite or not op.exists(filename):\n",
    "                dio.save_pickle(place_fits, filename, verbose=False)    \n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = '/home1/cjmac/logs/TryExceptError-run_place_cells_parallel-{}'.format(subj_sess_neuron)\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get neurons to process.\n",
    "fpath = op.join(proj_dir, 'ols_place_cells', '{}-Encoding.pkl')\n",
    "pop_spikes = pop_decoding.load_pop_spikes()\n",
    "neurons = [neuron for neuron in pop_spikes.neurons if not op.exists(fpath.format(neuron))]\n",
    "print('{} neurons to process'.format(len(neurons)))\n",
    "\n",
    "# Parallel processing\n",
    "n_ops = len(neurons)\n",
    "print('Running code for {} operations.\\n'.format(n_ops))\n",
    "with cluster_view(scheduler=\"sge\", queue=\"RAM.q\", num_jobs=np.min((n_ops, 200)), cores_per_job=1) as view:\n",
    "    output = view.map(run_place_cells_parallel, neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load place cells.\n",
    "files = glob(op.join(proj_dir, 'ols_place_cells', '*-Encoding.pkl'))\n",
    "place_fits = pd.concat([dio.open_pickle(f) for f in files]).reset_index(drop=True)\n",
    "\n",
    "# Add columns.\n",
    "place_fits.insert(0, 'subj', place_fits['subj_sess_unit'].apply(lambda x: x.split('-')[0].split('_')[0]))\n",
    "place_fits.insert(1, 'subj_sess', place_fits['subj_sess_unit'].apply(lambda x: x.split('-')[0]))\n",
    "place_fits.insert(2, 'neuron', place_fits['subj_sess_unit'].apply(lambda x: '-'.join(x.split('-')[1:])))\n",
    "place_fits.insert(3, 'hemroi', place_fits.apply(lambda x: spike_preproc.roi_lookup(x['subj_sess'], x['neuron'].split('-')[0]), axis=1))\n",
    "roi_map = spike_preproc.roi_mapping(5)\n",
    "place_fits.insert(4, 'roi_gen', place_fits['hemroi'].apply(lambda x: roi_map[x[1:]]))\n",
    "place_fits.insert(place_fits.columns.tolist().index('sig')+1, 'sig_pos', (place_fits['sig'] == True) & (place_fits['n_place_fields'] > 0))\n",
    "\n",
    "# Save indices to all place cells and place cells with a place field outside the base, respectively.\n",
    "place_all_idx = place_fits.query(\"(sig_pos==True)\").index.values\n",
    "place_mine_idx = place_all_idx[np.where(place_fits.query(\"(sig_pos==True)\")['place_fields']\n",
    "                                                  .apply(lambda x: len([place for place in x if place!='Base'])>0))[0]]\n",
    "\n",
    "print('place_fits:', place_fits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cells = place_fits['subj_sess_unit'].size\n",
    "n_place_cells = len(place_fits.query(\"(sig==True)\"))\n",
    "n_pos_place_cells = len(place_fits.query(\"(sig==True) & (n_place_fields>0)\"))\n",
    "\n",
    "print('{}/{} ({:.1%}) cells are significant for place'.format(n_place_cells, n_cells, n_place_cells/n_cells))\n",
    "print('{}/{} ({:.1%}) significant cells have 1+ place fields'.format(n_pos_place_cells, n_place_cells, n_pos_place_cells/n_place_cells))\n",
    "display(place_fits.query(\"(sig==True)\").groupby('n_place_fields').agg({'subj_sess_unit': len}).rename(columns={'subj_sess_unit': 'n'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_pct(x):\n",
    "    _sum = np.sum(x)\n",
    "    _n = len(x)\n",
    "    return '{}/{} ({:.1%})'.format(_sum, _n, _sum/_n)\n",
    "    \n",
    "display(place_fits.groupby('roi_gen').agg({'sig_pos': sum_pct}))\n",
    "display(place_fits.groupby('subj').agg({'sig_pos': sum_pct}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_fields = aop.unique(np.concatenate(place_fits.query(\"(sig_pos==True)\")['place_fields'].tolist()))\n",
    "\n",
    "print('All place cells:')\n",
    "print('{} place fields across {} place cells'.format(place_fields.sum(), len(place_fits.query(\"(sig_pos==True)\"))), end='\\n'*2)\n",
    "\n",
    "print('Subset of place cells with a place cell outside the mine:')\n",
    "print('{} place fields across {} place cells'.format(place_fields.sum(), len(place_fits.loc[place_mine_idx])))\n",
    "\n",
    "display(pd.concat([place_fields, place_fields / place_fields.sum()], axis=1).rename(columns={0: 'n', 1: 'prop'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = 'full'\n",
    "red = 'subplace'\n",
    "\n",
    "output.query(\"(mod=='{}')\").pivot(index=['subj_sess_unit', 'gameState', 'mod', 'llf'], columns=['level'], values=['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mod_fits['subplace'].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mod_fits['subplace'].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mod_fits['full'].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
