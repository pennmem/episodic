{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load fundamental modules & initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General\n",
    "import sys\n",
    "import os\n",
    "import os.path as op\n",
    "from time import time\n",
    "from collections import OrderedDict as od\n",
    "from importlib import reload\n",
    "from glob import glob\n",
    "import itertools\n",
    "import h5py\n",
    "import warnings\n",
    "from importlib import reload\n",
    "\n",
    "# Scientific\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 999\n",
    "import scipy.io as sio\n",
    "\n",
    "# Stats\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Plots\n",
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Plotting parameters\n",
    "mpl.rcParams['grid.linewidth'] = 0.1\n",
    "mpl.rcParams['grid.alpha'] = 0.75\n",
    "mpl.rcParams['lines.linewidth'] = 1\n",
    "mpl.rcParams['lines.markersize'] = 3\n",
    "mpl.rcParams['xtick.labelsize'] = 15\n",
    "mpl.rcParams['ytick.labelsize'] = 15 \n",
    "colors = ['1f77b4', 'd62728', '2ca02c', 'ff7f0e', '9467bd', \n",
    "          '8c564b', 'e377c2', '7f7f7f', 'bcbd22', '17becf']\n",
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler('color', colors)\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.formatter.offset_threshold'] = 2\n",
    "mpl.rcParams['axes.labelsize'] = 17\n",
    "mpl.rcParams['axes.labelpad'] = 10\n",
    "mpl.rcParams['axes.titlesize'] = 19\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "mpl.rcParams['axes.axisbelow'] = True\n",
    "mpl.rcParams['legend.loc'] = 'upper right'\n",
    "mpl.rcParams['legend.fontsize'] = 15\n",
    "mpl.rcParams['legend.frameon'] = False\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "mpl.rcParams['figure.titlesize'] = 19\n",
    "mpl.rcParams['figure.figsize'] = (6.85039, 4.79527) \n",
    "mpl.rcParams['figure.subplot.wspace'] = 0.25 \n",
    "mpl.rcParams['figure.subplot.hspace'] = 0.25 \n",
    "mpl.rcParams['font.sans-serif'] = ['Helvetica']\n",
    "mpl.rcParams['savefig.format'] = 'pdf'\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "# warnings.filterwarnings( 'default' )\n",
    "\n",
    "# Personal - for code, not data.\n",
    "sys.path.append('/home1/cjmac/code/general')\n",
    "sys.path.append('/home1/cjmac/code/manning_replication')\n",
    "sys.path.append('/home1/cjmac/code/projects/')\n",
    "import data_io as dio\n",
    "import array_operations as aop\n",
    "from eeg_plotting import plot_trace, plot_trace2\n",
    "\n",
    "from time_cells import spike_sorting, spike_preproc, events_preproc, events_proc, time_bin_analysis\n",
    "\n",
    "# Colors\n",
    "n = 4\n",
    "c = 2\n",
    "colors = [sns.color_palette('Blues', n)[c], \n",
    "          sns.color_palette('Reds', n)[c], \n",
    "          sns.color_palette('Greens', n)[c],\n",
    "          sns.color_palette('Purples', n)[c],\n",
    "          sns.color_palette('Oranges', n)[c],\n",
    "          sns.color_palette('Greys', n)[c],\n",
    "          sns.color_palette('YlOrBr', n+3)[c],\n",
    "          'k']\n",
    "cmap = sns.palettes.blend_palette((colors[0], \n",
    "                                   'w',\n",
    "                                   colors[1]), 501)\n",
    "font = {'tick': 12,\n",
    "        'label': 14,\n",
    "        'fig': 16}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Perform alignment (or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first timestamp in events before zero-ing is 1659907712081.790\n",
      "162813 events recorded over 27665241 min and 29 sec\n",
      "The first timestamp in lfp_timestamps before zero-ing & before conv factor is 1659886159500.505\n",
      "The first timestamp in lfp_timestamps before zero-ing & after conv factor is 1659886159500.505\n",
      "The first timestamp in lfp_timestamps after zero-ing & conv factor is 0.000\n",
      "Conversion factor is 1\n",
      "105923584 timestamps over 55 min and 10.1 s\n",
      "Sampling rate is 32000 Hz\n"
     ]
    }
   ],
   "source": [
    "subj_sess = 'U555_ses0'\n",
    "\n",
    "# Load the sync channel.\n",
    "# sync_chan = events_preproc.load_syncs(subj_sess, data_key='data')\n",
    "sync_chan, TTL, timestamp_flag = events_preproc.load_syncs(subj_sess, data_key='data')\n",
    "\n",
    "if not timestamp_flag: \n",
    "     \n",
    "    # Read events file and get event synctimes.\n",
    "    events, event_synctimes = events_preproc.read_events_json( subj_sess )\n",
    "\n",
    "    # Load LFP timestamps. LFP timestamps must be in msec\n",
    "    lfp_timestamps, sr = spike_sorting.load_lfp_timestamps( subj_sess )\n",
    "\n",
    "    # Identify sync pulses in the sync channel EEG. The sync channel EEG is typically sampled at a different rate than the physiological EEG.\n",
    "    pulse_startinds = events_preproc.find_pulse_starts(sync_chan, \n",
    "                                                       sampling_rate=sr, \n",
    "                                                       pulse_thresh=200, \n",
    "                                                       intrapulse_thresh_ms=20, \n",
    "                                                       interpulse_thresh_ms=790\n",
    "                                                      )\n",
    "    \n",
    "    lfp_synctimes = lfp_timestamps[pulse_startinds]\n",
    "    \n",
    "    print('Detected {} syncs for {} sync pulse events'.format(len(pulse_startinds), len(events.loc[events.key=='syncPulse', 'time'])))\n",
    "\n",
    "    subj, sess = subj_sess.split('_')\n",
    "    sync_f = os.path.join('/home1/cjmac/projects/time_cells', 'data', subj, sess, 'sync', 'sync_channel_micro.mat')\n",
    "\n",
    "\n",
    "    # Find matching sync pulse pairs.\n",
    "    event_synctimes_adj, lfp_synctimes_adj = events_preproc.pair_sync_pulses(event_synctimes, \n",
    "                                                                             lfp_synctimes, \n",
    "                                                                             step=5, \n",
    "                                                                             max_shift=200, \n",
    "                                                                             max_slide=50, \n",
    "                                                                             ipi_thresh=2\n",
    "                                                                            )\n",
    "    # Perform the alignment.\n",
    "    alignment = events_preproc.align_sync_pulses(event_synctimes_adj, \n",
    "                                                 lfp_synctimes_adj)\n",
    "    \n",
    "    # Apply the alignment to all event times.\n",
    "    events['time'] = events['time'].apply(lambda x: alignment['sync_params']['intercept'] + (alignment['sync_params']['slope'] * x))    \n",
    "    \n",
    "    plot_flag = 0     \n",
    "    if (plot_flag):\n",
    "        # How did our alignment go?\n",
    "        print('{} event sync pulses'.format(len(event_synctimes_adj)))\n",
    "        print('{} LFP sync pulses identified'.format(len(lfp_synctimes_adj)))\n",
    "        print('\\n--------------------\\nAlignment parameters\\n--------------------')\n",
    "        for k, v in alignment.items():\n",
    "            print('{}: {}'.format(k, v))\n",
    "\n",
    "        plt.close()\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(16, 6), dpi=300)\n",
    "        ax = np.ravel(ax)\n",
    "\n",
    "        min_syncs = np.min((len(event_synctimes_adj), len(lfp_synctimes_adj)))\n",
    "        start = 0\n",
    "        stop = None\n",
    "\n",
    "        i = 0\n",
    "        ax[i].scatter(np.diff(event_synctimes_adj), np.diff(lfp_synctimes_adj))\n",
    "        ax[i].set_xlabel('$Event_{IPI}$', fontsize=font['label'], labelpad=8)\n",
    "        ax[i].set_ylabel('$LFP_{IPI}$', fontsize=font['label'], labelpad=8)\n",
    "        ax[i].set_title('Inter-pulse interval correlation', fontsize=font['fig'], y=1.05)\n",
    "\n",
    "        i = 1\n",
    "        ax[i].plot(np.diff(lfp_synctimes_adj)[start:stop] - np.diff(event_synctimes_adj)[start:stop])\n",
    "        ax[i].plot(np.diff(lfp_synctimes_adj)[start:stop] - np.diff(event_synctimes_adj)[start:stop])\n",
    "        ax[i].set_xlabel('Sync no.', fontsize=font['label'], labelpad=8)\n",
    "        ax[i].set_ylabel('Time (ms)', fontsize=font['label'], labelpad=8)\n",
    "        ax[i].set_title('$LFP_{IPI} - Event_{IPI}$', fontsize=font['fig'], y=1.05)\n",
    "\n",
    "        i = 2\n",
    "        ax[i].plot(lfp_synctimes_adj[start:stop] - event_synctimes_adj[start:stop])\n",
    "        ax[i].set_xlabel('Sync no.', fontsize=font['label'], labelpad=8)\n",
    "        ax[i].set_ylabel('Time (ms)', fontsize=font['label'], labelpad=8)\n",
    "        ax[i].set_title('LFP - Event synctimes', fontsize=font['fig'], y=1.05)\n",
    "\n",
    "        for i in range(len(ax)):\n",
    "            ax[i].tick_params(axis='both', which='major', labelsize=font['tick'])\n",
    "        fig.tight_layout()\n",
    "\n",
    "        event_synctimes = events.loc[events['key']=='syncPulse', 'time'].values\n",
    "        event_pulse_inds = (np.array([x for x in (event_synctimes-lfp_timestamps[0]) * (sr/1e3) \n",
    "                                      if x<len(lfp_timestamps)])).astype(np.int64)\n",
    "        event_pulse_startinds_train = np.zeros(len(sync_chan))\n",
    "        event_pulse_startinds_train[event_pulse_inds] = 1\n",
    "\n",
    "        fig, ax = plot_trace2(sync_chan, spike_dat=event_pulse_startinds_train,\n",
    "                              start=300, duration=30, nwin=6, x_units='secs', sampling_rate=sr)  \n",
    "else:    \n",
    "    # Read events file and get event synctimes in msec.\n",
    "    events, event_synctimes = events_preproc.read_events_json( subj_sess, start_at_zero = False  )\n",
    "    \n",
    "    # Load LFP timestamps in msec\n",
    "    lfp_timestamps, sr = spike_sorting.load_lfp_timestamps( subj_sess, start_at_zero = True, conv_factor = 'infer' )\n",
    "\n",
    "    if (False):\n",
    "        #\n",
    "        sync_chan_new = sync_chan.copy()\n",
    "        sync_chan_new *= 1000 ; # converts to msec\n",
    "        sync_chan_new = sync_chan_new - sync_chan_new[0] #sync_chan_new and sync_chan are shorter in length than lfp_timestamps bc of different sampling frequency\n",
    "        TTL_new = TTL.copy()\n",
    "        TTL_new[np.where(TTL != 255)] = 0\n",
    "        from scipy import interpolate\n",
    "        f = interpolate.interp1d(sync_chan_new, TTL_new, kind = 'next', fill_value='extrapolate')\n",
    "        TTL_up = f(lfp_timestamps)\n",
    "\n",
    "        plot_flag = 0\n",
    "        if plot_flag:\n",
    "            ind_range_1 = [ 0, 100000 ] \n",
    "            fig, ax = plt.subplots(1, 1, figsize=(16, 6), dpi=300)\n",
    "            plt.plot(lfp_timestamps[ slice( ind_range_1[0], ind_range_1[1], 1)], \n",
    "                     TTL_up[ slice( ind_range_1[0], ind_range_1[1], 1)],\n",
    "                     marker = 'o', color = 'blue', linestyle = 'none', markersize = 8 )\n",
    "\n",
    "        pulse_startinds = np.where(TTL_up == 255)[0] \n",
    "        lfp_synctimes = lfp_timestamps[pulse_startinds]\n",
    "        \n",
    "        # \n",
    "        plot_flag = 0\n",
    "        if plot_flag:\n",
    "            time_range = [ 30000, 100000 ] \n",
    "            ind_lfp_synctimes = np.where(np.logical_and(lfp_synctimes>=time_range[0], lfp_synctimes<=time_range[1]))\n",
    "            ind_event_synctimes= np.where(np.logical_and(event_synctimes>=time_range[0], event_synctimes<=time_range[1]))\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(30, 10), dpi=300)\n",
    "            plt.plot(lfp_synctimes[ ind_lfp_synctimes ], \n",
    "                     np.full( ( 1, len( ind_lfp_synctimes[0] ) ), 255 )[0],\n",
    "                     marker = 'o', color = 'blue', linestyle = 'none', markersize = 16 ) \n",
    "            plt.plot(event_synctimes[ ind_event_synctimes ], \n",
    "                     np.full( ( 1, len( ind_event_synctimes[0] ) ), 255 )[0],\n",
    "                     marker = 'x', color = 'red', linestyle = 'none', mew = 4, markersize = 16 ) \n",
    "            plt.show()   \n",
    "    \n",
    "    else:\n",
    "        #\n",
    "        sync_chan_new = sync_chan.copy()\n",
    "        sync_chan_new /= 1000  # converts to msec\n",
    "#         sync_chan_new = sync_chan_new - sync_chan_new[0] # zero the timestamps\n",
    "        TTL_up = TTL.copy()\n",
    "        pulse_startinds = np.where(TTL_up == 1)[0] \n",
    "        lfp_synctimes = sync_chan_new[pulse_startinds]\n",
    "        event_synctimes = event_synctimes[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_flag = 0\n",
    "if plot_flag:\n",
    "    time_range = [ 30000, 100000 ] \n",
    "    ind_lfp_synctimes = np.where(np.logical_and(lfp_synctimes>=time_range[0], lfp_synctimes<=time_range[1]))\n",
    "    ind_event_synctimes= np.where(np.logical_and(event_synctimes>=time_range[0], event_synctimes<=time_range[1]))\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(30, 10), dpi=300)\n",
    "    plt.plot(lfp_synctimes[ ind_lfp_synctimes ], \n",
    "             np.full( ( 1, len( ind_lfp_synctimes[0] ) ), 255 )[0],\n",
    "             marker = 'o', color = 'blue', linestyle = 'none', markersize = 16 ) \n",
    "    plt.plot(event_synctimes[ ind_event_synctimes ], \n",
    "             np.full( ( 1, len( ind_event_synctimes[0] ) ), 255 )[0],\n",
    "             marker = 'x', color = 'red', linestyle = 'none', mew = 4, markersize = 16 ) \n",
    "    plt.show()  \n",
    "    \n",
    "# need a way to check (a) if time is in UNIX time or ? AND (b) if UNIX time is in us, ms, or s.\n",
    "\n",
    "plot_flag = 0\n",
    "# Creating histogram\n",
    "if plot_flag:\n",
    "    fig, ax = plt.subplots(figsize=[8, 8], sharex = 'col', sharey = 'row')\n",
    "    ax = plt.subplot(2, 1, 1)\n",
    "    ax.hist(np.diff(event_synctimes), bins = range(0, 2000, 10))\n",
    "    ax = plt.subplot(2, 1, 2)\n",
    "    ax.hist(np.diff(lfp_synctimes), bins = range(0, 2000, 10))   \n",
    "    \n",
    "# \n",
    "plot_flag = 0\n",
    "if plot_flag:\n",
    "    time_range = [ 30000, 50000 ] \n",
    "    ind_lfp_synctimes = np.where(np.logical_and(lfp_synctimes>=time_range[0], lfp_synctimes<=time_range[1]))\n",
    "    ind_event_synctimes= np.where(np.logical_and(event_synctimes>=time_range[0], event_synctimes<=time_range[1]))\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(30, 10), dpi=300)\n",
    "    plt.plot(lfp_synctimes[ ind_lfp_synctimes ], \n",
    "             np.full( ( 1, len( ind_lfp_synctimes[0] ) ), 255 )[0],\n",
    "             marker = 'o', color = 'blue', linestyle = 'none', markersize = 16 ) \n",
    "    plt.plot(event_synctimes[ ind_event_synctimes ], \n",
    "             np.full( ( 1, len( ind_event_synctimes[0] ) ), 255 )[0],\n",
    "             marker = 'x', color = 'red', linestyle = 'none', mew = 4, markersize = 16 ) \n",
    "    plt.show()  \n",
    "    \n",
    "#\n",
    "print('Detected {} syncs for {} sync pulse events'.format(len(pulse_startinds), len(events.loc[events.key=='syncPulse', 'time'])))\n",
    "\n",
    "subj, sess = subj_sess.split('_')\n",
    "sync_f = os.path.join('/home1/cjmac/projects/time_cells', 'data', subj, sess, 'sync', 'sync_channel_micro.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retained 3035 sync pulses\n"
     ]
    }
   ],
   "source": [
    "# Find matching sync pulse pairs.\n",
    "event_synctimes_adj, lfp_synctimes_adj = events_preproc.pair_sync_pulses(event_synctimes, \n",
    "                                                                         lfp_synctimes, \n",
    "                                                                         step=5, \n",
    "                                                                         max_shift=250, \n",
    "                                                                         max_slide=50, \n",
    "                                                                         ipi_thresh=2\n",
    "                                                                        )\n",
    "                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(events_preproc)\n",
    "# events.loc[events.key == 'syncPulse'].to_csv('./outputs/csv/events_all_synctimes.csv')\n",
    "# pd.DataFrame(lfp_synctimes).to_csv('./outputs/csv/lfp_synctimes.csv')\n",
    "# pd.DataFrame(lfp_synctimes_adj).to_csv('./outputs/csv/lfp_synctimes_adj.csv')\n",
    "# # pd.DataFrame(event_synctimes).to_csv('./outputs/csv/synctimes_events.csv')\n",
    "# # pd.DataFrame(lfp_synctimes).to_csv('./outputs/csv/synctimes_lfp.csv')\n",
    "# # pd.DataFrame(event_synctimes_adj).to_csv('./outputs/csv/synctimes_events_adj.csv')\n",
    "# # pd.DataFrame(lfp_synctimes_adj).to_csv('./outputs/csv/synctimes_lfp_adj.csv')\n",
    "\n",
    "# Perform the alignment.\n",
    "alignment = events_preproc.align_sync_pulses(event_synctimes_adj, \n",
    "                                             lfp_synctimes_adj)\n",
    "\n",
    "# Apply the alignment to all event times.\n",
    "events['time'] = events['time'].apply(lambda x: alignment['sync_params']['intercept'] + (alignment['sync_params']['slope'] * x))\n",
    "\n",
    "# events.to_csv('./outputs/csv/events_all_adj.csv')\n",
    "events.loc[events.key == 'syncPulse'].to_csv('./outputs/csv/events_all_adj_synctimes.csv')\n",
    "\n",
    "# cjm addition\n",
    "events['time'] = (events['time'] - events.at[0, 'time'])\n",
    "\n",
    "plot_flag = 0     \n",
    "if (plot_flag):\n",
    "\n",
    "    # How did our alignment go?\n",
    "    print('{} event sync pulses'.format(len(event_synctimes_adj)))\n",
    "    print('{} LFP sync pulses identified'.format(len(lfp_synctimes_adj)))\n",
    "    print('\\n--------------------\\nAlignment parameters\\n--------------------')\n",
    "    for k, v in alignment.items():\n",
    "        print('{}: {}'.format(k, v))\n",
    "\n",
    "    plt.close()\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(16, 6), dpi=300)\n",
    "    ax = np.ravel(ax)\n",
    "\n",
    "    min_syncs = np.min((len(event_synctimes_adj), len(lfp_synctimes_adj)))\n",
    "    start = 0\n",
    "    stop = None\n",
    "\n",
    "    i = 0\n",
    "    ax[i].scatter(np.diff(event_synctimes_adj), np.diff(lfp_synctimes_adj))\n",
    "    ax[i].set_xlabel('$Event_{IPI}$', fontsize=font['label'], labelpad=8)\n",
    "    ax[i].set_ylabel('$LFP_{IPI}$', fontsize=font['label'], labelpad=8)\n",
    "    ax[i].set_title('Inter-pulse interval correlation', fontsize=font['fig'], y=1.05)\n",
    "\n",
    "    i = 1\n",
    "    ax[i].plot(np.diff(lfp_synctimes_adj)[start:stop] - np.diff(event_synctimes_adj)[start:stop])\n",
    "    ax[i].plot(np.diff(lfp_synctimes_adj)[start:stop] - np.diff(event_synctimes_adj)[start:stop])\n",
    "    ax[i].set_xlabel('Sync no.', fontsize=font['label'], labelpad=8)\n",
    "    ax[i].set_ylabel('Time (ms)', fontsize=font['label'], labelpad=8)\n",
    "    ax[i].set_title('$LFP_{IPI} - Event_{IPI}$', fontsize=font['fig'], y=1.05)\n",
    "\n",
    "    i = 2\n",
    "    ax[i].plot(lfp_synctimes_adj[start:stop] - event_synctimes_adj[start:stop])\n",
    "    ax[i].set_xlabel('Sync no.', fontsize=font['label'], labelpad=8)\n",
    "    ax[i].set_ylabel('Time (ms)', fontsize=font['label'], labelpad=8)\n",
    "    ax[i].set_title('LFP - Event synctimes', fontsize=font['fig'], y=1.05)\n",
    "\n",
    "    for i in range(len(ax)):\n",
    "        ax[i].tick_params(axis='both', which='major', labelsize=font['tick'])\n",
    "    fig.tight_layout()    \n",
    "\n",
    "    event_synctimes = events.loc[events['key']=='syncPulse', 'time'].values\n",
    "    event_pulse_inds = (np.array([x for x in (event_synctimes-lfp_timestamps[0]) * (sr/1e3) \n",
    "                                  if x<len(lfp_timestamps)])).astype(np.int64)\n",
    "    event_pulse_startinds_train = np.zeros(len(lfp_timestamps))\n",
    "    event_pulse_startinds_train[event_pulse_inds] = 1\n",
    "\n",
    "#     fig, ax = plot_trace2(TTL_up, spike_dat=event_pulse_startinds_train,\n",
    "#                           start=300, duration=30, nwin=6, x_units='secs', sampling_rate=sr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format events and spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(events_preproc)\n",
    "reload(events_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U555_ses0\n",
      "Processing events data.\n",
      "\n",
      "Processing trial 1 and game state Delay\n",
      "Processing trial 1 and game state ReturnToBase\n",
      "Processing trial 2 and game state Delay\n",
      "Processing trial 2 and game state ReturnToBase\n",
      "Processing trial 3 and game state Delay\n",
      "Processing trial 3 and game state ReturnToBase\n",
      "Processing trial 4 and game state Delay\n",
      "Processing trial 4 and game state ReturnToBase\n",
      "Processing trial 5 and game state Delay\n",
      "Processing trial 5 and game state ReturnToBase\n",
      "Processing trial 6 and game state Delay\n",
      "Processing trial 6 and game state ReturnToBase\n",
      "Processing trial 7 and game state Delay\n",
      "Processing trial 7 and game state ReturnToBase\n",
      "Processing trial 8 and game state Delay\n",
      "Processing trial 8 and game state ReturnToBase\n",
      "Processing trial 9 and game state Delay\n",
      "Processing trial 9 and game state ReturnToBase\n",
      "Processing trial 10 and game state Delay\n",
      "Processing trial 10 and game state ReturnToBase\n",
      "Processing trial 11 and game state Delay\n",
      "Processing trial 11 and game state ReturnToBase\n",
      "Processing trial 12 and game state Delay\n",
      "Processing trial 12 and game state ReturnToBase\n",
      "Processing trial 13 and game state Delay\n",
      "Processing trial 13 and game state ReturnToBase\n",
      "Processing trial 14 and game state Delay\n",
      "Processing trial 14 and game state ReturnToBase\n",
      "Processing trial 15 and game state Delay\n",
      "Processing trial 15 and game state ReturnToBase\n",
      "Processing trial 16 and game state Delay\n",
      "Processing trial 16 and game state ReturnToBase\n",
      "Processing trial 17 and game state Delay\n",
      "Processing trial 17 and game state ReturnToBase\n",
      "Processing trial 18 and game state Delay\n",
      "Processing trial 18 and game state ReturnToBase\n",
      "Processing trial 19 and game state Delay\n",
      "Processing trial 19 and game state ReturnToBase\n",
      "Incomplete trials:\n",
      "trial  gameState           \n",
      "0      Delay                   5.841936e+06\n",
      "       DoNextTrial             8.474571e+04\n",
      "       Encoding                5.781596e+06\n",
      "       InitTrial               5.293171e+06\n",
      "       PreEncodingDelayMsg     5.295171e+06\n",
      "       PreRetrievalDelayMsg    4.474029e+06\n",
      "       PreTimelineMsg          4.473981e+06\n",
      "       Retrieval               4.502028e+06\n",
      "       ReturnToBase            4.604474e+06\n",
      "       Timeline                4.491872e+06\n",
      "Name: time, dtype: float64\n",
      "Removing incomplete trials...\n",
      "Noisy trials:\n",
      "Series([], Name: time, dtype: float64)\n",
      "Paused trials:\n",
      "Series([], Name: time, dtype: float64)\n",
      "Main experiment has 124064 events recorded over 75 min and 35 sec\n",
      "Saved /home1/cjmac/projects/time_cells/analysis/events/U555_ses0-events_formatted.pkl\n",
      "Wassssssssssup?\n",
      "> <ipython-input-5-b1bae0fc377a>(29)<module>()\n",
      "-> events = events_proc.load_events(subj_sess,\n",
      "--KeyboardInterrupt--\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  q\n"
     ]
    }
   ],
   "source": [
    "proc_events = True\n",
    "proc_spikes = True\n",
    "proj_dir = '/home1/cjmac/projects/time_cells'\n",
    "subj_sess = 'U555_ses0'\n",
    "run_all = True\n",
    "save_output = True\n",
    "overwrite = True\n",
    "verbose = True\n",
    "\n",
    "start_time = time()\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(subj_sess)\n",
    "if proc_events:\n",
    "    # Load events and event times.\n",
    "    print('Processing events data.', end='\\n\\n')\n",
    "    events = events_preproc.format_events(events=events,\n",
    "                                          noisy_trials=[],\n",
    "                                          remove_incomplete_trials=True,\n",
    "                                          remove_noisy_trials=False,\n",
    "                                          remove_paused_trials=False,\n",
    "                                          overwrite=overwrite,\n",
    "                                          save_output=save_output,\n",
    "                                          proj_dir=proj_dir,\n",
    "                                          verbose=verbose)\n",
    "    \n",
    "    print('Wassssssssssup?')\n",
    "    breakpoint()\n",
    "    events = events_proc.load_events(subj_sess,\n",
    "                                     proj_dir=proj_dir,\n",
    "                                     overwrite=overwrite,\n",
    "                                     verbose=verbose,\n",
    "                                     run_all=run_all)\n",
    "\n",
    "    if save_output:\n",
    "        events_proc.save_events(events,\n",
    "                                overwrite=overwrite,\n",
    "                                verbose=verbose)\n",
    "\n",
    "if proc_spikes:\n",
    "    # Load spikes.\n",
    "    print('Processing spikes data.', end='\\n\\n')\n",
    "    spikes = spike_preproc.format_spikes(subj_sess,\n",
    "                                         conv_factor='infer',\n",
    "                                         fr_thresh=0.1,\n",
    "                                         overwrite=True,\n",
    "                                         save_output=True,\n",
    "                                         split_files=True,\n",
    "                                         verbose=verbose)\n",
    "\n",
    "# warnings.resetwarnings()\n",
    "# print('Done in {:.2f} s'.format(time() - start_time))\n",
    "\n",
    "savefile = False\n",
    "overwrite = False\n",
    "\n",
    "event_spikes = time_bin_analysis.load_event_spikes(subj_sess, overwrite=overwrite)\n",
    "if savefile:\n",
    "    time_bin_analysis.save_event_spikes(event_spikes, overwrite=overwrite)\n",
    "\n",
    "savefile = True\n",
    "overwrite = True\n",
    "\n",
    "event_spikes = time_bin_analysis.load_event_spikes(subj_sess, overwrite=overwrite)\n",
    "if savefile:\n",
    "    time_bin_analysis.save_event_spikes(event_spikes, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_unit_fr_parallel(subj_sess_neuron):\n",
    "    import sys\n",
    "    import os\n",
    "    from time import sleep\n",
    "    import numpy as np\n",
    "    sys.path.append('/home1/cjmac/code/projects')\n",
    "    from time_cells.time_bin_analysis import model_unit_fr\n",
    "    # Take a nap.\n",
    "    if False:\n",
    "        sleep_secs = int(1800 * np.random.rand())\n",
    "        sleep(sleep_secs)\n",
    "    try:\n",
    "        subj_sess, chan, unit = subj_sess_neuron.split('-')\n",
    "        neuron = '{}-{}'.format(chan, unit)\n",
    "        output = model_unit_fr(subj_sess,\n",
    "                               neuron,\n",
    "                               model='ols',\n",
    "                               n_perm=1000,\n",
    "                               overwrite=True,\n",
    "                               save_output=True)\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = '/home1/cjmac/logs/TryExceptError-model_unit_fr_parallel-{}'.format(subj_sess_neuron)\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')\n",
    "    \n",
    "    return None\n",
    "\n",
    "# from importlib import reload\n",
    "# flag_reload = 1\n",
    "# if flag_reload:\n",
    "#     reload( time_bin_analysis )\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "# Load event_spikes and get the names of each neuron.\n",
    "proj_dir = '/home1/cjmac/projects/time_cells'\n",
    "\n",
    "# Get sessions.\n",
    "sessions = np.unique([op.basename(f).split('-')[0] \n",
    "                      for f in glob(op.join(proj_dir, 'analysis', 'events', '*.pkl'))])\n",
    "sessions = np.delete(sessions, 0)\n",
    "print('{} subjects, {} sessions'.format(len(np.unique([x.split('_')[0] for x in sessions])), len(sessions)))\n",
    "\n",
    "subj_sess_neurons = []\n",
    "for subj_sess in sessions:\n",
    "    event_spikes = time_bin_analysis.load_event_spikes(subj_sess, verbose=False)\n",
    "    for neuron in event_spikes.column_map['neurons']:\n",
    "        subj_sess_neuron = '{}-{}'.format(subj_sess, neuron)\n",
    "        #output_f = op.join(proj_dir, 'analysis', 'behav_glms', '{}-glm_results.pkl'.format(subj_sess_neuron))\n",
    "        output_f = op.join(proj_dir, 'analysis', 'unit_to_behav', '{}-ols-time_bin-model_pairs.pkl'.format(subj_sess_neuron))\n",
    "        print(output_f)\n",
    "        if not op.exists(output_f):\n",
    "            subj_sess_neurons.append(subj_sess_neuron)\n",
    "    print('{} neurons'.format(len(subj_sess_neurons)))\n",
    "\n",
    "# cjm change\n",
    "subj_sess_neurons = ['U554_ses0-46-1']\n",
    "\n",
    "# # cjm change\n",
    "if False:\n",
    "    subj_sess_neurons = [which_neuron for which_neuron in subj_sess_neurons if which_neuron in [ 'U554_ses0-46-1' ] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section to understand how OLS fitting was done in time_bin_analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = event_spikes.event_spikes.query(\"(gameState=='{}')\".format('Retrieval')).copy()\n",
    "neuron = '46-1'\n",
    "keep_cols = ['trial', 'gameState', 'time_step', 'maze_region', 'head_direc', 'is_moving', \n",
    "             'base_in_view', 'gold_in_view', 'dig_performed', neuron]\n",
    "df = df[keep_cols]\n",
    "dummys = ['is_moving', 'base_in_view', 'gold_in_view', 'dig_performed']\n",
    "df[dummys] = df[dummys].fillna(0)\n",
    "df.to_csv('mdl_46-1.csv')\n",
    "regress_trial = False\n",
    "trial_term = ' + C(trial)' if regress_trial else ''\n",
    "formulas = od([])\n",
    "formulas['full']          = \"Q('{}') ~ 1 + C(time_step) + C(maze_region) + C(head_direc) + is_moving + base_in_view + dig_performed{}\".format(neuron, trial_term)\n",
    "formulas['full_subtime']  = \"Q('{}') ~ 1                + C(maze_region) + C(head_direc) + is_moving + base_in_view + dig_performed{}\".format(neuron, trial_term)\n",
    "formulas['full_subplace'] = \"Q('{}') ~ 1 + C(time_step)                  + C(head_direc) + is_moving + base_in_view + dig_performed{}\".format(neuron, trial_term)\n",
    "formulas['full_subhd']    = \"Q('{}') ~ 1 + C(time_step) + C(maze_region)                 + is_moving + base_in_view + dig_performed{}\".format(neuron, trial_term)\n",
    "formulas['full_submvmt']  = \"Q('{}') ~ 1 + C(time_step) + C(maze_region) + C(head_direc)             + base_in_view + dig_performed{}\".format(neuron, trial_term)\n",
    "formulas['full_subbiv']   = \"Q('{}') ~ 1 + C(time_step) + C(maze_region) + C(head_direc) + is_moving                + dig_performed{}\".format(neuron, trial_term)\n",
    "formulas['full_subdig']   = \"Q('{}') ~ 1 + C(time_step) + C(maze_region) + C(head_direc) + is_moving + base_in_view                {}\".format(neuron, trial_term)\n",
    "mod_names = list(formulas.keys())\n",
    "df2 = df[['trial', 'gameState', 'maze_region', '46-1']].to_csv('mdl_place_46-1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section to organize spiking data into a table to determin the # spikes per maze segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_neurons = event_spikes.column_map.get('neurons')\n",
    "which_neuron = all_neurons[5]\n",
    "keep_cols = ['trial', 'gameState', 'time_step', 'maze_region', 'head_direc', 'is_moving', \n",
    "             'base_in_view', 'gold_in_view', 'dig_performed', which_neuron]\n",
    "rows = {'gameState':'Encoding'}\n",
    "df = get_df_subset(event_spikes.event_spikes.copy(), columns = keep_cols, rows = rows)\n",
    "df\n",
    "\n",
    "# df.insert(4, 'duration', df['stop_time']-df['start_time'])\n",
    "# df = df.drop(columns=['start_time', 'stop_time'])\n",
    "\n",
    "# Let's print the first entries\n",
    "# in all the groups formed.\n",
    "df_group = df.groupby(['maze_region']).sum()\n",
    "df_group.insert(3, 'rate', df_group[which_cell]/df_group['duration']*1000)\n",
    "df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    reload(time_bin_analysis)\n",
    "\n",
    "# Parallel processing\n",
    "for subj_sess_neuron in subj_sess_neurons:\n",
    "    _start_time = time()\n",
    "    print(subj_sess_neuron)\n",
    "    _ = model_unit_fr_parallel(subj_sess_neuron)\n",
    "    print('{:.1f}s'.format(time() - start_time))\n",
    "\n",
    "print('Done in {:.1f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subj_sess_neurons = subj_sess_neurons[23]\n",
    "subj_sess_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "with open('U554_ses0-46-1-ols-time_bin-model_pairs.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# %cd /home1/cjmac/projects/time_cells/analysis/unit_to_behav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
