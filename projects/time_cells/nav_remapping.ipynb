{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nav_remapping.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /usr/global/Anaconda/2019-10/envs/cml37/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /usr/global/Anaconda/2019-10/envs/cml37/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /usr/global/Anaconda/2019-10/envs/cml37/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /usr/global/Anaconda/2019-10/envs/cml37/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /usr/global/Anaconda/2019-10/envs/cml37/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /usr/global/Anaconda/2019-10/envs/cml37/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /usr/global/Anaconda/2019-10/envs/cml37/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /usr/global/Anaconda/2019-10/envs/cml37/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "# General\n",
    "import sys\n",
    "import os\n",
    "import os.path as op\n",
    "from time import time\n",
    "import warnings\n",
    "from collections import OrderedDict as od\n",
    "from importlib import reload\n",
    "from glob import glob\n",
    "import itertools\n",
    "import h5py\n",
    "\n",
    "# Scientific\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 999\n",
    "import scipy.io as sio\n",
    "\n",
    "# Stats\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import random\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.decomposition import PCA\n",
    "from astropy.convolution import Gaussian2DKernel\n",
    "from astropy.convolution import convolve\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# from matplotlib_venn import venn2\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.patches as patches\n",
    "mpl.rcParams['grid.linewidth'] = 0.1\n",
    "mpl.rcParams['grid.alpha'] = 0.75\n",
    "mpl.rcParams['lines.linewidth'] = 1\n",
    "mpl.rcParams['lines.markersize'] = 3\n",
    "mpl.rcParams['xtick.labelsize'] = 12\n",
    "mpl.rcParams['ytick.labelsize'] = 12\n",
    "mpl.rcParams['xtick.major.width'] = 0.8\n",
    "mpl.rcParams['ytick.major.width'] = 0.8\n",
    "colors = ['1f77b4', 'd62728', '2ca02c', 'ff7f0e', '9467bd', \n",
    "          '8c564b', 'e377c2', '7f7f7f', 'bcbd22', '17becf']\n",
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler('color', colors)\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.formatter.offset_threshold'] = 2\n",
    "mpl.rcParams['axes.labelsize'] = 14\n",
    "mpl.rcParams['axes.labelpad'] = 8\n",
    "mpl.rcParams['axes.titlesize'] = 16\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['axes.axisbelow'] = True\n",
    "mpl.rcParams['legend.loc'] = 'upper right'\n",
    "mpl.rcParams['legend.fontsize'] = 14\n",
    "mpl.rcParams['legend.frameon'] = False\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "mpl.rcParams['figure.titlesize'] = 16\n",
    "mpl.rcParams['figure.figsize'] = (10, 4) \n",
    "mpl.rcParams['figure.subplot.wspace'] = 0.25 \n",
    "mpl.rcParams['figure.subplot.hspace'] = 0.25 \n",
    "mpl.rcParams['font.sans-serif'] = ['Helvetica']\n",
    "mpl.rcParams['savefig.format'] = 'pdf'\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "# Personal\n",
    "sys.path.append('/home1/cjmac/code/general')\n",
    "sys.path.append('/home1/cjmac/code/manning_replication')\n",
    "sys.path.append('/home1/cjmac/code/projects/')\n",
    "import data_io as dio\n",
    "import array_operations as aop\n",
    "from eeg_plotting import plot_trace, plot_trace2\n",
    "from time_cells import spike_sorting, spike_preproc, events_preproc, time_bin_analysis, time_cell_plots, remapping\n",
    "\n",
    "font = {'tick': 12,\n",
    "        'label': 14,\n",
    "        'annot': 12,\n",
    "        'fig': 16}\n",
    "\n",
    "# Colors\n",
    "n = 4\n",
    "c = 2\n",
    "colors = [sns.color_palette('Blues', n)[c], \n",
    "          sns.color_palette('Reds', n)[c], \n",
    "          sns.color_palette('Greens', n)[c],\n",
    "          sns.color_palette('Purples', n)[c],\n",
    "          sns.color_palette('Oranges', n)[c],\n",
    "          sns.color_palette('Greys', n)[c],\n",
    "          sns.color_palette('YlOrBr', n+3)[c],\n",
    "          'k']\n",
    "cmap = sns.palettes.blend_palette((colors[0], \n",
    "                                   'w',\n",
    "                                   colors[1]), 501)\n",
    "\n",
    "colws = od([('1', 6.55),\n",
    "            ('2-1/2', 3.15),\n",
    "            ('2-1/3', 2.1),\n",
    "            ('2-2/3', 4.2),\n",
    "            ('3', 2.083),\n",
    "            ('4', 1.525),\n",
    "            ('5', 1.19),\n",
    "            ('6', 0.967),\n",
    "            (1, 2.05),\n",
    "            (2, 3.125),\n",
    "            (3, 6.45),\n",
    "            ('nat1w', 3.50394),\n",
    "            ('nat2w', 7.20472),\n",
    "            ('natl', 9.72441)])\n",
    "\n",
    "proj_dir = '/home1/cjmac/projects/time_cells'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 subjects, 1 sessions\n"
     ]
    }
   ],
   "source": [
    "# Get sessions.\n",
    "sessions = np.unique([op.basename(f).split('-')[0] \n",
    "                      for f in glob(op.join(proj_dir, 'analysis', 'events', '*.pkl'))])\n",
    "sessions = np.delete(sessions, 0)\n",
    "print('{} subjects, {} sessions'.format(len(np.unique([x.split('_')[0] for x in sessions])), len(sessions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_single_file = True\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "# Load all time OLS result files.\n",
    "# filename = op.join(proj_dir, 'analysis', 'unit_to_behav', 'all_units_time',\n",
    "#                    'ols-time_bin-model_pairs-457units.pkl')\n",
    "# cjm change\n",
    "# Load all time OLS result files.\n",
    "filename = op.join(proj_dir, 'analysis', 'unit_to_behav',\n",
    "                   'U554_ses0-46-1-ols-time_bin-model_pairs.pkl'\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_single_file and op.exists(filename)\n",
    "print(ols_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'fr_max_ind' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e4b0487658ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspike_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m \u001b[0micol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mols_pairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fr_max_ind'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'fr_max_ind10'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mols_pairs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mols_pairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0micol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fr_max_ind10'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mols_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spike_mat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_fr_max_ind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'fr_max_ind' is not in list"
     ]
    }
   ],
   "source": [
    "if load_single_file and op.exists(filename):\n",
    "    ols_pairs = dio.open_pickle(filename)\n",
    "else:\n",
    "    ols_pairs_files = glob(op.join(proj_dir, 'analysis', 'unit_to_behav', '*-time_bin-model_pairs.pkl'))\n",
    "    print('Found OLS outputs for {} neurons'.format(len(ols_pairs_files)))\n",
    "\n",
    "    warnings.filterwarnings('ignore')\n",
    "    bad_files = []\n",
    "    ols_pairs = pd.DataFrame([])\n",
    "    for filename in ols_pairs_files:\n",
    "        try:\n",
    "            ols_pairs = pd.concat((ols_pairs, dio.open_pickle(filename)))\n",
    "        except:\n",
    "            bad_files.append(filename)\n",
    "    ols_pairs = ols_pairs.sort_values(['subj_sess', 'neuron']).reset_index(drop=True)\n",
    "    warnings.resetwarnings()\n",
    "\n",
    "    # Restrict dataframe rows to navigation periods.\n",
    "    keep_cols = ['subj_sess', 'neuron', 'gameState', 'testvar', 'full', 'llf_full', 'lr', 'z_lr', 'emp_pval']\n",
    "    # ols_pairs = ols_pairs.query(\"(gameState==['Encoding', 'Retrieval'])\")[keep_cols].reset_index(drop=True)\n",
    "    ols_pairs = ols_pairs[keep_cols].reset_index(drop=True)\n",
    "\n",
    "    # Organize categorical columns.\n",
    "    test_vars = ['time', 'place', 'head_direc', 'is_moving', 'base_in_view', 'gold_in_view', 'dig_performed']\n",
    "    test_var_cat = pd.CategoricalDtype(test_vars, ordered=True)\n",
    "    ols_pairs['testvar'] = ols_pairs['testvar'].astype(test_var_cat)\n",
    "\n",
    "#     full_models = ['time', 'time_place', 'full']\n",
    "#     full_model_cat = pd.CategoricalDtype(full_models, ordered=True)\n",
    "#     ols_pairs['full'] = ols_pairs['full'].astype(full_model_cat)\n",
    "\n",
    "    # Add new columns.\n",
    "    roi_map = spike_preproc.roi_mapping(n=3)\n",
    "    val_map = od([('hem', []),\n",
    "                  ('roi', []),\n",
    "                  ('roi_gen', []),\n",
    "                  ('spike_mat'        , []),\n",
    "                  ('mean_frs'         , []),\n",
    "                  ('sem_frs'          , []),\n",
    "                  ('fr_mean'          , []),\n",
    "                  ('fr_max'           , []),\n",
    "                  ('fr_max_ind'       , []),\n",
    "                  ('sparsity'         , [])])\n",
    "    for idx, row in ols_pairs.iterrows():\n",
    "        if 'event_spikes' not in dir():\n",
    "            event_spikes = time_bin_analysis.load_event_spikes(row['subj_sess'], verbose=False)\n",
    "        elif event_spikes.subj_sess != row['subj_sess']:\n",
    "            event_spikes = time_bin_analysis.load_event_spikes(row['subj_sess'], verbose=False)\n",
    "        hemroi = spike_preproc.roi_lookup(row['subj_sess'], row['neuron'].split('-')[0])\n",
    "        hem = hemroi[0]\n",
    "        roi = hemroi[1:]\n",
    "        roi_gen = roi_map.get(roi, np.nan)\n",
    "        spike_mat = event_spikes.get_spike_mat(row['neuron'], row['gameState'])\n",
    "        mean_frs = time_bin_analysis.get_mean_frs(spike_mat) * 2\n",
    "        sem_frs = time_bin_analysis.get_sem_frs(spike_mat) * 2\n",
    "        fr_mean = np.mean(mean_frs.values)\n",
    "        fr_max = np.max(mean_frs.values)\n",
    "        fr_max_ind = np.argmax(mean_frs.values)\n",
    "        sparsity = time_bin_analysis.get_sparsity(spike_mat)\n",
    "\n",
    "        val_map['hem'].append(hem)\n",
    "        val_map['roi'].append(roi)\n",
    "        val_map['roi_gen'].append(roi_gen)\n",
    "        val_map['spike_mat'].append(spike_mat.values.tolist())\n",
    "        val_map['mean_frs'].append(mean_frs.tolist())\n",
    "        val_map['sem_frs'].append(sem_frs.tolist())\n",
    "        val_map['fr_mean'].append(fr_mean)\n",
    "        val_map['fr_max'].append(fr_max)\n",
    "        val_map['fr_max_ind'].append(fr_max_ind)\n",
    "        val_map['sparsity'].append(sparsity)\n",
    "\n",
    "    ols_pairs.insert(0, 'subj', ols_pairs['subj_sess'].apply(lambda x: x.split('_')[0]))\n",
    "    ols_pairs.insert(2, 'subj_sess_unit', ols_pairs.apply(lambda x: '{}-{}'.format(x['subj_sess'], x['neuron']), axis=1))\n",
    "    ols_pairs.insert(4, 'hem', val_map['hem'])\n",
    "    ols_pairs.insert(5, 'roi', val_map['roi'])\n",
    "    ols_pairs.insert(6, 'roi_gen', val_map['roi_gen'])\n",
    "    for col_name in val_map:\n",
    "        if col_name not in ols_pairs:\n",
    "            ols_pairs[col_name] = val_map[col_name]\n",
    "    roi_gen_cat = ['Hippocampus', 'MTL', 'Cortex']\n",
    "    ols_pairs['roi_gen'] = ols_pairs['roi_gen'].astype(pd.CategoricalDtype(roi_gen_cat, ordered=True))\n",
    "    ols_pairs.insert(ols_pairs.columns.tolist().index('roi_gen')+1, 'roi_gen2', ols_pairs['roi_gen'].tolist())\n",
    "    ols_pairs.loc[ols_pairs['roi_gen']=='Hippocampus', 'roi_gen2'] = 'MTL'\n",
    "    ols_pairs['roi_gen2'] = ols_pairs['roi_gen2'].astype(pd.CategoricalDtype(['MTL', 'Cortex'], ordered=True))\n",
    "    \n",
    "    # Test significance.\n",
    "    alpha = 0.05\n",
    "    ols_pairs['sig'] = False\n",
    "    ols_pairs.loc[((ols_pairs['emp_pval']<alpha)), 'sig'] = True\n",
    "    ols_pairs['sig_holm'] = ols_pairs.groupby(['subj_sess_unit', 'gameState', 'full'])['emp_pval'].transform(lambda x: sm.stats.multipletests(x, alpha, method='holm')[0])\n",
    "\n",
    "    print('{} bad files'.format(len(bad_files)))\n",
    "\n",
    "    \n",
    "def _fr_max_ind(spike_mat, bins=10):\n",
    "    return np.argmax([v.sum() for v in np.split(np.sum(spike_mat, axis=0), bins)])\n",
    "\n",
    "icol = ols_pairs.columns.tolist().index('fr_max_ind') + 1\n",
    "if 'fr_max_ind10' not in ols_pairs:\n",
    "    ols_pairs.insert(icol, 'fr_max_ind10', ols_pairs['spike_mat'].apply(lambda x: _fr_max_ind(x, 10)))\n",
    "if 'fr_max_ind5' not in ols_pairs:\n",
    "    ols_pairs.insert(icol+2, 'fr_max_ind5', ols_pairs['spike_mat'].apply(lambda x: _fr_max_ind(x, 5)))\n",
    "\n",
    "ols_pairs = ols_pairs.sort_values(['subj_sess_unit', 'gameState', 'testvar']).reset_index(drop=True)\n",
    "\n",
    "print('ols_pairs:', ols_pairs.shape)\n",
    "\n",
    "print('Done in {:.1f}s'.format(time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cells = len(set(ols_pairs['subj_sess_unit'].tolist()))\n",
    "\n",
    "sig_cells = od([])\n",
    "for game_state in ['Delay1', 'Encoding', 'Delay2', 'Retrieval']:\n",
    "    for testvar in ols_pairs['testvar'].unique():\n",
    "        qry = \"(gameState=='{}') & (testvar=='{}') & (full=='full') & (sig==True) & (beta_abs_max>0)\".format(game_state, testvar)\n",
    "        _neurons = set(ols_pairs.query(qry)['subj_sess_unit'].tolist())\n",
    "        k = '{}-{}'.format(game_state, testvar)\n",
    "        if len(_neurons) > 0:\n",
    "            sig_cells[k] = _neurons\n",
    "            print(k, len(sig_cells[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMAC Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_period_feature_coding = pd.DataFrame(data=0, index = ['Delay1', 'Encoding', 'Delay2', 'Retrieval'], columns= ['time', 'place']) \n",
    "neuron_list = ols_pairs.neuron.unique()\n",
    "gameState_list = ['Delay1', 'Encoding', 'Delay2', 'Retrieval']\n",
    "feature_list = ['time', 'place']\n",
    "\n",
    "for which_gameState in gameState_list:\n",
    "    for which_feature in feature_list:\n",
    "        for which_neuron in neuron_list:\n",
    "            if not ((which_gameState == 'Delay1' and which_feature == 'place') or (which_gameState == 'Delay2' and which_feature == 'place')):\n",
    "                if ols_pairs.loc[(ols_pairs.gameState == which_gameState) &  (ols_pairs.testvar == which_feature) & (ols_pairs.neuron == which_neuron)].reset_index().sig[0]:\n",
    "                    trial_period_feature_coding.loc[which_gameState, which_feature] += 1    \n",
    "                    \n",
    "fig00, ax00 = plt.subplots(figsize=(6, 6), ncols=1 )\n",
    "cmap00 = plt.get_cmap('binary')\n",
    "sns.heatmap(trial_period_feature_coding.values,\n",
    "            annot=True,\n",
    "            cmap = mpl.colors.ListedColormap(['white']),\n",
    "            annot_kws={\"size\": 20 },\n",
    "            norm = None,\n",
    "            cbar = False,\n",
    "            cbar_kws = {\"format\": mpl.ticker.ScalarFormatter() },\n",
    "            clip_on  = False,\n",
    "            linecolor = 'k',\n",
    "            linewidth = 1,\n",
    "            xticklabels = ['Time', 'Place'],\n",
    "            yticklabels = ['Delay1', 'Encoding', 'Delay2', 'Retrieval'],\n",
    "            ax=ax00\n",
    "           )\n",
    "plt.yticks( axes = ax00, rotation = 0)\n",
    "ax00.set_ylabel('Trial Period', size=24)\n",
    "ax00.set_xlabel('Feature Coding', size=24 )\n",
    "ax00.xaxis.set_ticks_position('top')\n",
    "ax00.xaxis.set_label_position('top')\n",
    "# make the heatplot axes boundary visible bc by default it is not\n",
    "ax00.spines[:].set_visible( True )\n",
    "# # thicken the heatplot axes boundary\n",
    "ax00.spines[:].set_linewidth( 2 )\n",
    "plt.tight_layout()\n",
    "plt.savefig('trial_period_counts_time_space.pdf', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_pairs.loc[(ols_pairs.neuron == '46-1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for which_neuron in ols_pairs.neuron.unique():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test independence of proportions between\n",
    "# Delay1 and Delay2 time cells.\n",
    "alpha = 0.05\n",
    "ctab = [[n_cells - len(sig_cells['Delay1-time']), len(sig_cells['Delay1-time'])],\n",
    "        [n_cells - len(sig_cells['Delay2-time']), len(sig_cells['Delay2-time'])]]\n",
    "\n",
    "chi2, pval, df, _ = stats.chi2_contingency(ctab, correction=True)\n",
    "print('contingency table : {}'.format(ctab),\n",
    "      'χ2({}) = {:.1f}, p = {:.6f}, reject = {}'.format(df, chi2, pval, pval<alpha),\n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test independence of overlap between cells coding\n",
    "# for each game state x behavioral variable pair.\n",
    "alpha = 0.05\n",
    "\n",
    "n_cells = len(set(ols_pairs['subj_sess_unit'].tolist()))\n",
    "gs_vars = list(sig_cells.keys())\n",
    "pairs = [[gs_vars[ii], gs_vars[jj]]\n",
    "         for ii in range(len(sig_cells))\n",
    "         for jj in range(len(sig_cells))\n",
    "         if (ii > jj)]\n",
    "\n",
    "cols = ['gameState1', 'testvar1', 'gameState2', 'testvar2',\n",
    "        'sig0', 'sig1', 'sig2', 'sig1or2',\n",
    "        'sig1and2', 'sig1and2_exp', 'obs_sub_exp', 'obs_div_exp', 'chi2',\n",
    "        'pval']\n",
    "overlap = []\n",
    "for k1, k2 in pairs:\n",
    "    gs1, tv1 = k1.split('-')\n",
    "    gs2, tv2 = k2.split('-')\n",
    "    sig1or2 = len(sig_cells[k1] | sig_cells[k2])\n",
    "    sig0 = n_cells - sig1or2\n",
    "    sig1 = len(sig_cells[k1])\n",
    "    sig2 = len(sig_cells[k2])\n",
    "    sig1and2 = len(sig_cells[k1] & sig_cells[k2])\n",
    "    ctab = [(sig0, sig1),\n",
    "            (sig2, sig1and2)]\n",
    "    chi2, pval, df, ctab_exp = stats.chi2_contingency(ctab, correction=True)\n",
    "    sig1and2_exp = ctab_exp[1, 1]\n",
    "    obs_sub_exp = sig1and2 - sig1and2_exp\n",
    "    obs_div_exp = sig1and2 / sig1and2_exp\n",
    "    overlap.append([gs1, tv1, gs2, tv2,\n",
    "                    sig0, sig1, sig2, sig1or2,\n",
    "                    sig1and2, sig1and2_exp, obs_sub_exp, obs_div_exp, chi2,\n",
    "                    pval])\n",
    "    \n",
    "overlap = pd.DataFrame(overlap, columns=cols)\n",
    "\n",
    "# Assess significance.\n",
    "overlap['sig'] = overlap['pval'] < alpha\n",
    "overlap['pval_fdr'] = sm.stats.multipletests(overlap['pval'], alpha, method='fdr_bh')[1]\n",
    "overlap['sig_fdr'] = sm.stats.multipletests(overlap['pval'], alpha, method='fdr_bh')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sig\n",
    "overlap.sort_values('chi2', ascending=0).query(\"(testvar1=='time') & (testvar2=='time')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_col = 'obs_div_exp'\n",
    "savefig = 0\n",
    "overwrite = 0\n",
    "figsize = (colws[2], colws[2]/2.5)\n",
    "dpi = 1200\n",
    "font = {'tick': 6, 'label': 7, 'annot': 6, 'fig': 8}\n",
    "_cmap = ['#296eb4', '#e10600']\n",
    "cbar_ticks = [0, 0.05, 0.1, 0.15, 0.2]\n",
    "ticklength = 3\n",
    "tickpad = 3\n",
    "spine_lw = 0.5\n",
    "spine_len = 1.8\n",
    "labelpad = 2\n",
    "\n",
    "# Get the behavioral matrix data to plot.\n",
    "_gs_vars = ['Delay1-time', 'Delay2-time', 'Encoding-time', 'Retrieval-time',\n",
    "            'Encoding-place', 'Retrieval-place', 'Encoding-head_direc', 'Retrieval-head_direc', 'Encoding-is_moving', 'Retrieval-is_moving',\n",
    "            'Encoding-base_in_view', 'Retrieval-base_in_view', 'Encoding-gold_in_view', 'Retrieval-dig_performed']\n",
    "qry = \"(gameState1=='{}') & (testvar1=='{}') & (gameState2=='{}') & (testvar2=='{}')\"\n",
    "dat = {left_col : np.ones([len(gs_vars), len(gs_vars)]) * np.nan,\n",
    "       'chi2'     : np.ones([len(gs_vars), len(gs_vars)]) * np.nan}\n",
    "for ii in range(len(_gs_vars)):\n",
    "    for jj in range(len(_gs_vars)):\n",
    "        if ii <= jj:\n",
    "            continue\n",
    "        gs1, tv1 = _gs_vars[ii].split('-')\n",
    "        gs2, tv2 = _gs_vars[jj].split('-')\n",
    "        _df = overlap.query(qry.format(gs1, tv1, gs2, tv2))\n",
    "        if len(_df) == 0:\n",
    "            _df = overlap.query(qry.format(gs2, tv2, gs1, tv1))\n",
    "        assert len(_df) == 1\n",
    "\n",
    "        dat[left_col][ii, jj] = _df.iloc[0][left_col]\n",
    "        if _df.iloc[0]['sig_fdr'] == True:\n",
    "            dat['chi2'][ii, jj] = _df.iloc[0]['chi2']\n",
    "        else:\n",
    "            dat['chi2'][ii, jj] = _df.iloc[0]['chi2'] # 0\n",
    "            \n",
    "# Make the plots.\n",
    "plt.close('')\n",
    "fig, ax = plt.subplots(1, 2, figsize=figsize, dpi=dpi)\n",
    "ax = np.ravel(ax)\n",
    "\n",
    "# Plot the data.\n",
    "for iax, col in enumerate([left_col, 'chi2']):\n",
    "    if iax==0:\n",
    "        vmin = overlap[col].min()\n",
    "    else:\n",
    "        vmin = overlap[col].min()\n",
    "    vmax = overlap[col].max()\n",
    "    print(vmin, vmax)\n",
    "    \n",
    "    ax[iax] = sns.heatmap(dat[col], vmin=vmin, vmax=vmax, square=True, ax=ax[iax],\n",
    "                          cmap='rocket')\n",
    "    col_labels = np.arange(len(_gs_vars))\n",
    "    ax[iax].tick_params(labelsize=font['tick'], pad=1, length=spine_len, width=spine_lw)\n",
    "    ax[iax].set_xticks(np.arange(0, len(col_labels), 1) + 0.5)\n",
    "    ax[iax].set_xticklabels(col_labels, rotation=90)\n",
    "    ax[iax].set_yticks(np.arange(0, len(col_labels), 1) + 0.5)\n",
    "    ax[iax].set_yticklabels(col_labels, rotation=0)\n",
    "    ax[iax].set_xlabel('')\n",
    "    ax[iax].set_ylabel('')\n",
    "    \n",
    "    cbar = ax[iax].collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=font['tick'], pad=tickpad, length=spine_len, width=spine_lw)\n",
    "    if col == left_col:\n",
    "        cbar.set_ticks([0.7, 1, 1.3, 1.6])\n",
    "        #cbar.set_clim([-10, 10])\n",
    "        #cbar.set_ticks([-10, -5, 0, 5, 10])\n",
    "    elif col == 'chi2':\n",
    "#         cbar.set_ticks([0, 5, 10, 15, 20, 25])\n",
    "        cbar.set_clim([0, 7])\n",
    "        cbar.set_ticks([0, 2, 4, 6])\n",
    "    cbar.set_label(col, fontsize=font['tick'], labelpad=labelpad)\n",
    "    \n",
    "fig.tight_layout(w_pad=0)\n",
    "print([(ii, _gs_vars[ii]) for ii in range(len(_gs_vars))])\n",
    "\n",
    "if savefig:\n",
    "    n_units = ols_pairs['subj_sess_unit'].unique().size\n",
    "    filename = op.join(proj_dir, 'figs', 'plot_remapping', 'behavioral_response_overlap-{}units.pdf'.format(n_units))\n",
    "    if overwrite or not op.exists(filename):\n",
    "        fig.savefig(filename, format='pdf', bbox_inches='tight')\n",
    "        fig.savefig(filename.replace('pdf', 'png'), format='png', dpi=dpi, bbox_inches='tight')\n",
    "        \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Venn diagrams to show the overlap between\n",
    "# game state x behavioral variable pairs.\n",
    "savefig = 0\n",
    "overwrite = 0\n",
    "figsize = (colws[1], colws[1])\n",
    "dpi = 1200\n",
    "font = {'tick': 8, 'label': 8, 'annot': 8, 'fig': 10}\n",
    "_cmap = ['#296eb4', '#e10600']\n",
    "spine_lw = 0.5\n",
    "\n",
    "# -------------------\n",
    "pairs = [[list(sig_cells.keys())[ii], list(sig_cells.keys())[jj]]\n",
    "         for ii in range(len(sig_cells))\n",
    "         for jj in range(len(sig_cells))\n",
    "         if (ii < jj)]\n",
    "\n",
    "for idx, row in overlap.iterrows():\n",
    "    plt.close()\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize, dpi=300)\n",
    "    k1 = '{}-{}'.format(row['gameState1'], row['testvar1'])\n",
    "    k2 = '{}-{}'.format(row['gameState2'], row['testvar2'])\n",
    "    \n",
    "    area = (row['sig1or2'] / n_cells)\n",
    "    _venn = venn2([sig_cells[k1], sig_cells[k2]], normalize_to=area,\n",
    "                   set_labels=None, set_colors=_cmap, alpha=0.5, ax=ax)\n",
    "    \n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_visible(True)\n",
    "        ax.spines[axis].set_color('k')\n",
    "        ax.spines[axis].set_linewidth(spine_lw)\n",
    "\n",
    "    if savefig:\n",
    "        filename = op.join(proj_dir, 'figs', 'plot_remapping',\n",
    "                           'venn_{}-{}units_{}-{}units.pdf'\n",
    "                           .format(k1, len(sig_cells[k1]), k2, len(sig_cells[k2])))\n",
    "        if overwrite or not op.exists(filename):\n",
    "            fig.savefig(filename, format='pdf', bbox_inches='tight', pad_inches=0)\n",
    "            fig.savefig(filename.replace('pdf', 'png'), format='png', dpi=dpi, bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "print(k1, k2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_pairs.query(\"(full==['time', 'full'])\").groupby(['gameState', 'testvar'], observed=True).agg({'sig': lambda x: '{}/{} ({:.1%})'.format(np.sum(x), len(x), np.mean(x))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_pairs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cells = ols_pairs['subj_sess_unit'].unique()\n",
    "qry = \"(gameState==['Delay1', 'Delay2']) & (testvar=='time') & (sig==True) & (beta_abs_max>0)\"\n",
    "nav_time_cells = ols_pairs.query(qry)['subj_sess_unit'].unique()\n",
    "nav_time_cells.size, all_cells.size, nav_time_cells.size / all_cells.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cells = ols_pairs['subj_sess_unit'].unique()\n",
    "qry = \"(gameState==['Encoding', 'Retrieval']) & (testvar=='time') & (sig==True) & (beta_abs_max>0)\"\n",
    "nav_time_cells = ols_pairs.query(qry)['subj_sess_unit'].unique()\n",
    "nav_time_cells.size, all_cells.size, nav_time_cells.size / all_cells.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cells = ols_pairs['subj_sess_unit'].unique()\n",
    "qry = \"(gameState==['Delay1', 'Encoding', 'Delay2', 'Retrieval']) & (testvar=='time') & (sig==True) & (beta_abs_max>0)\"\n",
    "nav_time_cells = ols_pairs.query(qry)['subj_sess_unit'].unique()\n",
    "nav_time_cells.size, all_cells.size, nav_time_cells.size / all_cells.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which time cells significantly remapped between Encoding and Retrieval\n",
    "# by comparing the mean difference in firing rate correlation between\n",
    "# within-interval vs. between-inteval trial pairs.\n",
    "sim_func = 'pearson'\n",
    "n_perm = 1000\n",
    "alpha = 0.05\n",
    "save_output = True\n",
    "overwrite = True\n",
    "game_state_pairs = [('Delay1',   'Delay2',    'prop'),\n",
    "                    ('Encoding', 'Retrieval', 'prop'),\n",
    "                    ('Delay1',   'Encoding',  'first10'),\n",
    "                    ('Delay1',   'Retrieval', 'first10'),\n",
    "                    ('Delay1',   'Encoding',  'last10'),\n",
    "                    ('Delay1',   'Retrieval', 'last10'),\n",
    "                    ('Delay1',   'Encoding',  'prop'),\n",
    "                    ('Delay1',   'Retrieval', 'prop'),\n",
    "                    ('Encoding', 'Delay2',    'first10'),\n",
    "                    ('Delay2',   'Retrieval', 'first10'),\n",
    "                    ('Encoding', 'Delay2',    'last10'),\n",
    "                    ('Delay2',   'Retrieval', 'last10'),\n",
    "                    ('Encoding', 'Delay2',    'prop'),\n",
    "                    ('Delay2',   'Retrieval', 'prop')]\n",
    "\n",
    "start_time = time()\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "time_remapping = []    \n",
    "# Calculate remapping scores for each contrast between intervals.\n",
    "for (gs1, gs2, contrast) in game_state_pairs:\n",
    "    qry = \"(gameState==['{}', '{}']) & (testvar=='time') & (sig==True) & (beta_abs_max>0)\".format(gs1, gs2)\n",
    "    _time_cells = ols_pairs.query(qry)['subj_sess_unit'].unique().tolist()\n",
    "    qry = \"(gameState==['{}', '{}']) & (testvar=='time') & (subj_sess_unit=={})\".format(gs1, gs2, _time_cells)\n",
    "    grp = (ols_pairs.sort_values(['subj_sess', 'neuron', 'gameState'])\n",
    "           .query(qry)\n",
    "           .groupby(['subj_sess_unit'], observed=True))\n",
    "\n",
    "    for neuron, _df in grp:\n",
    "        assert len(_df) == 2\n",
    "        assert _df.iloc[0]['gameState'] == gs1\n",
    "        assert _df.iloc[1]['gameState'] == gs2\n",
    "        subj_sess = _df.iloc[0]['subj_sess']\n",
    "        nsig = np.sum(_df['sig'].astype(int) * (_df['beta_abs_max'] > 0).astype(int))\n",
    "        assert nsig in [1, 2]\n",
    "\n",
    "        # Load event_spikes.\n",
    "        if 'event_spikes' not in dir():\n",
    "            event_spikes = time_bin_analysis.load_event_spikes(subj_sess, verbose=False)\n",
    "        elif event_spikes.subj_sess != subj_sess:\n",
    "            event_spikes = time_bin_analysis.load_event_spikes(subj_sess, verbose=False)\n",
    "        \n",
    "        spike_mats = od([])\n",
    "        for _, row in _df.iterrows():\n",
    "            spike_mats[row['gameState']] = event_spikes.get_spike_mat(row['neuron'], row['gameState'], column='time_bin')\n",
    "            \n",
    "            # Aggregate time bins.\n",
    "            if ('Delay' in row['gameState']) or (contrast == 'prop'):\n",
    "                spike_mats[row['gameState']] = np.array([np.mean(x, axis=-1) for x in np.split(spike_mats[row['gameState']].values, 10, axis=1)]).T\n",
    "            else:\n",
    "                if contrast == 'first10':\n",
    "                    spike_mats[row['gameState']] = np.array([np.mean(x, axis=-1) for x in np.split(spike_mats[row['gameState']].values, 30, axis=1)]).T[:, :10]\n",
    "                elif contrast == 'last10':\n",
    "                    spike_mats[row['gameState']] = np.array([np.mean(x, axis=-1) for x in np.split(spike_mats[row['gameState']].values, 30, axis=1)]).T[:, -10:]\n",
    "        \n",
    "        # Get firing vector correlations between trial pairs.\n",
    "        pairwise_sims = remapping.trial_pair_remapping(spike_mats, sim_func=sim_func)\n",
    "        mean_sims = {k : np.mean(v) for k, v in pairwise_sims.items()}\n",
    "        mean_sims['within'] = np.max((mean_sims[gs1], mean_sims[gs2]))\n",
    "        asym = mean_sims['within'] - mean_sims['between']\n",
    "        \n",
    "        # Compute the null distribution.\n",
    "        pairwise_sims_vec = np.concatenate([pairwise_sims[gs1],\n",
    "                                            pairwise_sims[gs2],\n",
    "                                            pairwise_sims['between']]) # cond x trial_pair\n",
    "        divs = np.cumsum((len(pairwise_sims[gs1]), len(pairwise_sims[gs2]), len(pairwise_sims['between'])))[:2]\n",
    "        within_sims_null = []\n",
    "        btwn_sims_null = []\n",
    "        asyms_null = []\n",
    "        for iPerm in range(n_perm):\n",
    "            np.random.shuffle(pairwise_sims_vec)\n",
    "            mean_sims_null = dict(zip([gs1, gs2, 'between'], \n",
    "                                      [np.mean(x) for x in np.split(pairwise_sims_vec, divs)]))\n",
    "            mean_sims_null['within'] = np.max((mean_sims_null[gs1], mean_sims_null[gs2]))\n",
    "            within_sims_null.append(mean_sims_null['within'])\n",
    "            btwn_sims_null.append(mean_sims_null['between'])\n",
    "            asyms_null.append(mean_sims_null['within'] - mean_sims_null['between'])\n",
    "        within_sims_null = np.array(within_sims_null)\n",
    "        btwn_sims_null = np.array(btwn_sims_null)\n",
    "        asyms_null = np.array(asyms_null)\n",
    "        \n",
    "        asym_z = (asym - np.mean(asyms_null)) / np.std(asyms_null)\n",
    "        if asym_z > 0:\n",
    "            asym_z_sign = 1\n",
    "        elif asym_z == 0:\n",
    "            asym_z_sign = 0\n",
    "        else:\n",
    "            asym_z_sign = -1\n",
    "        pval_ind = np.sum(np.abs(asyms_null) >= np.abs(asym))\n",
    "        pval = (1 + pval_ind) / (1 + n_perm)\n",
    "\n",
    "        # Figure out which trial interval has stronger time coding.\n",
    "        # (If only one trial phase is significant, take that one. Otherwise, take whichever\n",
    "        # has the highest info score). Then add time coding info for the stronger trial phase.\n",
    "        z_lr_diff = np.abs(np.diff(_df['z_lr']))[0]\n",
    "        if nsig == 1:\n",
    "            row = _df.query(\"(sig==True)\").iloc[0]\n",
    "        else:\n",
    "            row = _df.sort_values('z_lr', ascending=False).iloc[0]\n",
    "        main_game_state = row['gameState']\n",
    "        z_lr = row['z_lr']\n",
    "        fr_max_ind = row['fr_max_ind']\n",
    "        time_remapping.append([neuron, subj_sess, gs1, gs2, contrast,\n",
    "                               nsig, z_lr_diff, main_game_state, z_lr, fr_max_ind,\n",
    "                               mean_sims['within'], mean_sims['between'],\n",
    "                               asym, asym_z, asym_z_sign, pval_ind, pval])\n",
    "    \n",
    "time_remapping = pd.DataFrame(time_remapping, columns=['neuron', 'subj_sess', 'gameState1', 'gameState2', 'contrast',\n",
    "                                                       'nsig',   'z_lr_diff', 'main_game_state', 'z_lr', 'fr_max_ind',\n",
    "                                                       'r_within', 'r_btwn',\n",
    "                                                       'asym', 'asym_z', 'asym_z_sign', 'pval_ind', 'pval'])\n",
    "time_remapping['sig'] = time_remapping['pval'] < alpha\n",
    "time_remapping['asym_z_cat'] = 0\n",
    "time_remapping.loc[(time_remapping['sig']==True) & (time_remapping['asym_z_sign']==-1), 'asym_z_cat'] = 1\n",
    "time_remapping.loc[(time_remapping['sig']==True) & (time_remapping['asym_z_sign']==1), 'asym_z_cat'] = 2\n",
    "time_remapping['dummy'] = 0\n",
    "unit_to_roi_map = ols_pairs[['subj_sess_unit', 'roi_gen5']].drop_duplicates().set_index('subj_sess_unit')['roi_gen5'].to_dict()\n",
    "time_remapping.insert(2, 'roi_gen5', time_remapping['neuron'].apply(lambda x: unit_to_roi_map[x]))\n",
    "\n",
    "if save_output:\n",
    "    filename = op.join(proj_dir, 'analysis', 'remapping',\n",
    "                       'time_remapping_{}time_cells_{}neurons.pkl'\n",
    "                       .format(time_remapping['neuron'].unique().size, ols_pairs['subj_sess_unit'].unique().size))\n",
    "    if overwrite or not op.exists(filename):\n",
    "        dio.save_pickle(time_remapping, filename)\n",
    "\n",
    "warnings.resetwarnings()\n",
    "print('time_remapping: {}'.format(time_remapping.shape))\n",
    "print('Dont in {:.1f}s'.format(time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max(within)\n",
    "def sum_pct(x):\n",
    "    return '{}/{} ({:.1%})'.format(np.sum(x), x.size, np.sum(x) / len(x))\n",
    "\n",
    "def mean_sem(x):\n",
    "    return '{:.2f} ± {:.2f}'.format(np.mean(x), stats.sem(x))\n",
    "\n",
    "sig_pct = time_remapping.groupby(['gameState1', 'gameState2', 'contrast']).agg({'sig': sum_pct,\n",
    "                                                                      'r_within': mean_sem,\n",
    "                                                                      'r_btwn': mean_sem,\n",
    "                                                                      'asym_z': mean_sem,\n",
    "                                                                      'nsig': lambda x: np.unique(x, return_counts=True)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max(within)\n",
    "def sum_pct(x):\n",
    "    return '{}/{} ({:.1%})'.format(np.sum(x), x.size, np.sum(x) / len(x))\n",
    "\n",
    "def mean_sem(x):\n",
    "    return '{:.2f} ± {:.2f}'.format(np.mean(x), stats.sem(x))\n",
    "\n",
    "(time_remapping\n",
    " .query(\"(sig==True)\")\n",
    " .groupby(['gameState1', 'gameState2', 'contrast'])\n",
    " .agg({'sig': sum_pct,\n",
    "       'r_within': mean_sem,\n",
    "       'r_btwn': mean_sem,\n",
    "       'asym_z': mean_sem,\n",
    "       'asym_z_sign': lambda x: np.unique(x, return_counts=True),\n",
    "       'nsig': lambda x: np.unique(x, return_counts=True),\n",
    "       'main_game_state': lambda x: np.unique(x, return_counts=True)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, dpi=1200)\n",
    "ax = np.ravel(ax)\n",
    "\n",
    "sig_pct['gameStates'] = sig_pct['gameState1'] + sig_pct['gameState2']\n",
    "\n",
    "iax = 0\n",
    "ax[iax] = sns.barplot(x='gameStates', y='sig', hue='contrast', data=sig_pct, ax=ax[iax])\n",
    "ax[iax].tick_params(labelsize=font['tick'], pad=1, length=spine_len, width=spine_lw)\n",
    "ax[iax].set_xlabel('')\n",
    "ax[iax].set_ylabel('% time cells', fontsize=font['label'], labelpad=labelpad-1)\n",
    "\n",
    "ax[iax].get_legend().remove()\n",
    "custom_lines = [Line2D([0], [0], marker='s', color='w', label='Prop.', mfc=colors[0], mew=spine_lw, mec='k', ms=font['annot']),\n",
    "                Line2D([0], [0], marker='s', color='w', label='First 10s', mfc=colors[1], mew=spine_lw, mec='k', ms=font['annot']),\n",
    "                Line2D([0], [0], marker='s', color='w', label='Last 10s', mfc=colors[2], mew=spine_lw, mec='k', ms=font['annot'])]\n",
    "legend = ax[iax].legend(handles=custom_lines, fontsize=font['annot'], bbox_to_anchor=(1, 1), handletextpad=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig = 0\n",
    "overwrite = 0\n",
    "sig_col = 'sig_pos'\n",
    "test_vars = ['time', 'place', 'head_direc', 'base_in_view', 'gold_in_view']\n",
    "xcats = ['Time', 'Place', 'Head\\ndirec.', 'View\\nbase', 'View\\ngold']\n",
    "ylim = [0, 15]\n",
    "yticks = [0, 5, 10, 15]\n",
    "figsize = (colws['2-1/3'], colws['2-1/3']/1.8)\n",
    "font = {'tick': 5, 'label': 6, 'annot': 5}\n",
    "spine_lw = 0.5\n",
    "spine_len = 1.8\n",
    "labelpad = 2\n",
    "cmap = {0: (190, 190, 190), # gray\n",
    "        1: (225, 6, 0), # red\n",
    "        2: (41, 110, 180), # blue\n",
    "        3: (243, 165, 191)} # pink\n",
    "for k in cmap:\n",
    "    cmap[k] = list(np.array(cmap[k])/255)\n",
    "\n",
    "# Graph percent of units that code for each variable of interest.\n",
    "sig_pct = time_remapping.groupby(['gameState1', 'gameState2', 'contrast']).agg({'sig': lambda x: 100 * np.mean(x)}).reset_index()\n",
    "\n",
    "#sig_pct.columns = ['gameState', 'testvar', 'sum', 'pct']\n",
    "sig_pct['gameState'] = sig_pct['gameState'].astype(str)\n",
    "\n",
    "# Make the plot.\n",
    "plt.close()\n",
    "fig, ax = plt.subplots(1, 1, figsize=figsize, dpi=1200)\n",
    "ax = sns.barplot(x='testvar', y='pct', hue='gameState', data=sig_pct, ax=ax,\n",
    "                 palette=['k', cmap[0]], saturation=1, linewidth=spine_lw, edgecolor='k')\n",
    "ax.hlines(2.5, -0.5, 4.5, colors='#e10600', linestyles='dashed', lw=spine_lw)\n",
    "for axis in ['left', 'bottom']:\n",
    "    ax.spines[axis].set_linewidth(spine_lw)\n",
    "ax.tick_params(labelsize=font['tick'], pad=1, length=spine_len, width=spine_lw)\n",
    "ax.set_xticklabels(xcats, fontsize=font['tick'])\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(yticks)\n",
    "ax.set_xlabel('', fontsize=font['label'], labelpad=labelpad)\n",
    "ax.set_ylabel('% neurons', fontsize=font['label'], labelpad=labelpad-1)\n",
    "\n",
    "# ax2 = ax.twinx()\n",
    "# ax2.spines['right'].set_visible(True)\n",
    "# ax2.spines['right'].set_linewidth(spine_lw)\n",
    "# for axis in ['left', 'bottom', 'top']:\n",
    "#     ax2.spines[axis].set_visible(False)\n",
    "# ax2.tick_params(labelsize=font['tick'], pad=1, length=1.5, width=spine_lw)\n",
    "# slope, icpt, *_ = stats.linregress(sig_pct['pct'], sig_pct['sum'])\n",
    "# ax2.set_ylim(icpt + (np.array(ylim) * slope))\n",
    "# ax2.set_yticks(icpt + (np.array(yticks)*slope))\n",
    "# ax2.set_yticklabels(np.rint(icpt + (np.array(yticks)*slope)).astype(int))\n",
    "# ax2.set_ylabel('No. units', fontsize=font['label'], labelpad=labelpad)\n",
    "\n",
    "ax.get_legend().remove()\n",
    "custom_lines = [Line2D([0], [0], marker='s', color='w', label='Encoding', mfc='k', mew=spine_lw, mec='k', ms=font['annot']),\n",
    "                Line2D([0], [0], marker='s', color='w', label='Retrieval', mfc=cmap[0], mew=spine_lw, mec='k', ms=font['annot'])]\n",
    "legend = ax.legend(handles=custom_lines, fontsize=font['annot'], bbox_to_anchor=(0.33, 1.08), handletextpad=0)\n",
    "\n",
    "if savefig:\n",
    "    n_units = np.unique(ols_pairs['subj_sess_unit']).size\n",
    "    filename = op.join(proj_dir, 'figs', 'plot_navigation',\n",
    "                       'pct_sig-time_place_hd_gold_base-{}units.pdf'.format(n_units))\n",
    "    if overwrite or not op.exists(filename):\n",
    "        fig.savefig(filename, format='pdf', bbox_inches='tight')\n",
    "            \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean(within)\n",
    "def sum_pct(x):\n",
    "    return '{}/{} ({:.1%})'.format(np.sum(x), x.size, np.sum(x) / len(x))\n",
    "\n",
    "time_remapping.groupby(['gameState1', 'gameState2', 'contrast']).agg({'sig': sum_pct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.pearsonr(time_remapping['z_lr'], time_remapping['asym_z']))\n",
    "time_remapping.groupby('asym_z_cat').agg({'neuron': len, 'z_lr': lambda x: '{:.1f} ± {:.1f}'.format(np.mean(x), stats.sem(x))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.pearsonr(time_remapping['z_lr'], time_remapping['asym_z']))\n",
    "time_remapping.query(\"(nsig==2)\").groupby('asym_z_cat').agg({'neuron': len, 'z_lr': lambda x: '{:.1f} ± {:.1f}'.format(np.mean(x), stats.sem(x))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_remapping.groupby(['nsig', 'roi_gen'])['asym_z_cat'].apply(lambda x: '{}/{}; {:.1%}'.format(np.sum(x==2), len(x), np.mean(x==2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_remapping['_fr_max_ind'] = np.floor(time_remapping['fr_max_ind'] / 12)\n",
    "time_remapping.groupby('_fr_max_ind')['asym_z_cat'].apply(lambda x: '{}/{}; {:.1%}'.format(np.sum(x==2), len(x), np.mean(x==2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_remapping.groupby(['asym_z_cat']).agg({'neuron': len, 'fr_max_ind': [np.mean, np.std, stats.sem]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_remapping.groupby('nsig').agg({'neuron': lambda x: '{}/{} ({:.1%})'.format(len(x), all_cells.size, len(x)/all_cells.size)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig = 0\n",
    "overwrite = 1\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(colws[1], colws[1]), dpi=300)\n",
    "#ax = np.ravel(ax)\n",
    "\n",
    "font = {'tick': 8, 'label': 8, 'annot': 8, 'fig': 10}\n",
    "_cmap = ['#bebebe', '#296eb4', '#e10600']\n",
    "\n",
    "i = 0\n",
    "ax = sns.violinplot(x='dummy', y='asym_z', data=time_remapping, ax=ax,\n",
    "                    inner=None, color='k',  saturation=100, zorder=0)\n",
    "\n",
    "poly = ax.collections[0]\n",
    "poly.set_alpha(0.1)\n",
    "poly.set_linewidth(0)\n",
    "ax = sns.swarmplot(x='dummy', y='asym_z', hue='asym_z_cat', data=time_remapping,\n",
    "                   palette=_cmap, size=2, edgecolor='k', linewidth=0.4, zorder=2, ax=ax)\n",
    "ax.get_legend().remove()\n",
    "ax.tick_params(axis='y', which='both', length=2.5, pad=2, labelsize=font['tick'])\n",
    "ax.set_xlim([-0.5, 0.5])\n",
    "ax.set_xticks([])\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Remapping score (Z)', fontsize=font['label'], labelpad=2)\n",
    "plt.hlines(0, -10, 10, color='k', linewidth=0.8, linestyle='--', zorder=1)\n",
    "\n",
    "if savefig:\n",
    "    n_neurons = time_remapping['neuron'].unique().size\n",
    "    filename = op.join(proj_dir, 'figs', 'plot_remapping',\n",
    "                       'nav_time_cell_remapping_scores-{}units.pdf'\n",
    "                       .format(n_neurons))\n",
    "    if overwrite or not op.exists(filename):\n",
    "        fig.savefig(filename, format='pdf', bbox_inches='tight', pad_inches=0)\n",
    "        fig.savefig(filename.replace('pdf', 'png'), format='png', dpi=dpi, bbox_inches='tight', pad_inches=0)\n",
    "        \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(colws[1], colws[1]), dpi=300)\n",
    "#ax = np.ravel(ax)\n",
    "\n",
    "font = {'tick': 8, 'label': 8, 'annot': 8, 'fig': 10}\n",
    "_cmap = ['#bebebe', '#e10600'] # ['#bebebe', '#296eb4', '#e10600']\n",
    "_df = time_remapping.query(\"(nsig==2)\")\n",
    "\n",
    "i = 0\n",
    "ax = sns.violinplot(x='dummy', y='asym_z', data=_df,\n",
    "                    inner=None, color='k',  saturation=100, zorder=0, ax=ax)\n",
    "\n",
    "poly = ax.collections[0]\n",
    "poly.set_alpha(0.1)\n",
    "poly.set_linewidth(0)\n",
    "ax = sns.swarmplot(x='dummy', y='asym_z', hue='asym_z_cat', data=_df,\n",
    "                   palette=_cmap, size=2, \n",
    "                   edgecolor='k', linewidth=0.4, zorder=2, ax=ax)\n",
    "ax.get_legend().remove()\n",
    "ax.tick_params(axis='y', which='both', length=2.5, pad=2, labelsize=font['tick'])\n",
    "ax.set_xticks([])\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Remapping score (Z)', fontsize=font['label'], labelpad=2)\n",
    "plt.hlines(0, -10, 10, color='k', linewidth=0.8, linestyle='--', zorder=1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time_remapping.sort_values('asym_z', ascending=False).groupby('sig').size())\n",
    "print('{:.2f} ± {:.2f}, n = {}'.format(np.mean(time_remapping['asym_z']), stats.sem(time_remapping['asym_z']), len(time_remapping['asym_z'])))\n",
    "print(stats.ttest_1samp(time_remapping['asym_z'], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean timecourse for all Encoding and Retrieval neurons.\n",
    "savefig = 1\n",
    "overwrite = 1\n",
    "remapped = True\n",
    "figsize = (colws['2-1/2'], colws['2-1/2'] * 1.25)\n",
    "dpi = 1200\n",
    "font = {'tick': 10, 'label': 10, 'annot': 10, 'fig': 12}\n",
    "xticks = np.arange(0, 61, step=10)\n",
    "xticklabels = np.arange(0, 31, step=5, dtype=int)\n",
    "plot_title = False\n",
    "ax_labels = {0: 'Encoding', 1: 'Retrieval'}\n",
    "add_cbar = False\n",
    "vmin = 0\n",
    "vmax = 1\n",
    "\n",
    "plt.close()\n",
    "fig, ax = plt.subplots(2, 2, figsize=figsize, dpi=dpi)\n",
    "ax = np.ravel(ax)\n",
    "\n",
    "n_neurons = time_remapping['neuron'].unique().size\n",
    "for ii, remapped in enumerate([False, True]):\n",
    "    iax = ii * 2\n",
    "    \n",
    "    # Sort neurons that we'll plot firing rates over time for.\n",
    "    _neurons = time_remapping.query(\"(sig=={})\".format(remapped)).groupby('gameState')['neuron'].apply(list)\n",
    "    sbt_neurons = []\n",
    "    for game_state in ['Encoding', 'Retrieval']:\n",
    "        qry = \"(gameState=='{}') & (testvar=='time') & (full=='full') & (subj_sess_unit=={})\".format(game_state, _neurons[game_state])\n",
    "        sbt_neurons.extend(ols_pairs.query(qry).sort_values(['fr_max_ind', 'sparsity'])['subj_sess_unit'].tolist())\n",
    "    # _neurons = time_remapping.query(\"(sig=={})\".format(remapped))['neuron'].tolist()\n",
    "    # qry = \"(gameState=='Encoding') & (testvar=='time') & (subj_sess_unit=={})\".format(_neurons)\n",
    "    # sbt_neurons = ols_pairs.query(qry).sort_values(['fr_max_ind', 'sparsity'])['subj_sess_unit'].tolist()\n",
    "    spikes_by_time = od([('Encoding', []), ('Retrieval', [])])\n",
    "    for neuron in sbt_neurons:\n",
    "        for game_state in ['Encoding', 'Retrieval']:\n",
    "            qry = \"(gameState=='{}') & (testvar=='time') & (full=='full') & (subj_sess_unit=='{}')\".format(game_state, neuron)\n",
    "            _df = ols_pairs.query(qry)#\n",
    "            assert len(_df) == 1\n",
    "            spikes_by_time[game_state].append(_df.iloc[0]['mean_frs'])\n",
    "\n",
    "    fr_mat = np.concatenate((np.array(spikes_by_time['Encoding']), np.array(spikes_by_time['Retrieval'])), axis=1)\n",
    "    time_bins = int(fr_mat.shape[1] / 2)\n",
    "    fr_mat = minmax_scale(fr_mat, axis=1)\n",
    "    fr_mat = [fr_mat[:, :time_bins], fr_mat[:, time_bins:]]\n",
    "\n",
    "    # Plot the firing rate heatmaps.\n",
    "    for imat in range(2):\n",
    "        ax[iax] = sns.heatmap(fr_mat[imat], vmin=vmin, vmax=vmax, cmap='rocket',\n",
    "                            square=False, cbar=add_cbar, ax=ax[iax])\n",
    "        ax[iax].tick_params(axis='x', which='both', length=2.5, pad=2)\n",
    "        ax[iax].tick_params(axis='y', which='both', length=0, pad=2)\n",
    "        ax[iax].set_xticks(xticks)\n",
    "        ax[iax].set_yticks([])\n",
    "        if iax in [0, 2]:\n",
    "            ax[iax].set_xticklabels(xticklabels, fontsize=font['tick'], rotation=0)\n",
    "            ax[iax].set_xlabel('Time (s)', fontsize=font['label'], labelpad=4)\n",
    "            ax[iax].set_ylabel('Unit 1..{}'.format(fr_mat[0].shape[0]), fontsize=font['label'], labelpad=5)\n",
    "        else:\n",
    "            ax[iax].set_xticklabels([], fontsize=font['tick'], rotation=0)\n",
    "        if plot_title:\n",
    "            ax[iax].set_title(ax_labels[i], pad=6, fontsize=font['fig'])\n",
    "\n",
    "        if add_cbar:\n",
    "            cbar = ax[iax].collections[0].colorbar\n",
    "            cbar.ax.tick_params(labelsize=font['tick'])\n",
    "            cbar.set_ticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "            cbar.set_ticklabels([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "            cbar.set_label('Norm. firing rate', fontsize=font['label'], labelpad=2)\n",
    "        \n",
    "        iax += 1\n",
    "\n",
    "fig.tight_layout(w_pad=0)\n",
    "\n",
    "if savefig:\n",
    "    filename = op.join(proj_dir, 'figs', 'plot_remapping',\n",
    "                       'nav_time_cell_remapping-{}units-mean_fr_over_time.pdf'\n",
    "                       .format(n_neurons))\n",
    "    if overwrite or not op.exists(filename):\n",
    "        fig.savefig(filename, format='pdf', bbox_inches='tight', pad_inches=0)\n",
    "        fig.savefig(filename.replace('pdf', 'png'), format='png', dpi=dpi, bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean timecourse for all Delay1 and Delay2 neurons.\n",
    "savefig = 0\n",
    "overwrite = 0\n",
    "remapped = True\n",
    "grid_shp = (15, 37)\n",
    "figsize = (colws['1'], colws['1']*(grid_shp[0]/grid_shp[1]))\n",
    "dpi = 1200\n",
    "font = {'tick': 10, 'label': 10, 'annot': 10, 'fig': 12}\n",
    "ax_labels = {0: 'Encoding', 1: 'Retrieval'}\n",
    "add_cbar = False\n",
    "vmin = 0\n",
    "vmax = 1\n",
    "\n",
    "# Sort neurons that we'll plot firing rates over time for.\n",
    "_neurons = time_remapping.query(\"(sig=={})\".format(remapped)).groupby('gameState')['neuron'].apply(list)\n",
    "sbt_neurons = []\n",
    "for game_state in ['Encoding', 'Retrieval']:\n",
    "    qry = \"(gameState=='{}') & (testvar=='time') & (full=='full') & (subj_sess_unit=={})\".format(game_state, _neurons[game_state])\n",
    "    sbt_neurons.extend(ols_pairs.query(qry).sort_values(['fr_max_ind', 'sparsity'])['subj_sess_unit'].tolist())\n",
    "# _neurons = time_remapping.query(\"(sig=={})\".format(remapped))['neuron'].tolist()\n",
    "# qry = \"(gameState=='Encoding') & (testvar=='time') & (full=='full') & (subj_sess_unit=={})\".format(_neurons)\n",
    "# sbt_neurons = ols_pairs.query(qry).sort_values(['fr_max_ind', 'sparsity'])['subj_sess_unit'].tolist()\n",
    "spikes_by_time = od([('Encoding', []), ('Retrieval', [])])\n",
    "for neuron in sbt_neurons:\n",
    "    for game_state in ['Encoding', 'Retrieval']:\n",
    "        qry = \"(gameState=='{}') & (testvar=='time') & (full=='full') & (subj_sess_unit=='{}')\".format(game_state, neuron)\n",
    "        _df = ols_pairs.query(qry)#\n",
    "        assert len(_df) == 1\n",
    "        spikes_by_time[game_state].append(_df.iloc[0]['mean_frs'])\n",
    "\n",
    "plt.close()\n",
    "fig, ax = plt.subplots(1, 2, figsize=figsize, dpi=dpi)\n",
    "ax = np.ravel(ax)\n",
    "\n",
    "fr_mat = np.concatenate((np.array(spikes_by_time['Encoding']), np.array(spikes_by_time['Retrieval'])), axis=1)\n",
    "n_neurons = fr_mat.shape[0]\n",
    "time_bins = int(fr_mat.shape[1] / 2)\n",
    "fr_mat = minmax_scale(fr_mat, axis=1)\n",
    "fr_mat = [fr_mat[:, :time_bins], fr_mat[:, time_bins:]]\n",
    "\n",
    "# Plot the firing rate heatmaps.\n",
    "for i in range(2):\n",
    "    ax[i] = sns.heatmap(fr_mat[i], vmin=vmin, vmax=vmax, cmap='rocket',\n",
    "                        square=False, cbar=add_cbar, ax=ax[i])\n",
    "    ax[i].tick_params(axis='x', which='both', length=2.5, pad=2)\n",
    "    ax[i].tick_params(axis='y', which='both', length=0, pad=2)\n",
    "    ax[i].set_xticks(np.arange(0, fr_mat[i].shape[1]+1, 10))\n",
    "    ax[i].set_yticks([])\n",
    "    if i == 0:\n",
    "        ax[i].set_xticklabels(np.arange(0, (fr_mat[i].shape[1]+1)/2, 5, dtype=np.int), \n",
    "                              fontsize=font['tick'], rotation=0)\n",
    "        ax[i].set_xlabel('Time (s)', fontsize=font['label'], labelpad=2)\n",
    "        ax[i].set_ylabel('Unit 1..{}'.format(fr_mat[0].shape[0]), fontsize=font['label'], labelpad=5)\n",
    "    else:\n",
    "        ax[i].set_xticklabels([], fontsize=font['tick'], rotation=0)\n",
    "    ax[i].set_title(ax_labels[i], pad=6, fontsize=font['fig'])\n",
    "\n",
    "    if add_cbar:\n",
    "        cbar = ax[i].collections[0].colorbar\n",
    "        cbar.ax.tick_params(labelsize=font['tick'])\n",
    "        cbar.set_ticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "        cbar.set_ticklabels([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "        cbar.set_label('Norm. firing rate', fontsize=font['label'], labelpad=2)\n",
    "        \n",
    "fig.tight_layout(w_pad=0)\n",
    "    \n",
    "if savefig:\n",
    "    filename = op.join(proj_dir, 'figs', 'plot_nav',\n",
    "                       'nav_time_cells-{}units-Encoding_Retrieval_firing.pdf'\n",
    "                       .format(n_neurons))\n",
    "    if overwrite or not op.exists(filename):\n",
    "        fig.savefig(filename, format='pdf', bbox_inches='tight', pad_inches=0)\n",
    "        fig.savefig(filename.replace('pdf', 'png'), format='png', dpi=dpi, bbox_inches='tight', pad_inches=0)\n",
    "        \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean timecourse for all Delay1 and Delay2 neurons.\n",
    "savefig = 0\n",
    "overwrite = 0\n",
    "remapped = False\n",
    "grid_shp = (15, 37)\n",
    "figsize = (colws['1'], colws['1']*(grid_shp[0]/grid_shp[1]))\n",
    "dpi = 1200\n",
    "font = {'tick': 10, 'label': 10, 'annot': 10, 'fig': 12}\n",
    "ax_labels = {0: 'Encoding', 1: 'Retrieval'}\n",
    "add_cbar = False\n",
    "vmin = 0\n",
    "vmax = 1\n",
    "\n",
    "# Sort neurons that we'll plot firing rates over time for.\n",
    "_neurons = time_remapping.query(\"(sig=={})\".format(remapped)).groupby('gameState')['neuron'].apply(list)\n",
    "sbt_neurons = []\n",
    "for game_state in ['Encoding', 'Retrieval']:\n",
    "    qry = \"(gameState=='{}') & (testvar=='time') & (full=='full') & (subj_sess_unit=={})\".format(game_state, _neurons[game_state])\n",
    "    sbt_neurons.extend(ols_pairs.query(qry).sort_values(['fr_max_ind', 'sparsity'])['subj_sess_unit'].tolist())\n",
    "# _neurons = time_remapping.query(\"(sig=={})\".format(remapped))['neuron'].tolist()\n",
    "# qry = \"(gameState=='Encoding') & (testvar=='time') & (full=='full') & (subj_sess_unit=={})\".format(_neurons)\n",
    "# sbt_neurons = ols_pairs.query(qry).sort_values(['fr_max_ind', 'sparsity'])['subj_sess_unit'].tolist()\n",
    "spikes_by_time = od([('Encoding', []), ('Retrieval', [])])\n",
    "for neuron in sbt_neurons:\n",
    "    for game_state in ['Encoding', 'Retrieval']:\n",
    "        qry = \"(gameState=='{}') & (testvar=='time') & (full=='full') & (subj_sess_unit=='{}')\".format(game_state, neuron)\n",
    "        _df = ols_pairs.query(qry)#\n",
    "        assert len(_df) == 1\n",
    "        spikes_by_time[game_state].append(_df.iloc[0]['mean_frs'])\n",
    "\n",
    "plt.close()\n",
    "fig, ax = plt.subplots(1, 2, figsize=figsize, dpi=dpi)\n",
    "ax = np.ravel(ax)\n",
    "\n",
    "fr_mat = np.concatenate((np.array(spikes_by_time['Encoding']), np.array(spikes_by_time['Retrieval'])), axis=1)\n",
    "n_neurons = fr_mat.shape[0]\n",
    "time_bins = int(fr_mat.shape[1] / 2)\n",
    "fr_mat = minmax_scale(fr_mat, axis=1)\n",
    "fr_mat = [fr_mat[:, :time_bins], fr_mat[:, time_bins:]]\n",
    "\n",
    "# Plot the firing rate heatmaps.\n",
    "for i in range(2):\n",
    "    ax[i] = sns.heatmap(fr_mat[i], vmin=vmin, vmax=vmax, cmap='rocket',\n",
    "                        square=False, cbar=add_cbar, ax=ax[i])\n",
    "    ax[i].tick_params(axis='x', which='both', length=2.5, pad=2)\n",
    "    ax[i].tick_params(axis='y', which='both', length=0, pad=2)\n",
    "    ax[i].set_xticks(np.arange(0, fr_mat[i].shape[1]+1, 10))\n",
    "    ax[i].set_yticks([])\n",
    "    if i == 0:\n",
    "        ax[i].set_xticklabels(np.arange(0, (fr_mat[i].shape[1]+1)/2, 5, dtype=np.int), \n",
    "                              fontsize=font['tick'], rotation=0)\n",
    "        ax[i].set_xlabel('Time (s)', fontsize=font['label'], labelpad=2)\n",
    "        ax[i].set_ylabel('Unit 1..{}'.format(fr_mat[0].shape[0]), fontsize=font['label'], labelpad=5)\n",
    "    else:\n",
    "        ax[i].set_xticklabels([], fontsize=font['tick'], rotation=0)\n",
    "    ax[i].set_title(ax_labels[i], pad=6, fontsize=font['fig'])\n",
    "\n",
    "    if add_cbar:\n",
    "        cbar = ax[i].collections[0].colorbar\n",
    "        cbar.ax.tick_params(labelsize=font['tick'])\n",
    "        cbar.set_ticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "        cbar.set_ticklabels([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "        cbar.set_label('Norm. firing rate', fontsize=font['label'], labelpad=2)\n",
    "        \n",
    "fig.tight_layout(w_pad=0)\n",
    "    \n",
    "if savefig:\n",
    "    filename = op.join(proj_dir, 'figs', 'plot_nav',\n",
    "                       'nav_time_cells-{}units-Encoding_Retrieval_firing.pdf'\n",
    "                       .format(n_neurons))\n",
    "    if overwrite or not op.exists(filename):\n",
    "        fig.savefig(filename, format='pdf', bbox_inches='tight', pad_inches=0)\n",
    "        fig.savefig(filename.replace('pdf', 'png'), format='png', dpi=dpi, bbox_inches='tight', pad_inches=0)\n",
    "        \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Place cell remapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(time_bin_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#event_spikes.get_spike_mat(neuron='time_bin', game_state='Encoding', column='maze_region', apply_f=len)[places].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_odd = np.unique(event_spikes.event_spikes['trial']) % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_spikes.event_spikes['is_odd'] = event_spikes.event_spikes['trial'].apply(lambda x: x % 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy['Encoding'].index.values % 2 == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum time bins in each maze region, separately for even and odd trials.\n",
    "occupancy = od([('Encoding', event_spikes.get_spike_mat(neuron='time_bin', game_state='Encoding', column='maze_region', apply_f=len)[places].fillna(0)),\n",
    "                ('Retrieval', event_spikes.get_spike_mat(neuron='time_bin', game_state='Retrieval', column='maze_region', apply_f=len)[places].fillna(0))])\n",
    "for _k in occupancy:\n",
    "    occupancy[_k] = (pd.concat((occupancy[_k].loc[occupancy[_k].index.values % 2 == 1, :].sum(),\n",
    "                                occupancy[_k].loc[occupancy[_k].index.values % 2 == 0, :].sum()), axis=1)\n",
    "                     .rename(columns={0: 'even', 1: 'odd'}).T)\n",
    "    \n",
    "place_remapping = []\n",
    "for neuron, _df in grp:\n",
    "    assert len(_df) == 2\n",
    "    assert _df.iloc[0]['gameState'] == 'Encoding'\n",
    "    assert _df.iloc[1]['gameState'] == 'Retrieval'\n",
    "    \n",
    "    subj_sess = _df.iloc[0]['subj_sess']\n",
    "    nsig = _df['sig'].sum()\n",
    "    assert nsig in [0, 1, 2]\n",
    "    \n",
    "    if 'event_spikes' not in dir():\n",
    "        event_spikes = time_bin_analysis.load_event_spikes(subj_sess, verbose=False)\n",
    "    elif event_spikes.subj_sess != subj_sess:\n",
    "        event_spikes = time_bin_analysis.load_event_spikes(subj_sess, verbose=False)\n",
    "    \n",
    "    # Sum spikes in each maze region, separately for even and odd trials.\n",
    "    spike_mats = od([])\n",
    "    for _, row in _df.iterrows():\n",
    "        spike_mats[row['gameState']] = event_spikes.get_spike_mat(row['neuron'], row['gameState'], column='maze_region')[places].fillna(0)\n",
    "        spike_mats[row['gameState']] = (pd.concat((spike_mats[row['gameState']].loc[spike_mats[row['gameState']].index.values % 2 == 1, :].sum(),\n",
    "                                                   spike_mats[row['gameState']].loc[spike_mats[row['gameState']].index.values % 2 == 0, :].sum()), axis=1)\n",
    "                                        .rename(columns={0: 'even', 1: 'odd'}).T)\n",
    "        spike_mats[row['gameState']] = (spike_mats[row['gameState']] / occupancy[row['gameState']]).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_mats['Encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_mats['Retrieval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(occupancy['Encoding'], occupancy['Retrieval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy['Encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occupancy(event_spikes):\n",
    "    # Sum time bins in each maze region, separately for even and odd trials.\n",
    "    occupancy = od([('Encoding', event_spikes.get_spike_mat(neuron='time_bin', game_state='Encoding', column='maze_region', apply_f=len)[places].fillna(0)),\n",
    "                    ('Retrieval', event_spikes.get_spike_mat(neuron='time_bin', game_state='Retrieval', column='maze_region', apply_f=len)[places].fillna(0))])\n",
    "    return occupancy\n",
    "\n",
    "for _k in occupancy:\n",
    "    if do_shuffle:\n",
    "        \n",
    "    occupancy[_k] = (pd.concat((occupancy[_k].loc[occupancy[_k].index.values % 2 == 1, :].sum(),\n",
    "                                occupancy[_k].loc[occupancy[_k].index.values % 2 == 0, :].sum()), axis=1)\n",
    "                     .rename(columns={0: 'even', 1: 'odd'}).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_sims_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which place cells significantly remapped between Encoding and Retrieval\n",
    "# by comparing the mean difference in firing rate cosine similarity between\n",
    "# within-nav vs. between-nav trial pairs.\n",
    "n_perm = 1000\n",
    "alpha = 0.05\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "places = ['SW_Hall', 'SW_Room', 'NW_Room', 'NW_Hall',\n",
    "          'Base', 'S_Passage', 'C_Hall', 'N_Passage',\n",
    "          'SE_Hall', 'SE_Room', 'NE_Room', 'NE_Hall']\n",
    "all_cells = ols_pairs['subj_sess_unit'].unique()\n",
    "qry = \"(gameState==['Encoding', 'Retrieval']) & (testvar=='place') & (full=='full') & (sig==True)\"\n",
    "nav_place_cells = ols_pairs.query(qry)['subj_sess_unit'].unique()\n",
    "qry = \"(gameState==['Encoding', 'Retrieval']) & (testvar=='place') & (full=='full') & (subj_sess_unit=={})\".format(list(nav_place_cells))\n",
    "grp = (ols_pairs.sort_values(['subj_sess', 'neuron', 'gameState'])\n",
    "       .query(qry)\n",
    "       .groupby(['subj_sess_unit'], observed=True))\n",
    "\n",
    "# Sum time bins in each maze region, separately for even and odd trials.\n",
    "occupancy = od([('Encoding', event_spikes.get_spike_mat(neuron='time_bin', game_state='Encoding', column='maze_region', apply_f=len)[places].fillna(0)),\n",
    "                ('Retrieval', event_spikes.get_spike_mat(neuron='time_bin', game_state='Retrieval', column='maze_region', apply_f=len)[places].fillna(0))])\n",
    "for _k in occupancy:\n",
    "    occupancy[_k] = (pd.concat((occupancy[_k].loc[occupancy[_k].index.values % 2 == 1, :].sum(),\n",
    "                                occupancy[_k].loc[occupancy[_k].index.values % 2 == 0, :].sum()), axis=1)\n",
    "                     .rename(columns={0: 'even', 1: 'odd'}).T)\n",
    "    \n",
    "place_remapping = []\n",
    "for neuron, _df in grp:\n",
    "    assert len(_df) == 2\n",
    "    assert _df.iloc[0]['gameState'] == 'Encoding'\n",
    "    assert _df.iloc[1]['gameState'] == 'Retrieval'\n",
    "    \n",
    "    subj_sess = _df.iloc[0]['subj_sess']\n",
    "    nsig = _df['sig'].sum()\n",
    "    assert nsig in [0, 1, 2]\n",
    "    \n",
    "    if 'event_spikes' not in dir():\n",
    "        event_spikes = time_bin_analysis.load_event_spikes(subj_sess, verbose=False)\n",
    "    elif event_spikes.subj_sess != subj_sess:\n",
    "        event_spikes = time_bin_analysis.load_event_spikes(subj_sess, verbose=False)\n",
    "    \n",
    "    # Sum spikes in each maze region, separately for even and odd trials.\n",
    "    spike_mats = od([])\n",
    "    for _, row in _df.iterrows():\n",
    "        spike_mats[row['gameState']] = event_spikes.get_spike_mat(row['neuron'], row['gameState'], column='maze_region')[places].fillna(0)\n",
    "        spike_mats[row['gameState']] = (pd.concat((spike_mats[row['gameState']].loc[spike_mats[row['gameState']].index.values % 2 == 1, :].sum(),\n",
    "                                                   spike_mats[row['gameState']].loc[spike_mats[row['gameState']].index.values % 2 == 0, :].sum()), axis=1)\n",
    "                                        .rename(columns={0: 'even', 1: 'odd'}).T)\n",
    "        spike_mats[row['gameState']] = (spike_mats[row['gameState']] / occupancy[row['gameState']]).fillna(0)\n",
    "    \n",
    "    # Get Encoding to Retrieval firing vector sims.\n",
    "    pairwise_sims = remapping.trial_pair_remapping(spike_mats)\n",
    "    mean_sims = {k : np.mean(v) for k, v in pairwise_sims.items()}\n",
    "    mean_sims['within'] = np.max((mean_sims['Encoding'], mean_sims['Retrieval']))\n",
    "    asym = mean_sims['within'] - mean_sims['between']\n",
    "    \n",
    "    # Compute the null distribution.\n",
    "    pairwise_sims_vec = np.concatenate([pairwise_sims['Encoding'],\n",
    "                                        pairwise_sims['Retrieval'],\n",
    "                                        pairwise_sims['between']]) # cond x trial_pair\n",
    "    divs = np.cumsum((len(pairwise_sims['Encoding']), len(pairwise_sims['Retrieval']), len(pairwise_sims['between'])))[:2]\n",
    "    asyms_null = []\n",
    "    for iPerm in range(n_perm):\n",
    "        np.random.shuffle(pairwise_sims_vec)\n",
    "        mean_sims_null = dict(zip(['Encoding', 'Retrieval', 'between'], \n",
    "                                  [np.mean(x) for x in np.split(pairwise_sims_vec, divs)]))\n",
    "        mean_sims_null['within'] = np.max((mean_sims_null['Encoding'], mean_sims_null['Retrieval']))\n",
    "        asyms_null.append(mean_sims_null['within'] - mean_sims_null['between'])\n",
    "    asyms_null = np.array(asyms_null)\n",
    "    \n",
    "    asym_z = (asym - np.mean(asyms_null)) / np.std(asyms_null)\n",
    "    if asym_z > 0:\n",
    "        asym_z_sign = 1\n",
    "    elif asym_z == 0:\n",
    "        asym_z_sign = 0\n",
    "    else:\n",
    "        asym_z_sign = -1\n",
    "    pval_ind = np.sum(np.abs(asyms_null) >= np.abs(asym))\n",
    "    pval = (1 + pval_ind) / (1 + n_perm)\n",
    "    \n",
    "    # Figure out which trial phase (Encoding or Retrieval) has stronger place coding.\n",
    "    # (If only one trial phase is significant, take that one. Otherwise, take whichever\n",
    "    # has the highest info score). Then add place coding info for the stronger trial phase.\n",
    "    z_lr_diff = np.abs(np.diff(_df['z_lr']))[0]\n",
    "    if nsig == 1:\n",
    "        row = _df.query(\"(sig==True)\").iloc[0]\n",
    "    else:\n",
    "        row = _df.sort_values('z_lr', ascending=False).iloc[0]\n",
    "    game_state = row['gameState']\n",
    "    z_lr = row['z_lr']\n",
    "    fr_max_ind = row['fr_max_ind']\n",
    "    place_remapping.append([neuron, subj_sess, nsig, z_lr_diff, game_state, z_lr,\n",
    "                           fr_max_ind, asym, asym_z, asym_z_sign, pval_ind, pval])\n",
    "        \n",
    "place_remapping = pd.DataFrame(place_remapping, columns=['neuron', 'subj_sess', 'nsig', 'z_lr_diff', 'gameState', 'z_lr', \n",
    "                                                         'fr_max_ind', 'asym', 'asym_z', 'asym_z_sign', 'pval_ind', 'pval'])\n",
    "place_remapping['sig'] = place_remapping['pval'] < alpha\n",
    "place_remapping['asym_z_cat'] = 0\n",
    "place_remapping.loc[(place_remapping['sig']==True) & (place_remapping['asym_z_sign']==-1), 'asym_z_cat'] = 1\n",
    "place_remapping.loc[(place_remapping['sig']==True) & (place_remapping['asym_z_sign']==1), 'asym_z_cat'] = 2\n",
    "place_remapping['dummy'] = 0\n",
    "unit_to_roi_map = ols_pairs[['subj_sess_unit', 'roi_gen']].drop_duplicates().set_index('subj_sess_unit')['roi_gen'].to_dict()\n",
    "place_remapping.insert(2, 'roi_gen', place_remapping['neuron'].apply(lambda x: unit_to_roi_map[x]))\n",
    "\n",
    "print('place_remapping: {}'.format(place_remapping.shape))\n",
    "print('Done in {:.1f}s'.format(time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Determine which place cells significantly remapped between Encoding and Retrieval\n",
    "# # by comparing the mean difference in firing rate cosine similarity between\n",
    "# # within-nav vs. between-nav trial pairs.\n",
    "# n_perm = 1000\n",
    "# alpha = 0.05\n",
    "\n",
    "# start_time = time()\n",
    "\n",
    "# places = ['SW_Hall', 'SW_Room', 'NW_Room', 'NW_Hall',\n",
    "#           'Base', 'S_Passage', 'C_Hall', 'N_Passage',\n",
    "#           'SE_Hall', 'SE_Room', 'NE_Room', 'NE_Hall']\n",
    "# all_cells = ols_pairs['subj_sess_unit'].unique()\n",
    "# qry = \"(gameState==['Encoding', 'Retrieval']) & (testvar=='place') & (full=='full') & (sig==True)\"\n",
    "# nav_place_cells = ols_pairs.query(qry)['subj_sess_unit'].unique()\n",
    "# qry = \"(gameState==['Encoding', 'Retrieval']) & (testvar=='place') & (full=='full') & (subj_sess_unit=={})\".format(list(nav_place_cells))\n",
    "# grp = (ols_pairs.sort_values(['subj_sess', 'neuron', 'gameState'])\n",
    "#        .query(qry)\n",
    "#        .groupby(['subj_sess_unit'], observed=True))\n",
    "\n",
    "# occupancy = od([('Encoding', event_spikes.get_spike_mat(neuron='time_bin', game_state='Encoding', column='maze_region', apply_f=len)[places].fillna(0)),\n",
    "#                 ('Retrieval', event_spikes.get_spike_mat(neuron='time_bin', game_state='Retrieval', column='maze_region', apply_f=len)[places].fillna(0))])\n",
    "# place_remapping = []\n",
    "# for neuron, _df in grp:\n",
    "#     assert len(_df) == 2\n",
    "#     assert _df.iloc[0]['gameState'] == 'Encoding'\n",
    "#     assert _df.iloc[1]['gameState'] == 'Retrieval'\n",
    "    \n",
    "#     subj_sess = _df.iloc[0]['subj_sess']\n",
    "#     nsig = _df['sig'].sum()\n",
    "#     assert nsig in [0, 1, 2]\n",
    "    \n",
    "#     if 'event_spikes' not in dir():\n",
    "#         event_spikes = time_bin_analysis.load_event_spikes(subj_sess, verbose=False)\n",
    "#         event_spikes.event_spikes['is_odd'] = event_spikes.event_spikes['trial'].apply(lambda x: x % 2)\n",
    "#     elif event_spikes.subj_sess != subj_sess:\n",
    "#         event_spikes = time_bin_analysis.load_event_spikes(subj_sess, verbose=False)\n",
    "#         event_spikes.event_spikes['is_odd'] = event_spikes.event_spikes['trial'].apply(lambda x: x % 2)\n",
    "    \n",
    "#     spike_mats = od([])\n",
    "#     for _, row in _df.iterrows():\n",
    "#         spike_mats[row['gameState']] = (event_spikes.get_spike_mat(row['neuron'], row['gameState'], column='maze_region')[places].fillna(0) / occupancy[row['gameState']]).fillna(0)\n",
    "    \n",
    "#     # Get Encoding to Retrieval firing vector sims.\n",
    "#     pairwise_sims = remapping.trial_pair_remapping(spike_mats)\n",
    "#     mean_sims = {k : np.mean(v) for k, v in pairwise_sims.items()}\n",
    "#     mean_sims['within'] = np.max((mean_sims['Encoding'], mean_sims['Retrieval']))\n",
    "#     asym = mean_sims['within'] - mean_sims['between']\n",
    "    \n",
    "#     # Compute the null distribution.\n",
    "#     pairwise_sims_vec = np.concatenate([pairwise_sims['Encoding'],\n",
    "#                                         pairwise_sims['Retrieval'],\n",
    "#                                         pairwise_sims['between']]) # cond x trial_pair\n",
    "#     divs = np.cumsum((len(pairwise_sims['Encoding']), len(pairwise_sims['Retrieval']), len(pairwise_sims['between'])))[:2]\n",
    "#     asyms_null = []\n",
    "#     for iPerm in range(n_perm):\n",
    "#         np.random.shuffle(pairwise_sims_vec)\n",
    "#         mean_sims_null = dict(zip(['Encoding', 'Retrieval', 'between'], \n",
    "#                                   [np.mean(x) for x in np.split(pairwise_sims_vec, divs)]))\n",
    "#         mean_sims_null['within'] = np.max((mean_sims_null['Encoding'], mean_sims_null['Retrieval']))\n",
    "#         asyms_null.append(mean_sims_null['within'] - mean_sims_null['between'])\n",
    "#     asyms_null = np.array(asyms_null)\n",
    "    \n",
    "#     asym_z = (asym - np.mean(asyms_null)) / np.std(asyms_null)\n",
    "#     if asym_z > 0:\n",
    "#         asym_z_sign = 1\n",
    "#     elif asym_z == 0:\n",
    "#         asym_z_sign = 0\n",
    "#     else:\n",
    "#         asym_z_sign = -1\n",
    "#     pval_ind = np.sum(np.abs(asyms_null) >= np.abs(asym))\n",
    "#     pval = (1 + pval_ind) / (1 + n_perm)\n",
    "    \n",
    "#     # Figure out which trial phase (Encoding or Retrieval) has stronger place coding.\n",
    "#     # (If only one trial phase is significant, take that one. Otherwise, take whichever\n",
    "#     # has the highest info score). Then add place coding info for the stronger trial phase.\n",
    "#     z_lr_diff = np.abs(np.diff(_df['z_lr']))[0]\n",
    "#     if nsig == 1:\n",
    "#         row = _df.query(\"(sig==True)\").iloc[0]\n",
    "#     else:\n",
    "#         row = _df.sort_values('z_lr', ascending=False).iloc[0]\n",
    "#     game_state = row['gameState']\n",
    "#     z_lr = row['z_lr']\n",
    "#     fr_max_ind = row['fr_max_ind']\n",
    "#     place_remapping.append([neuron, subj_sess, nsig, z_lr_diff, game_state, z_lr,\n",
    "#                            fr_max_ind, asym, asym_z, asym_z_sign, pval_ind, pval])\n",
    "        \n",
    "# place_remapping = pd.DataFrame(place_remapping, columns=['neuron', 'subj_sess', 'nsig', 'z_lr_diff', 'gameState', 'z_lr', \n",
    "#                                                      'fr_max_ind', 'asym', 'asym_z', 'asym_z_sign', 'pval_ind', 'pval'])\n",
    "# place_remapping['sig'] = place_remapping['pval'] < alpha\n",
    "# place_remapping['asym_z_cat'] = 0\n",
    "# place_remapping.loc[(place_remapping['sig']==True) & (place_remapping['asym_z_sign']==-1), 'asym_z_cat'] = 1\n",
    "# place_remapping.loc[(place_remapping['sig']==True) & (place_remapping['asym_z_sign']==1), 'asym_z_cat'] = 2\n",
    "# place_remapping['dummy'] = 0\n",
    "# unit_to_roi_map = ols_pairs[['subj_sess_unit', 'roi_gen']].drop_duplicates().set_index('subj_sess_unit')['roi_gen'].to_dict()\n",
    "# place_remapping.insert(2, 'roi_gen', place_remapping['neuron'].apply(lambda x: unit_to_roi_map[x]))\n",
    "\n",
    "# print('place_remapping: {}'.format(place_remapping.shape))\n",
    "# print('Done in {:.1f}s'.format(time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_remapping.sort_values('asym', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_remapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
