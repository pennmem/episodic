import mkl
mkl.set_num_threads(1)
import numpy as np
import os
import errno
import scipy.io
from glob import glob
import time
import sys
import pandas

import lagCRP2
import opR_crl
import plis
import CMR2_pack_cyth_LTP228 as CMR2

"""
Dependencies: CMR2_pack.py, lagCRP2.py, plus all the package imports above.
              Must also have access to a data file & LSA or W2V file.

This last updated on Sunday Jul 9, 2017
"""

def recode_for_spc(data_recs, data_pres, ll=24, subjsize=24, 
                   exclude_plis=False, exclude_xlis=False, 
                   exclude_repeats=True):
    print('using shais recoding vers')
    ll = data_pres.shape[1]
    rec_lists = []
    
    data_subj = []
    for i in range(data_recs.shape[0]):
        data_subj.append(i/subjsize)
    data_subj = np.asarray(data_subj)
    
    for trial in range(len(data_recs)):
        this_list = data_recs[trial]
        pres_list = data_pres[trial]
        
        myrow = []
        
        for rec in this_list:
            if rec == 0:
                myrow.append(0)
            elif rec in pres_list:
                serial_pos = int(np.where(pres_list==rec)[0]+1)
                if exclude_repeats and serial_pos in myrow:
                    continue
                myrow.append(serial_pos)
            elif not exclude_plis:
                found=False
                prev_subj_start = np.where(data_subj==data_subj[trial])[0][0]-1
                for prev_list in np.arange(trial-1, prev_subj_start, -1):
                    #print prev_list,
                    if rec in data_pres[prev_list]:
                        #print data_pres[prev_list], data_pres[prev_list+1], data_pres[trial]
                        myrow.append(prev_list-trial)
                        found=True
                        break
                if not found and not exclude_xlis:
                    myrow.append(-1000)
        while len(myrow) < ll*2:
            myrow.append(0)
        rec_lists.append(np.asarray(myrow).astype(float)[:ll*2])
        
    rec_lists = np.asmatrix(rec_lists)
    rec_lists = rec_lists.astype(int)

    return rec_lists


def get_num_intrusions(data_rec, data_pres, lists_per_div):
    ################################
    #Syntax: 
    # data_rec: the numpy matrix of patient recordings
    # data_pres: the numpy matrix of presented words
    #How many lists are you looking at one time???
    #Note for long stuff like ltpFR2 this function 
    #Gets PLI per section, not for the entirety of the experiment
    #Which is what we are trying to fit for, for each section
    #returns: average plis/elis across divisions, adjusted standard error 
    #of pli / eli or whatever its called
    #################################
    #Meta variables hold everything when we're done
    #with all divisions
    meta_pli = []
    meta_eli = []
    #Get the starting point for each division
    for division_start in range(0, len(data_pres), lists_per_div):
        #... and the ending point
        division_end = division_start + lists_per_div
        #Get the requisite data for that specific division
        #, recalled and presented
        pres_div = data_pres[division_start: division_end]
        rec_div = data_rec[division_start: division_end]
        #temporary variables to keep track of things for this
        #division
        temp_pli_count = 0
        temp_eli_count = 0
        for list_number in range(len(rec_div)):
            #First find all the items in the rec that are not in the
            #pres. These are either PLIs or ELIs and are of interest
            # to this function... or they are vocalizations/0's
            of_interest = [x for x in rec_div[list_number] if \
                          x not in pres_div[list_number]]
            #Clean the of_interest array of 0s and -1s (vocalizations)
            while 0 in of_interest:
                of_interest.remove(0)
            #Check if it was in some previous list. This is not as computationally efficient 
            #as it could be but runtime doesn't matter in this part of the code
            for word in of_interest:
                PLI = False
                for earlier_list in pres_div[0:list_number]:
                    if word in earlier_list and word != -1:
                        PLI = True
                if PLI:
                    temp_pli_count += 1
                else:
                    temp_eli_count += 1
        meta_pli.append(temp_pli_count)
        meta_eli.append(temp_eli_count)
    # Part 2: Calculate the stuff you need
    meta_pli = np.array(meta_pli)
    meta_eli = np.array(meta_eli)
    mean_pli = np.mean(meta_pli, axis = 0)
    mean_eli = np.mean(meta_eli, axis = 0)
    sem_pli = np.std(meta_pli)/(len(meta_pli) ** 0.5)
    sem_eli = np.std(meta_eli)/(len(meta_eli) ** 0.5)
    
    #print meta_pli, meta_eli
    return mean_pli, mean_eli, sem_pli, sem_eli

def get_num_intrusions(data_rec, data_pres, lists_per_div):
    
    num_plis = []
    num_elis = []
    recoded_lists = recode_for_spc(data_rec, data_pres)
    
    for lst in recoded_lists:
        num_plis.append(lst[lst<0][lst[lst<0]>-1000].size)
        num_elis.append(lst[lst==-1000].size)
    
    mean_pli = np.nanmean(num_plis)
    mean_eli = np.nanmean(num_elis)
    
    sem_pli = np.std(num_plis)/(len(num_plis) ** 0.5)
    sem_eli = np.std(num_elis)/(len(num_elis) ** 0.5)
    
    return mean_pli, mean_eli, sem_pli, sem_eli

def get_spc_pfc(rec_lists, ll, onlysixpoints=True):

    """Get spc and pfc for the recoded lists"""

    spclists = []
    pfclists = []
    for each_list in rec_lists:

        each_list = each_list[each_list > 0]

        # init. list to store whether or not an item was recalled
        spc_counts = np.zeros((1, ll))
        pfc_counts = np.zeros((1, ll))

        # get indices of where to put items in the list;
        # items start at 1, so index needs to -1
        spc_count_indices = each_list - 1
        spc_counts[0, spc_count_indices] = 1

        if each_list.shape[1] <= 0:
            continue
        else:
            # get index for first item in list
            pfc_count_index = each_list[0, 0] - 1
            pfc_counts[0, pfc_count_index] = 1

            spclists.append(np.squeeze(spc_counts))
            pfclists.append(np.squeeze(pfc_counts))

    # if no items were recalled, output a matrix of 0's
    if not spclists:
        spcmat = np.zeros((rec_lists.shape[0], ll))
    else:
        spcmat = np.array(spclists)

    if not pfclists:
        pfcmat = np.zeros((rec_lists.shape[0], ll))
    else:
        pfcmat = np.array(pfclists)

    # get mean and sem's for spc and pfc
    spc_mean = np.nanmean(spcmat, axis=0)
    spc_sem  = np.nanstd(spcmat, axis=0) / (len(spcmat) ** 0.5)
    
    if onlysixpoints:
        spc_mean = np.asarray([spc_mean[0], spc_mean[3], 
                               np.nanmean([spc_mean[i] for i in range(10, 14)]), 
                               spc_mean[20], spc_mean[22], spc_mean[23]])
        spc_sem = np.asarray([spc_sem[0], spc_sem[3], 
                               np.nanmean([spc_sem[i] for i in range(10, 14)]), 
                               spc_sem[20], spc_sem[22], spc_sem[23]])

    pfc_mean = np.nanmean(pfcmat, axis=0)
    pfc_sem  = np.nanstd(pfcmat, axis=0) / (len(pfcmat) ** 0.5)

    return spc_mean, spc_sem, pfc_mean, pfc_sem

def convert_crp(crp, left=True):
    center_val = ll - 1
    mult=1
    if not left:
        mult = -1
    converted = np.array([np.nanmean([crp[center_val-mult*i] for i in [4, 5, 6]]),
                                np.nanmean([crp[center_val-mult*i] for i in [2, 3]]),
                                crp[center_val-mult*1]
            ])
    if not left:
        converted = np.flip(converted, 0)
    return converted
# insert CMR2 objective function here, and name it obj_func

def btwn01normed(data):
    data = np.asarray(data)
    if data.max() == 0 and data.min() == 0:
        return np.zeros(data.shape)
    elif data.size == 1:
        return data/2
    else:
        return (data-data.min())/(data.max()-data.min())

def obj_func(param_vec=None, param_dict=None):
    """Error function that we want to minimize"""

    # pso sometimes will try to assign eta_val = 0.0.  Do not allow this.
    if param_vec and    param_vec[7] > 0.0:
        eta_val = param_vec[7]
    else:
        eta_val = .001

    # desired model parameters
    if not param_dict:
        param_dict = {
    
            'beta_enc': param_vec[0],
            'beta_rec': param_vec[1],
            'gamma_fc': param_vec[2],
            'gamma_cf': param_vec[3],
            'scale_fc': 1 - param_vec[2],
            'scale_cf': 1 - param_vec[3],
    
            'phi_s': param_vec[4],
            'phi_d': param_vec[5],
            'kappa': param_vec[6],
    
            'eta': eta_val,
            's_cf': param_vec[8],
            's_fc': 0.0,
            'beta_rec_post': param_vec[9],
            'omega':param_vec[10],
            'alpha': param_vec[11],
            'c_thresh': param_vec[12],
            'dt': 10.0,
    
            'lamb': param_vec[13],
            'rec_time_limit': 75000,
    
            'dt_tau': 0.01,
            'sq_dt_tau': 0.10,
    
            'nlists_for_accumulator': 4
        }

    rec_nos, times = CMR2.run_CMR2(LSA_path, LSA_mat, data_path, param_dict,
                                   sep_files=False)

    cmr_recoded_output = recode_for_spc(rec_nos, data_pres)

    # get the model's spc and pfc predictions:
    (this_spc, this_spc_sem, this_pfc,
	this_pfc_sem) = get_spc_pfc(cmr_recoded_output, ll)

    # get the model's crp predictions:
    this_crp, this_crp_sem = lagCRP2.get_crp(cmr_recoded_output, ll)

    center_val = ll - 1

    # get left crp values
    this_left_crp = this_crp[(center_val-5):center_val]
    
    
    this_left_crp = convert_crp(this_crp, left=True)

    # get right crp values
    this_right_crp = this_crp[(center_val+1):(center_val + 6)]
    
    this_right_crp = convert_crp(this_crp, left=False)

    # get metrics re: mean and sem of PLIs and ELIs
    this_PLI, this_PLI_sem, = plis.plicount(cmr_recoded_output)
    
    this_crl, this_crl_sem, sz_placeholder = opR_crl.opR_crl(times, 
                                    cmr_recoded_output, Szs=szs_for_crl)

    # be careful not to divide by 0! some param sets may output 0 sem vec's.
    # if this happens, just leave all outputs alone.
    if np.nansum(this_spc_sem) == 0 \
            or np.nansum(this_pfc_sem) == 0 \
            or np.nansum(this_crp_sem) == 0:
        print("np.nansum equaled 0")
        this_spc_sem[range(len(this_spc_sem))] = 1
        this_pfc_sem[range(len(this_pfc_sem))] = 1
        this_crp_sem[range(len(this_crp_sem))] = 1


    # get the error vectors for each type of analysis
    
    
    print 'this'
    print this_crl
    print 'targ'
    print target_crl
    print szs_for_crl
    
    es = {}
    
    es['e1'] = [np.subtract(target_spc, this_spc)*50, target_spc_sem]
    #e1_norm = np.divide(e1, target_spc_sem)

    #es['e2'] = [np.subtract(target_pfc, this_pfc), target_pfc_sem]
    #e2_norm = np.divide(e2, target_pfc_sem)

    es['e3'] = [np.subtract(target_left_crp, this_left_crp), target_left_crp_sem]
    #e3_norm = np.divide(e3, target_left_crp_sem)

    es['e4'] = [np.subtract(target_right_crp, this_right_crp), target_right_crp_sem]
    #e4_norm = np.divide(e4, target_right_crp_sem)

    es['e5'] = [np.subtract(target_PLI, this_PLI), np.array(target_PLI_sem)]
    #e5_norm = np.divide(e5, target_PLI_sem)

    #es['e6'] = [np.array(target_ELI - this_ELI), np.array(target_ELI_sem)]
    #e6_norm = np.divide(e6, target_ELI_sem)
    
    es['e7'] = [np.subtract(target_crl, this_crl), target_crl_sem]
    
    
    
    for e in es:
        if 0 in es[e][1]:
            es[e][0] = np.delete(es[e][0], np.where(es[e][1] == 0))
            es[e][1] = np.delete(es[e][1], np.where(es[e][1] == 0))
        es[e] = (es[e][0]/es[e][1].astype(float)) ** 2

    print es
    # calculate rmse / chi^2 value after norming the error terms
    
#    (
#        len(e1_norm) + len(e2_norm) + len(e3_norm)
#        + len(e4_norm) + 2)

    # this one is only the lag-crp values and spc and PLI and ELI
    
    print 'why is there a zero here', [es[e] for e in es]
    
    RMSE_normed = (np.nansum([np.nansum(es[e]) for e in es]))
    
#    RMSE_normed = (
#                      (np.nansum(e3_norm ** 2)
#                       + np.nansum(e4_norm ** 2)
#                       + np.nansum(e1_norm **2)
#                       + np.nansum(e5_norm **2)
#                       + np.nansum(e6_norm ** 2))
#                   /(len(e1) + len(e3) + len(e4) + 2)) ** 0.5

    print("RMSE_normed is: ", RMSE_normed)

    # get just a regular rmse, not normed by the sem of the data
    # nerr_raw = len(e1) + len(e2) + len(e3) + len(e4)
    # sum_squared_err_raw = (np.nansum(e1**2) + np.nansum(e2**2)
    #                        + np.nansum(e3**2) + np.nansum(e4**2))
    # RMSE = (sum_squared_err_raw / nerr_raw) ** 0.5

    return RMSE_normed


def gridsearch(func, def_params, lb, ub, search_on, num_bins):
    lb = np.array(lb)
    ub = np.array(ub)
    search_on = np.asarray(search_on)
    gridparams = def_params.copy()
    rmses = {}
    
    for i in np.linspace(lb[0], ub[0], num=num_bins):
        print search_on[0], i
        gridparams[search_on[0]] = i
        for j in np.linspace(lb[1], ub[1], num=num_bins):
            print '-', search_on[1], j
            gridparams[search_on[1]] = j
            rmse =  obj_func(param_vec=None, param_dict=gridparams)
            label = '%s:%s' % (i, j)
            rmses[label] = rmse
            print 'rmse:',  rmse
    
    return rmses

def gridsearch_parralel(func, def_params, lb, ub, search_on, num_bins):
    lb = np.array(lb)
    ub = np.array(ub)
    search_on = np.asarray(search_on)
    gridparams = def_params.copy()
    rmses = {}
    
    param1_linspace = np.linspace(lb[0], ub[0], num=num_bins)
    stored_fname = 'param1_linspace.txt'
    if not os.path.isfile(stored_fname):
        np.savetxt(stored_fname, param1_linspace)
        
    param1_linspace = np.loadtxt(stored_fname)
    if not param1_linspace.shape:
        param1_linspace = param1_linspace.reshape(1)
        os.remove(stored_fname)
    
    print 'param1_linspace`:', param1_linspace
    my_param1 = param1_linspace[0]
    param1_linspace = param1_linspace[1:]
    np.savetxt(stored_fname, param1_linspace)
    print 'im doing %f for param %s' % (my_param1, search_on[0])
    
    gridparams[search_on[0]] = my_param1
    param2_linspace = np.linspace(lb[1], ub[1], num=num_bins)
    rmses = []
    for j in param2_linspace:
        print '- %s=' % search_on[1], j
        gridparams[search_on[1]] = j
        rmse =  obj_func(param_vec=None, param_dict=gridparams)
        print 'rmse:',  rmse
        rmses.append(rmse)
    
    toSave = np.array([param2_linspace, rmses])
    savename = '%s=%f_rmses.txt' % (search_on[0], my_param1)
    np.savetxt(savename, toSave)
    best_rmse = min(rmses)
    print 'best rmse is at %s=%f and is %f' % (search_on[1], 
                    param2_linspace[np.where(rmses==best_rmse)], best_rmse)
    
    return rmses
    

def main():
    #########
    #
    #   Define some helpful global (yikes, I know!) variables.
    #
    #########

    global ll, data_pres, data_rec, LSA_path, data_path, LSA_mat
    global target_spc, target_spc_sem, target_pfc, target_pfc_sem
    global target_left_crp, target_left_crp_sem
    global target_right_crp, target_right_crp_sem

    # Set LSA and data paths -- K02 data
    on_rhino = True
    if on_rhino:
        LSA_path = 'w2v.txt'
        data_path = 'pres_nos_LTP093.txt'
        rec_path = 'rec_nos_LTP093.txt'
        times_path = 'times_LTP093.txt'

    else:
        LSA_path = '/Users/KahaNinja/PycharmProjects/LinearPar/CMR2_lowmem/K02_LSA.txt'
        data_path = '/Users/KahaNinja/PycharmProjects/CMR2/K02_files/K02_data.mat'


    LSA_mat = np.loadtxt(LSA_path)

    ### comment this back in if getting data from a MATLAB file
    # get data file, presented items, & recalled items
    # data_file = scipy.io.loadmat(
    #     data_path, squeeze_me=True, struct_as_record=False)
    #
    # data_pres = data_file['data'].pres_itemnos      # presented
    # data_rec = data_file['data'].rec_itemnos        # recalled

    # if getting data from a text file:
    data_pres = np.loadtxt(data_path, delimiter=',')
    data_rec = np.loadtxt(rec_path, delimiter=',')
    data_times = np.loadtxt(times_path, delimiter=',')

    # set list length
    ll = 24
    # set n sessions
    nsessions = 24
    # set n lists per session
    lists_per_session=24

    # recode lists for spc, pfc, and lag-CRP analyses
    recoded_lists = recode_for_spc(data_rec, data_pres)

    # get spc & pfc
    target_spc, target_spc_sem, target_pfc, target_pfc_sem = \
        get_spc_pfc(recoded_lists, ll)

    target_crp, target_crp_sem = lagCRP2.get_crp(recoded_lists, ll)

    # set any SEM values that are equal to 0.0, equal to 1.0
    # (i.e., leave values as is)
    target_spc_sem[target_spc_sem == 0.0] = 1.0
    target_crp_sem[target_crp_sem == 0.0] = 1.0
    target_pfc_sem[target_pfc_sem == 0.0] = 1.0

    # get Lag-CRP sections of interest
    center_val = ll - 1

    target_left_crp = target_crp[center_val-5:center_val]
    target_left_crp_sem = target_crp_sem[center_val-5:center_val]
    
    target_left_crp = convert_crp(target_crp, left=True)
    target_left_crp_sem = convert_crp(target_crp_sem, left=True)
    
    target_right_crp = target_crp[center_val+1:center_val+6]
    target_right_crp_sem = target_crp_sem[center_val+1:center_val+6]
    
    target_right_crp = convert_crp(target_crp, left=False)
    target_right_crp_sem = convert_crp(target_crp_sem, left=False)

    global target_PLI, target_PLI_sem
    global target_ELI, target_ELI_sem

    # get mean and sem for the observed data's PLI's and ELI's
    target_PLI, target_ELI, \
    target_PLI_sem, target_ELI_sem = get_num_intrusions(
        data_rec, data_pres,
        lists_per_div=lists_per_session)
    target_PLI, target_PLI_sem = plis.plicount(recoded_lists)
    
    global szs_for_crl, target_crl, target_crl_sem
    target_crl, target_crl_sem, szs_for_crl = opR_crl.opR_crl(data_times, recoded_lists)

    # make sure we do not later divide by 0 in case the sem's are 0
    #target_ELI_sem[target_ELI_sem == 0] = 1
    target_PLI_sem[target_PLI_sem == 0] = 1


    #############
    #
    #   set lower and upper bounds
    #
    #############

    lb = [0.1, 0.1, 0.3, 0.1, 0.1, 0.1, 0.01, 0.01, 0.5, .1, 5.0, .5, .001, .01]
    ub = [1.0, 1.0, 0.7, 1.0, 3.0, 1.5, 0.5, 0.5, 3.0, 1.0, 15.0, 1.0, 0.8, 0.5]
    
    params_093_spc_crp_pli_31 = {
        'beta_enc': 2.785291934596597074e-01,
        'beta_rec': 6.383527530661591287e-01,
        'gamma_fc': 3.968139462336542911e-01,
        'gamma_cf': 9.494140002163982128e-01,
        'scale_fc': 1 - 3.968139462336542911e-01,
        'scale_cf': 1 - 9.494140002163982128e-01,
    
        'phi_s': 2.157968652715054780e+00,
        'phi_d': 1.312590804776602615e+00,
        'kappa': 1.954898402828377513e-01,
    
        'eta': 2.115299892696877460e-01,
        's_cf': 1.439828498396066081e+00,
        's_fc': 0.0,
        'beta_rec_post': 5.539411142449401915e-01,
        'omega': 1.118186487766434389e+01,
        'alpha': 8.608259186179094691e-01,
        'c_thresh': 4.086471677982843054e-01,
        'dt': 10.0,
    
        'lamb': 7.677613206786167155e-02,
        'rec_time_limit': 75000,
    
        'dt_tau': 0.01,
        'sq_dt_tau': 0.10,
    
        'nlists_for_accumulator': 4
    }

    #kappa :  0.01-0.5
    #lamb : 0.01-0.5
    
    lb = [0.01, 0.01]
    ub = [0.5, 0.5]
    search_on = ['kappa', 'lamb']

    start_time = time.time()
    gridsearch_parralel(func=obj_func, 
                        def_params=params_093_spc_crp_pli_31, 
                        lb=lb, ub=ub, 
                        search_on=search_on, num_bins=50)
    #pso(obj_func, params_093_spc_crp_pli_31, lb, ub, search_on = search_on, num_bins=50, debug=False)

    #print(xopt)
    print("Run time: " + str(time.time() - start_time))

    sys.stdout.flush()
    time.sleep(5)
    tempfile_paths = glob('*tempfile*')
    for mini_path in tempfile_paths:
        if os.path.isfile(mini_path):
            os.remove(mini_path)

   # np.savetxt('xopt_LTP093.txt', xopt, delimiter=',', fmt='%f')


if __name__ == "__main__": main()
